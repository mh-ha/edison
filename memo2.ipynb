{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rearrange\n",
    "### einsum\n",
    "### reduce\n",
    "### repeat\n",
    "### pack, unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, einsum, reduce, repeat\n",
    "import torch, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1 = torch.randn((16, 32, 64))\n",
    "arr_2 = torch.randn((16, 32, 64))\n",
    "arr_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(arr_1, 'a b c -> b a c').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 32, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(arr_2, 'a b (d e) -> a b d e', d=arr_2.shape[-1]//2, e=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einsum(arr_1, 'a b c -> a b').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(arr_1, 'a b c -> b c', 'mean').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 10]),\n",
       " tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
       "          [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
       "          [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
       "          [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
       "          [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]],\n",
       " \n",
       "         [[50., 51., 52., 53., 54., 55., 56., 57., 58., 59.],\n",
       "          [60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n",
       "          [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n",
       "          [80., 81., 82., 83., 84., 85., 86., 87., 88., 89.],\n",
       "          [90., 91., 92., 93., 94., 95., 96., 97., 98., 99.]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_int = torch.arange(100, dtype=torch.float)\n",
    "arr_int = rearrange(arr_int, '(a b c) -> a b c', a=2, b=5, c=10)\n",
    "arr_int.shape, arr_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5000, 14.5000, 24.5000, 34.5000, 44.5000],\n",
       "        [54.5000, 64.5000, 74.5000, 84.5000, 94.5000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(arr_int, 'a b c -> a b', 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9., 19., 29., 39., 49.],\n",
       "        [59., 69., 79., 89., 99.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(arr_int, 'a b c -> a b', 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 3.3522e+11, 7.2685e+13, 2.3070e+15, 2.9821e+16],\n",
       "        [2.2799e+17, 1.2339e+18, 5.2279e+18, 1.8453e+19, 5.6534e+19]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(arr_int, 'a b c -> a b', 'prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "         14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
       "         28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
       "         42., 43., 44., 45., 46., 47., 48., 49.],\n",
       "        [50., 51., 52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62., 63.,\n",
       "         64., 65., 66., 67., 68., 69., 70., 71., 72., 73., 74., 75., 76., 77.,\n",
       "         78., 79., 80., 81., 82., 83., 84., 85., 86., 87., 88., 89., 90., 91.,\n",
       "         92., 93., 94., 95., 96., 97., 98., 99.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(arr_int, 'a b c -> a (b c)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
       "         [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
       "         [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]],\n",
       "\n",
       "        [[50., 51., 52., 53., 54., 55., 56., 57., 58., 59.],\n",
       "         [60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n",
       "         [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n",
       "         [80., 81., 82., 83., 84., 85., 86., 87., 88., 89.],\n",
       "         [90., 91., 92., 93., 94., 95., 96., 97., 98., 99.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 10]), torch.Size([2, 5, 10]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(arr_int, 'a b c -> a () c', 'mean').shape, arr_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.],\n",
       "         [ 10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [-10., -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20.]],\n",
       "\n",
       "        [[ 20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.],\n",
       "         [ 10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [-10., -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20.]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(arr_int, 'a b c -> a () c', 'mean') - arr_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.],\n",
       "         [ 10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [-10., -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20.]],\n",
       "\n",
       "        [[ 20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.,  20.],\n",
       "         [ 10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.,  10.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [-10., -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20.]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = reduce(arr_int, 'a b c -> a () c', 'mean')\n",
    "arr - arr_int\n",
    "# arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
       "          [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
       "          [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
       "          [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
       "          [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.]],\n",
       " \n",
       "         [[70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n",
       "          [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n",
       "          [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n",
       "          [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n",
       "          [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.]]]),\n",
       " tensor([[[20., 21., 22., 23., 24., 25., 26., 27., 28., 29.]],\n",
       " \n",
       "         [[70., 71., 72., 73., 74., 75., 76., 77., 78., 79.]]]),\n",
       " tensor([[[20., 21., 22., 23., 24., 25., 26., 27., 28., 29.]],\n",
       " \n",
       "         [[70., 71., 72., 73., 74., 75., 76., 77., 78., 79.]]]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_rep = repeat(arr, 'a () c -> a b c', b=5)\n",
    "arr_rep, reduce(arr_rep, 'a b c -> a () c', 'min'), arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 10]) torch.Size([10, 5, 2])\n",
      "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
      "         [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
      "         [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
      "         [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]],\n",
      "\n",
      "        [[50., 51., 52., 53., 54., 55., 56., 57., 58., 59.],\n",
      "         [60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n",
      "         [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n",
      "         [80., 81., 82., 83., 84., 85., 86., 87., 88., 89.],\n",
      "         [90., 91., 92., 93., 94., 95., 96., 97., 98., 99.]]]) tensor([[[ 0., 50.],\n",
      "         [10., 60.],\n",
      "         [20., 70.],\n",
      "         [30., 80.],\n",
      "         [40., 90.]],\n",
      "\n",
      "        [[ 1., 51.],\n",
      "         [11., 61.],\n",
      "         [21., 71.],\n",
      "         [31., 81.],\n",
      "         [41., 91.]],\n",
      "\n",
      "        [[ 2., 52.],\n",
      "         [12., 62.],\n",
      "         [22., 72.],\n",
      "         [32., 82.],\n",
      "         [42., 92.]],\n",
      "\n",
      "        [[ 3., 53.],\n",
      "         [13., 63.],\n",
      "         [23., 73.],\n",
      "         [33., 83.],\n",
      "         [43., 93.]],\n",
      "\n",
      "        [[ 4., 54.],\n",
      "         [14., 64.],\n",
      "         [24., 74.],\n",
      "         [34., 84.],\n",
      "         [44., 94.]],\n",
      "\n",
      "        [[ 5., 55.],\n",
      "         [15., 65.],\n",
      "         [25., 75.],\n",
      "         [35., 85.],\n",
      "         [45., 95.]],\n",
      "\n",
      "        [[ 6., 56.],\n",
      "         [16., 66.],\n",
      "         [26., 76.],\n",
      "         [36., 86.],\n",
      "         [46., 96.]],\n",
      "\n",
      "        [[ 7., 57.],\n",
      "         [17., 67.],\n",
      "         [27., 77.],\n",
      "         [37., 87.],\n",
      "         [47., 97.]],\n",
      "\n",
      "        [[ 8., 58.],\n",
      "         [18., 68.],\n",
      "         [28., 78.],\n",
      "         [38., 88.],\n",
      "         [48., 98.]],\n",
      "\n",
      "        [[ 9., 59.],\n",
      "         [19., 69.],\n",
      "         [29., 79.],\n",
      "         [39., 89.],\n",
      "         [49., 99.]]])\n"
     ]
    }
   ],
   "source": [
    "print(arr_int.shape, rearrange(arr_int, 'a b c -> c b a').shape)\n",
    "print(arr_int, rearrange(arr_int, 'a b c -> c b a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 10]), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_int.shape, rearrange(arr_int, 'a b c -> (a b) c').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import pack, unpack\n",
    "\n",
    "h, w = 100, 200\n",
    "# image_rgb is 3-dimensional (h, w, 3) and depth is 2-dimensional (h, w)\n",
    "image_rgb = np.random.random([h, w, 3])\n",
    "image_depth = np.random.random([h, w])\n",
    "# but we can stack them\n",
    "image_rgbd, ps = pack([image_rgb, image_depth], 'h w *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 200, 3), (100, 200), (100, 200, 4), [(3,), ()])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_rgb.shape, image_depth.shape, image_rgbd.shape, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 200, 3), (100, 200))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 1-axis in depth image during unpacking. Results are (h, w, 3) and (h, w)\n",
    "unpacked_rgb, unpacked_depth = unpack(image_rgbd, ps, 'h w *')\n",
    "unpacked_rgb.shape, unpacked_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple unpack by splitting the axis. Results are (h, w, 3) and (h, w, 1)\n",
    "rgb, depth = unpack(image_rgbd, [[3], [1]], 'h w *')\n",
    "# different split, both outputs have shape (h, w, 2)\n",
    "rg, bd = unpack(image_rgbd, [[2], [2]], 'h w *')\n",
    "# unpack to 4 tensors of shape (h, w). More like 'unstack over last axis'\n",
    "[r, g, b, d] = unpack(image_rgbd, [[], [], [], []], 'h w *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 200, 3),\n",
       " (100, 200, 1),\n",
       " (100, 200, 2),\n",
       " (100, 200, 2),\n",
       " (100, 200),\n",
       " (100, 200),\n",
       " (100, 200),\n",
       " (100, 200))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb.shape, depth.shape, rg.shape, bd.shape, r.shape, g.shape, b.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-Batching Example\n",
    "\n",
    "from einops import reduce\n",
    "def image_classifier(images_bhwc):\n",
    "    # mock for image classifier\n",
    "    predictions = reduce(images_bhwc, 'b h w c -> b c', 'mean', h=100, w=200, c=3)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def universal_predict(x):\n",
    "    x_packed, ps = pack([x], '* h w c')\n",
    "    predictions_packed = image_classifier(x_packed)\n",
    "    [predictions] = unpack(predictions_packed, ps, '* cls')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(5, 3)\n",
      "(5, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "# works with a single image\n",
    "print(universal_predict(np.zeros([h, w, 3])).shape)\n",
    "# works with a batch of images\n",
    "batch = 5\n",
    "print(universal_predict(np.zeros([batch, h, w, 3])).shape)\n",
    "# or even a batch of videos\n",
    "n_frames = 7\n",
    "print(universal_predict(np.zeros([batch, n_frames, h, w, 3])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 10]), torch.Size([16, 32, 64]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_int.shape, arr_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1 = rearrange(arr_1, 'a (b c) -> a b c', b=32, c=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2048, 1])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1 = rearrange(arr_1, 'a b c -> a (b c) ()')\n",
    "arr_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n"
     ]
    }
   ],
   "source": [
    "arr_1 = arr_1.to(torch.int8)\n",
    "prev = None\n",
    "for i in arr_1[0]:\n",
    "    if prev is None:\n",
    "        prev = i\n",
    "    # print(i.data_ptr())\n",
    "    print((i.data_ptr() - prev.data_ptr()))\n",
    "    # print(id(i) - id(prev))\n",
    "    # print(id(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(10,20,30) # b -> 10, i -> 20, k -> 30\n",
    "c = torch.randn(10,50,30) # b -> 10, j -> 50, k -> 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20, 50])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einsum(a,c, 'b i k, b j k -> b i j').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contiguous, stride\n",
    "메모리 저장 상태 깨졌을 때 일관되게 바꿔주고 확인하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 1, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1.contiguous()\n",
    "arr_1.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2048, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-100],\n",
       "         [   0],\n",
       "         [-100],\n",
       "         ...,\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0]],\n",
       "\n",
       "        [[   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         ...,\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0]],\n",
       "\n",
       "        [[   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         ...,\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         ...,\n",
       "         [  -1],\n",
       "         [   0],\n",
       "         [   0]],\n",
       "\n",
       "        [[   0],\n",
       "         [   0],\n",
       "         [-100],\n",
       "         ...,\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0]],\n",
       "\n",
       "        [[   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         ...,\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0]]], dtype=torch.int8)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1.masked_fill(arr_1>0, -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deberta.networks import LM, LMDataModule\n",
    "from deberta.config import Config\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "config = Config(\n",
    "    hidden_dim=768,\n",
    "    embedding_dim=1024,\n",
    "    max_seq_len=512,\n",
    "    padding_idx=0,\n",
    "    vocab_size=128001,\n",
    "    absolute_position_biased_input=True,\n",
    "    num_heads=12,\n",
    "    num_head_dim=64,\n",
    "    layernorm_eps=1e-9,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    num_hidden_layers=12,\n",
    "    device='cuda',\n",
    "    mask_lm_prob=0.15,\n",
    ")\n",
    "\n",
    "model = LM(config)\n",
    "data_module = LMDataModule(config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[     1,    387,  27825,  ...,      0,      0,      0],\n",
      "        [     1,     11,   2986,  ...,      0,      0,      0],\n",
      "        [     1,    133,  34720,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [     1, 128000,      5,  ...,      0,      0,      0],\n",
      "        [     1,    627,   2764,  ...,      0,      0,      0],\n",
      "        [     1,   6634,    215,  ...,      0,      0,      0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0, 34720,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    0, 49519,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]])}\n"
     ]
    }
   ],
   "source": [
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "for batch in data_module.train_dataloader():\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 225]), torch.Size([32, 225]), torch.Size([32, 225]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     1, 128000,     42,  ...,      0,      0,      0],\n",
       "         [     1,  46086,   1264,  ...,      0,      0,      0],\n",
       "         [     1,  49519,   2230,  ...,      0,      0,      0],\n",
       "         ...,\n",
       "         [     1,    700,  20185,  ...,      0,      0,      0],\n",
       "         [     1,    625,  16977,  ...,      0,      0,      0],\n",
       "         [     1,  49519,    905,  ...,      0,      0,      0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[    0, 49519,     0,  ...,     0,     0,     0],\n",
       "         [    0,     0,     0,  ...,     0,     0,     0],\n",
       "         [    0,     0,     0,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    0,     0,     0,  ...,     0,     0,     0],\n",
       "         [    0,     0,     0,  ...,     0,     0,     0],\n",
       "         [    0,     0,   905,  ...,     0,     0,     0]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 317]), torch.Size([32, 317]), torch.Size([32, 317]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape, batch['attention_mask'].shape, batch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(x):\n",
    "    return x**2\n",
    "\n",
    "lists = [1, 2, 3, 4, 5]\n",
    "lists = list(map(test, lists))\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from deberta.fetch_dataset import fetch_dataset\n",
    "\n",
    "dataset = fetch_dataset('bookcorpus')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=12): 100%|██████████| 74009525/74009525 [04:48<00:00, 256353.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from deberta.prep_dataset import split_sentences, tokenize\n",
    "\n",
    "dataset = dataset.map(split_sentences, batched=True, num_proc=12, remove_columns=dataset.column_names)\n",
    "dataset = dataset.map(tokenize, batched=True, num_proc=12, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from deberta.utils import NGramMaskGenerator\n",
    "from deberta.config import Config\n",
    "from deberta.networks import LM, LMDataModule\n",
    "\n",
    "config = Config(\n",
    "    hidden_dim=768,\n",
    "    embedding_dim=1024,\n",
    "    max_seq_len=512,\n",
    "    padding_idx=0,\n",
    "    vocab_size=128001,\n",
    "    absolute_position_biased_input=True,\n",
    "    num_heads=12,\n",
    "    num_head_dim=64,\n",
    "    layernorm_eps=1e-9,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    num_hidden_layers=12,\n",
    "    device='cuda',\n",
    "    mask_lm_prob=0.15,\n",
    ")\n",
    "model = LM(config)\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "data_module = LMDataModule(config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 238 M \n",
      "1 | discriminator | Discriminator | 237 M \n",
      "------------------------------------------------\n",
      "475 M     Trainable params\n",
      "0         Non-trainable params\n",
      "475 M     Total params\n",
      "1,902.993 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [00:00<?, ?it/s], 69, 865, 1335, 479, 2][1, 49519, 117, 2156, 12801, 1236, 11867, 26, 2156, 45518, 53, 939, 21, 295, 75, 1227, 7, 12908, 1518, 261, 2156, 1169, 479, 12801, 2][1, 405, 5658, 28, 3859, 662, 479, 2]   11[1, 4297, 117, 55, 3422, 479, 2]1\n",
      "Training:   0%|          | 0/25701300 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/25701300 [00:00<?, ?it/s]  \n",
      "['[CLS]', '▁82', '▁storms', '▁easy', '<0x41>', '<0x04>', 'con', '<0x04>', 'ute', '<0x41>', '▁e', '▁rights', '▁things', '[SEP]']['[CLS]', '▁COD', '<0x71>', '▁90', '▁amendments', '▁credit', '▁architects', '<0x16>', '▁90', '▁tidbits', '<0x31>', '▁forward', '<0x11>', '▁can', '<0x47>', '▁extra', '<0x03>', '▁sweep', '▁bed', ',', '▁90', '▁terms', '▁things', '▁amendments', '[SEP]']1['[CLS]', '▁such', '▁occasions', '<0x18>', '▁grant', '▁S', '▁things', '[SEP]']  \n",
      " 222['[CLS]', '▁army', '<0x71>', '<0x33>', '▁collected', '▁things', '[SEP]']\n",
      "\n",
      "\n",
      " 2\n",
      "['[CLS]', '▁such', '▁occasions', '<0x18>', '▁grant', '▁S', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 405, 5658, 28, 3859, 662, 128000, 2] masked_sample ids\n",
      "[1, 118, 19975, 14, 127, 809, 21, 6827, 7, 39, 356, 479, 2] 1\n",
      "['[CLS]', '<0x72>', '▁pyramid', '<0x0A>', '<0x7B>', '▁buy', '<0x11>', '▁jumped', '<0x03>', '<0x23>', '▁any', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁army', '<0x71>', '[MASK]', '▁collected', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 55, 0, 0, 0] target_labels\n",
      "[1, 4297, 117, 128000, 3422, 479, 2] masked_sample ids\n",
      "[1, 763, 6, 886, 6, 147, 37, 21, 41, 1031, 13, 10, 6255, 8, 26923, 138, 4, 91, 1410, 7, 4316, 11, 23102, 6, 147, 37, 1179, 9440, 8, 13460, 15, 11771, 4743, 583, 33053, 6125, 4, 91, 2075, 13, 558, 25, 41, 2222, 6, 53, 23, 5, 7493, 9, 5, 1172, 537, 6, 71, 6217, 119, 10544, 6, 54, 56, 416, 5288, 258, 5, 1557, 8, 1172, 11097, 13, 28683, 6, 21, 1238, 9, 13557, 6046, 4, 91, 18783, 11429, 217, 903, 6, 1492, 6, 4264, 6, 8, 6300, 6, 8, 1665, 10, 1385, 25, 394, 1759, 32196, 1688, 11, 12497, 4, 50118, 50118, 39531, 10849, 4625, 10, 1418, 217, 5, 343, 9, 17720, 11567, 4, 91, 1660, 10, 5265, 1305, 7, 1323, 41, 490, 2270, 8322, 7, 5, 4316, 5879, 11, 14873, 4, 91, 78, 585, 37, 74, 1962, 5, 1557, 537, 11, 502, 14488, 6, 31993, 2961, 3262, 26682, 108, 2] 1\n",
      "['[CLS]', '▁current', '<0x02>', '▁required', '<0x02>', '<0x8F>', '<0x21>', '<0x11>', '<0x25>', '▁recent', '<0x09>', '<0x06>', '▁Records', '<0x04>', '▁Potato', '<0x86>', '<0x00>', '<0x57>', '▁app', '<0x03>', '▁temporary', '<0x07>', '▁biopsy', '<0x02>', '<0x8F>', '<0x21>', '▁difficult', '▁explosion', '<0x04>', '▁cemetery', '<0x0B>', 'any', '▁temperatures', '▁until', '▁Cine', '▁keyboard', '<0x00>', '<0x57>', '▁furniture', '<0x09>', 'A', '<0x15>', '<0x25>', '▁USA', '<0x02>', '<0x31>', '<0x13>', '<0x01>', '▁breach', '<0x05>', '<0x01>', '▁June', '▁area', '<0x02>', '<0x43>', '▁sixth', '<0x73>', '▁laughter', '<0x02>', '<0x32>', '<0x34>', '▁before', '▁roughly', '<0xFE>', '<0x01>', '▁businesses', '<0x04>', '▁June', '▁spinal', '<0x09>', '▁eczema', '<0x02>', '<0x11>', '▁goal', '<0x05>', '▁Verizon', '▁parallel', '<0x00>', '<0x57>', 'ü', '▁Programs', '<0xD5>', '▁May', '<0x02>', 'p', '<0x02>', '▁deeply', '<0x02>', '<0x04>', '▁amenities', '<0x02>', '<0x04>', '▁Because', '<0x06>', '▁himself', '<0x15>', '▁now', '▁existing', '▁automaker', '▁anti', '<0x07>', '▁exceeded', '<0x00>', 'wrenching', 'wrenching', '▁Anastasia', '▁credibility', '▁consent', '<0x06>', '▁High', '<0xD5>', '<0x01>', '▁there', '<0x05>', '▁Avengers', '▁Method', '<0x00>', '<0x57>', '▁easier', '<0x06>', '▁documentation', '▁marketing', '<0x03>', '▁daily', '<0x25>', '▁does', '▁topic', '▁urged', '<0x03>', '<0x01>', '▁temporary', 'ize', '<0x07>', '▁responds', '<0x00>', '<0x57>', '<0x4A>', '▁No', '<0x21>', '<0x46>', '▁contract', '<0x01>', '▁businesses', '▁area', '<0x07>', '▁To', '▁borrowing', '<0x02>', '▁gazing', '▁candidates', '▁tiny', '▁pageant', '<0x68>', '[SEP]'] 2\n",
      "['[CLS]', '▁82', '▁storms', '▁easy', '<0x41>', '<0x04>', '[MASK]', '<0x04>', 'ute', '<0x41>', '▁e', '▁rights', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 0, 5699, 0, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 8877, 11541, 639, 69, 8, 128000, 8, 14454, 69, 865, 1335, 128000, 2] masked_sample ids\n",
      "[1, 487, 9259, 179, 108, 10862, 14208, 24276, 108, 3713, 108, 16, 5, 200, 8, 507, 2642, 703, 30, 11619, 333, 6, 5, 1821, 5637, 329, 4, 85, 21, 703, 15, 779, 204, 6, 8148, 149, 9880, 8, 6107, 10023, 4, 572, 10, 1800, 2453, 80, 107, 2052, 6, 42, 2642, 1447, 7, 914, 5, 1282, 9, 4611, 20914, 4611, 6, 129, 3723, 7520, 23, 849, 2940, 15, 5, 3107, 248, 947, 387, 73, 725, 1588, 12, 30158, 19657, 29, 4, 20, 129, 5966, 154, 881, 22, 35436, 179, 113, 95, 21174, 23, 849, 3414, 15, 5, 6003, 16469, 10413, 1634, 4, 50118, 50118, 39901, 8118, 50118, 113, 16549, 15, 305, 329, 2990, 34133, 155, 35, 3714, 50118, 113, 29390, 1342, 9, 16945, 36, 133, 2944, 35110, 30831, 12, 195, 35, 844, 50118, 113, 35436, 179, 108, 34133, 155, 35, 4283, 50118, 113, 4148, 8318, 108, 312, 9671, 34133, 204, 35, 2518, 50118, 113, 43361, 34133, 204, 35, 2546, 50118, 113, 495, 219, 179, 108, 2548, 1398, 34133, 155, 35, 3305, 50118, 113, 1106, 38, 305, 4987, 10, 9908, 34133, 204, 35, 2546, 50118, 113, 3084, 41385, 6, 440, 22916, 6, 440, 34643, 34133, 204, 35, 2890, 50118, 113, 996, 3676, 26859, 34133, 155, 35, 3079, 50118, 113, 24514, 22191, 166, 2462, 34133, 204, 35, 4540, 50118, 113, 22456, 1832, 34133, 195, 35, 4124, 50118, 113, 487, 9259, 179, 108, 10862, 6, 14208, 24276, 108, 3713, 108, 34133, 204, 35, 2481, 50118, 113, 33177, 11101, 1631, 34133, 155, 35, 4419, 50118, 113, 495, 196, 14086, 34133, 204, 35, 1922, 50118, 50118, 104, 45598, 50118, 113, 16549, 2] 1\n",
      "['[CLS]', '▁set', '▁NOW', '<0xAF>', '<0x68>', '▁giveaway', 'berry', '▁berth', '<0x68>', '▁bags', '<0x68>', '<0x0C>', '<0x01>', '<0xC4>', '<0x04>', '▁', '▁limit', '▁30', '<0x1A>', '▁developmental', '▁do', '<0x02>', '<0x01>', '▁larger', '▁Atlantic', '▁This', '<0x00>', '<0x51>', '<0x11>', '▁30', '<0x0B>', '▁special', '<0xC8>', '<0x02>', 'person', '<0x91>', '▁fixing', '<0x04>', 'born', '▁vocals', '<0x00>', '▁children', '<0x06>', '▁comfortable', '▁35', '<0x4C>', '<0x67>', '▁soft', '<0x02>', '<0x26>', '▁limit', '▁Great', '<0x03>', '▁account', '<0x01>', '▁International', '<0x05>', '▁flower', '▁tally', '▁flower', '<0x02>', '<0x7D>', '▁mining', '▁partially', '<0x13>', '▁wanted', '▁providers', '<0x0B>', '<0x01>', '▁films', '<0xF4>', '▁problems', '▁could', '<0x45>', 'to', '▁bar', '<0x08>', '▁hamstring', 'Mail', '<0x19>', '<0x00>', '<0x10>', '<0x7D>', '▁Industrial', '<0x96>', '▁white', '<0x12>', '▁eroded', '<0xAF>', '<0x6D>', '<0x5B>', '▁duly', '<0x13>', '▁wanted', '▁intelligence', '<0x0B>', '<0x01>', '▁entertaining', '▁Coral', '▁Understanding', '▁storage', '<0x00>', 'wrenching', 'wrenching', 'rounder', '▁Robinson', 'wrenching', '<0x6D>', '▁Holidays', '<0x0B>', '▁all', '▁This', '▁Museum', '▁ketchup', '<0x97>', '<0x1F>', '▁generated', 'wrenching', '<0x6D>', '▁Quincy', '▁English', '<0x05>', '▁KB', '<0x20>', '<0x81>', '22', '▁rejuvenation', '▁outsourced', '<0x08>', '<0xBF>', '<0x1F>', '▁City', 'wrenching', '<0x6D>', '▁eroded', '<0xAF>', '<0x68>', '▁ketchup', '<0x97>', '<0x1F>', '▁Alex', 'wrenching', '<0x6D>', '▁suggestions', '▁Wind', '<0x68>', '▁my', '▁searched', '▁ketchup', '<0xC8>', '<0x1F>', '▁typically', 'wrenching', '<0x6D>', 'rau', '▁ketchup', '<0xC8>', '<0x1F>', '▁cultural', 'wrenching', '<0x6D>', '▁family', '<0xD7>', '<0xAF>', '<0x68>', '▁Z', 'an', '▁ketchup', '<0x97>', '<0x1F>', '▁hardware', 'wrenching', '<0x6D>', '▁store', '<0x22>', '▁all', '▁1995', '<0x06>', '▁remainder', '▁ketchup', '<0xC8>', '<0x1F>', '▁cultural', 'wrenching', '<0x6D>', '▁output', '▁SUNY', '<0x02>', '%', 'etz', '<0x02>', '%', '▁Defensive', '▁ketchup', '<0xC8>', '<0x1F>', '▁speech', 'wrenching', '<0x6D>', '▁specific', '▁thread', '▁Fridays', '▁ketchup', '<0x97>', '<0x1F>', '▁extended', 'wrenching', '<0x6D>', '▁Wildcats', '▁Clan', '<0xA2>', '▁whom', '▁ketchup', '<0xC8>', '<0x1F>', '▁viewing', 'wrenching', '<0x6D>', '▁vows', '▁spot', '▁ketchup', '<0xBF>', '<0x1F>', '▁bars', 'wrenching', '<0x6D>', '▁set', '▁NOW', '<0xAF>', '<0x68>', '▁giveaway', '<0x02>', 'berry', '▁berth', '<0x68>', '▁bags', '<0x68>', '▁ketchup', '<0xC8>', '<0x1F>', '▁volume', 'wrenching', '<0x6D>', '▁temperate', '▁Knowing', '▁pictures', '▁ketchup', '<0x97>', '<0x1F>', '▁museum', 'wrenching', '<0x6D>', '▁family', '<0xC0>', '▁commissioner', '▁ketchup', '<0xC8>', '<0x1F>', '▁Use', 'wrenching', 'wrenching', '<0x64>', '▁daisy', 'wrenching', '<0x6D>', '▁Holidays', '[SEP]'] 2\n",
      "['[CLS]', '<0x72>', '▁pyramid', '<0x0A>', '<0x7B>', '[MASK]', '<0x11>', '▁jumped', '<0x03>', '<0x23>', '[MASK]', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 809, 0, 0, 0, 0, 356, 0, 0] target_labels\n",
      "[1, 118, 19975, 14, 127, 128000, 21, 6827, 7, 39, 128000, 479, 2] masked_sample ids\n",
      "[1, 133, 4743, 2456, 11660, 16493, 4031, 6, 11, 4743, 2456, 6, 188, 1625, 6, 21, 1490, 11, 28955, 4, 1437, 85, 21, 3147, 15, 5, 496, 10315, 9, 15541, 28540, 11, 11735, 4, 50118, 50118, 243, 34, 67, 57, 684, 25, 5, 4743, 2456, 2573, 6919, 8, 25, 5, 2573, 824, 4, 50118, 50118, 243, 16, 5, 144, 5395, 745, 11, 4743, 2456, 6, 8, 21, 341, 25, 10, 559, 7648, 9, 188, 10979, 1767, 30, 188, 1625, 3383, 27058, 255, 7790, 4, 50118, 50118, 49379, 50118, 50118, 18285, 10315, 9, 15541, 28540, 11, 6623, 16557, 413, 6, 188, 1625, 50118, 30597, 254, 858, 9437, 11, 5, 315, 532, 50118, 36590, 1033, 8, 6609, 2121, 11, 28955, 50118, 1646, 3079, 22883, 11, 188, 1625, 2] 1\n",
      "['[CLS]', '<0x81>', '▁temperatures', '▁south', '▁Methods', '▁prose', '▁Without', '<0x02>', '<0x07>', '▁temperatures', '▁south', '<0x02>', '<0xB8>', '▁happened', '<0x02>', '<0x11>', 'F', '<0x07>', '▁Evo', '<0x00>', '▁wish', '<0x51>', '<0x11>', '▁Italian', '<0x0B>', '<0x01>', '▁number', '▁marker', '<0x05>', '▁Ros', '▁keto', '<0x07>', '▁Hours', '<0x00>', 'wrenching', 'wrenching', '<0xEF>', '<0x1E>', '<0x3F>', '<0x35>', '▁run', '<0x15>', '<0x01>', '▁temperatures', '▁south', '19', 'light', '<0x04>', '<0x15>', '<0x01>', '19', '▁ago', '<0x00>', 'wrenching', 'wrenching', '<0xEF>', '<0x0C>', '<0x01>', '<0x8C>', '▁horses', '▁non', '<0x07>', '▁temperatures', '▁south', '<0x02>', '<0x04>', '<0x11>', '▁-', '<0x15>', '<0x06>', '▁With', '▁banned', '<0x05>', '<0xB8>', '▁bend', '▁aren', '<0x1A>', '<0xB8>', '▁happened', '▁listening', '▁Cuomo', '<0xFB>', '▁evident', '<0x00>', 'wrenching', 'wrenching', 'ebel', 'wrenching', 'wrenching', '▁Richards', '▁marker', '<0x05>', '▁Ros', '▁keto', '<0x07>', '▁Practice', 'cross', '▁take', '<0x02>', '<0xB8>', '▁happened', 'wrenching', 'bath', '<0xFA>', '▁needed', '▁Chef', '<0x07>', '<0x01>', '▁his', '▁against', 'wrenching', '▁anxiously', '▁weeks', '<0x04>', 'url', '▁listed', '<0x07>', '▁Evo', 'wrenching', '▁join', '▁extended', '▁artisan', '<0x07>', '<0xB8>', '▁happened', '[SEP]'] 2\n",
      "['[CLS]', '▁COD', '<0x71>', '▁90', '▁amendments', '[MASK]', '▁architects', '<0x16>', '[MASK]', '▁tidbits', '<0x31>', '▁forward', '<0x11>', '[MASK]', '<0x47>', '▁extra', '<0x03>', '▁sweep', '▁bed', ',', '▁90', '[MASK]', '▁things', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 1236, 0, 0, 2156, 0, 0, 0, 0, 295, 0, 0, 0, 0, 0, 0, 0, 1169, 0, 0, 0] target_labels\n",
      "[1, 49519, 117, 2156, 12801, 128000, 11867, 26, 128000, 45518, 53, 939, 21, 128000, 75, 1227, 7, 12908, 1518, 261, 2156, 128000, 479, 12801, 2] masked_sample ids\n",
      "[1, 405, 128, 29, 2933, 25, 7105, 2156, 53, 14, 128, 29, 5, 275, 86, 7, 356, 23, 5, 2690, 479, 2] 1\n",
      "['[CLS]', '▁such', '<0x7C>', '<0x19>', '▁mouth', '<0x15>', '▁vessel', '▁90', '<0x31>', '<0x0A>', '<0x7C>', '<0x19>', '<0x01>', '▁with', '<0x52>', '<0x03>', '▁any', '<0x13>', '<0x01>', '▁broken', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁such', '<0x7C>', '<0x19>', '▁mouth', '[MASK]', '▁vessel', '▁90', '<0x31>', '<0x0A>', '<0x7C>', '<0x19>', '[MASK]', '▁with', '<0x52>', '<0x03>', '[MASK]', '<0x13>', '<0x01>', '▁broken', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 356, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 405, 128, 29, 2933, 128000, 7105, 2156, 53, 14, 128, 29, 128000, 275, 86, 7, 128000, 23, 5, 2690, 479, 2] masked_sample ids\n",
      "[1, 267, 3361, 1410, 1706, 69, 479, 2] 1\n",
      "['[CLS]', '▁in', '▁submit', '▁app', '▁condition', '<0x41>', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁in', '▁submit', '[MASK]', '▁condition', '<0x41>', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 1410, 0, 0, 0, 0] target_labels\n",
      "[1, 267, 3361, 128000, 1706, 69, 479, 2] masked_sample ids\n",
      "[1, 700, 74, 5478, 68, 1878, 38187, 260, 1932, 2156, 2540, 2156, 5, 28894, 2140, 26, 2156, 8, 939, 880, 7, 5170, 141, 203, 55, 47510, 37, 429, 1994, 479, 2] 1\n",
      "['[CLS]', '▁went', '<0x46>', '▁accommodate', '<0x40>', '▁Act', 'Connell', '.', '▁opened', '▁90', '▁conversation', '▁90', '<0x01>', '▁Vander', '▁manager', '<0x16>', '▁90', '<0x04>', '▁forward', '▁among', '<0x03>', '▁ranging', '<0x89>', '<0xC7>', '<0x33>', '▁hybridization', '<0x21>', '▁&', '▁Air', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '<0x46>', '▁accommodate', '<0x40>', '▁Act', 'Connell', '.', '▁opened', '▁90', '▁conversation', '▁90', '<0x01>', '▁Vander', '▁manager', '<0x16>', '▁90', '[MASK]', '▁forward', '▁among', '<0x03>', '[MASK]', '<0x89>', '<0xC7>', '<0x33>', '▁hybridization', '<0x21>', '▁&', '▁Air', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 700, 0, 0, 0, 0, 0, 260, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 5170, 0, 0, 0, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 128000, 74, 5478, 68, 1878, 38187, 260, 1932, 2156, 2540, 2156, 5, 28894, 2140, 26, 2156, 128000, 939, 880, 7, 128000, 141, 203, 55, 47510, 37, 429, 1994, 128000, 2] masked_sample ids\n",
      "[{'input_ids': [1, 49519, 117, 2156, 12801, 128000, 11867, 26, 128000, 45518, 53, 939, 21, 128000, 75, 1227, 7, 12908, 1518, 261, 2156, 128000, 479, 12801, 2], 'labels': [0, 0, 0, 0, 0, 1236, 0, 0, 2156, 0, 0, 0, 0, 295, 0, 0, 0, 0, 0, 0, 0, 1169, 0, 0, 0]}, {'input_ids': [1, 405, 128, 29, 2933, 128000, 7105, 2156, 53, 14, 128, 29, 128000, 275, 86, 7, 128000, 23, 5, 2690, 479, 2], 'labels': [0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 356, 0, 0, 0, 0, 0]}, {'input_ids': [1, 267, 3361, 128000, 1706, 69, 479, 2], 'labels': [0, 0, 0, 1410, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 74, 5478, 68, 1878, 38187, 260, 1932, 2156, 2540, 2156, 5, 28894, 2140, 26, 2156, 128000, 939, 880, 7, 128000, 141, 203, 55, 47510, 37, 429, 1994, 128000, 2], 'labels': [0, 700, 0, 0, 0, 0, 0, 260, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 5170, 0, 0, 0, 0, 0, 0, 0, 479, 0]}] 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13237, 2] 1\n",
      "['[CLS]', '▁cooperative', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 13237, 0] target_labels\n",
      "[1, 128000, 2] masked_sample ids\n",
      "[1, 627, 652, 9, 10, 313, 1415, 159, 2115, 69, 2156, 8, 10, 251, 36393, 1382, 7, 1087, 1722, 31, 39, 5397, 479, 2] 1\n",
      "['[CLS]', '▁God', '▁says', '<0x05>', '<0x06>', '▁he', '▁tools', '<0x9B>', '▁Where', '<0x41>', '▁90', '<0x04>', '<0x06>', '<0xF7>', '▁Dalai', '▁benefits', '<0x03>', '▁focus', '▁Paul', '<0x1B>', '<0x23>', '▁MA', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁God', '▁says', '[MASK]', '<0x06>', '▁he', '▁tools', '<0x9B>', '[MASK]', '<0x41>', '▁90', '<0x04>', '<0x06>', '<0xF7>', '[MASK]', '▁benefits', '<0x03>', '▁focus', '▁Paul', '<0x1B>', '<0x23>', '[MASK]', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 9, 0, 0, 0, 0, 2115, 0, 0, 0, 0, 0, 36393, 0, 0, 0, 0, 0, 0, 5397, 0, 0] target_labels\n",
      "[1, 627, 652, 128000, 10, 313, 1415, 159, 128000, 69, 2156, 8, 10, 251, 128000, 1382, 7, 1087, 1722, 31, 39, 128000, 479, 2] masked_sample ids\n",
      "[1, 118, 1224, 160, 5, 2384, 8, 2468, 66, 10, 14165, 31, 5, 1980, 13235, 5219, 128, 29, 985, 1682, 6387, 62, 223, 5, 4000, 1312, 8, 2504, 24, 66, 81, 13235, 5219, 128, 29, 8416, 1026, 479, 2] 1\n",
      "['[CLS]', '<0x72>', '▁brand', '<0x9C>', '<0x01>', '▁Public', '<0x04>', '▁Foundation', '<0x3E>', '<0x06>', 'ú', '<0x1B>', '<0x01>', '▁status', 'fest', '▁concentration', '<0x7C>', '<0x19>', '▁role', '▁disease', '▁Friends', '<0x3A>', '<0xDB>', '<0x01>', '▁limits', '▁hands', '<0x04>', '▁proud', '<0x14>', '<0x3E>', '<0x4D>', 'fest', '▁concentration', '<0x7C>', '<0x19>', '▁Dental', '▁higher', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '<0x81>', '▁temperatures', '▁south', '[MASK]', '▁prose', '▁Without', '<0x02>', '<0x07>', '[MASK]', '▁south', '<0x02>', '<0xB8>', '▁happened', '<0x02>', '<0x11>', '▁Derma', '<0x07>', '▁Evo', '<0x00>', '▁wish', '<0x51>', '[MASK]', '▁Italian', '<0x0B>', '<0x01>', '▁number', '▁marker', '<0x05>', '▁Ros', '▁keto', '<0x07>', '▁Hours', '<0x00>', 'wrenching', '[MASK]', '<0xEF>', '<0x1E>', '[MASK]', '<0x35>', '▁run', '<0x15>', '<0x01>', '▁temperatures', '▁south', '19', '[MASK]', '<0x04>', '<0x15>', '<0x01>', '[MASK]', '▁ago', '<0x00>', 'wrenching', 'wrenching', '<0xEF>', '[MASK]', '<0x01>', '<0x8C>', '▁horses', '▁non', '<0x07>', '▁temperatures', '▁south', '<0x02>', '<0x04>', '<0x11>', '▁-', '[MASK]', '<0x06>', '▁With', '▁banned', '<0x05>', '[MASK]', '▁bend', '▁aren', '<0x1A>', '<0xB8>', '▁happened', '▁listening', '▁Cuomo', '<0xFB>', '▁evident', '<0x00>', '[MASK]', '[MASK]', 'ebel', 'wrenching', 'wrenching', '▁Richards', '▁marker', '<0x05>', '▁Ros', '[MASK]', '<0x07>', '▁Practice', 'cross', '▁take', '<0x02>', '<0xB8>', '▁happened', '[MASK]', 'bath', '<0xFA>', '▁needed', '▁Chef', '<0x07>', '<0x01>', '▁his', '▁against', 'wrenching', '▁anxiously', '▁weeks', '<0x04>', 'url', '▁listed', '<0x07>', '▁Evo', 'wrenching', '▁join', '▁extended', '▁artisan', '<0x07>', '<0xB8>', '▁happened', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 11660, 0, 0, 0, 0, 4743, 0, 0, 0, 0, 0, 0, 1490, 0, 0, 0, 0, 0, 21, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 67, 0, 0, 0, 0, 0, 0, 0, 6919, 0, 0, 0, 2573, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 188, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50118, 50118, 0, 0, 0, 0, 0, 0, 0, 28540, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 315, 0, 0, 36590, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 133, 4743, 2456, 128000, 16493, 4031, 6, 11, 128000, 2456, 6, 188, 1625, 6, 21, 50842, 11, 28955, 4, 1437, 85, 128000, 3147, 15, 5, 496, 10315, 9, 15541, 28540, 11, 11735, 4, 50118, 128000, 243, 34, 128000, 57, 684, 25, 5, 4743, 2456, 2573, 128000, 8, 25, 5, 128000, 824, 4, 50118, 50118, 243, 128000, 5, 144, 5395, 745, 11, 4743, 2456, 6, 8, 21, 341, 128000, 10, 559, 7648, 9, 128000, 10979, 1767, 30, 188, 1625, 3383, 27058, 255, 7790, 4, 128000, 128000, 49379, 50118, 50118, 18285, 10315, 9, 15541, 128000, 11, 6623, 16557, 413, 6, 188, 1625, 128000, 30597, 254, 858, 9437, 11, 5, 315, 532, 50118, 36590, 1033, 8, 6609, 2121, 11, 28955, 50118, 1646, 3079, 22883, 11, 188, 1625, 2] masked_sample ids\n",
      "[1, 34451, 728, 17066, 1550, 258, 1275, 17029, 8, 1357, 5, 909, 25606, 37, 16492, 5, 11822, 2382, 8, 7015, 355, 9893, 17705, 2156, 23845, 8, 5853, 31287, 385, 10155, 7, 5, 13223, 5120, 479, 2] 1\n",
      "['[CLS]', '▁Beans', '▁social', '▁Steps', '▁s', '<0xFE>', '▁hear', '▁revisions', '<0x04>', '▁Christmas', '<0x01>', '▁R', '▁marginalized', '<0x21>', '▁simulations', '<0x01>', '▁Coalition', '▁rooms', '<0x04>', '▁1988', '▁people', '▁swap', 'ended', '▁90', '▁foreground', '<0x04>', '▁Cambridge', '▁ipad', '▁after', '▁Ku', '<0x03>', '<0x01>', '▁Griffin', '▁depend', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁current', '<0x02>', '[MASK]', '<0x02>', '<0x8F>', '<0x21>', '<0x11>', '<0x25>', '▁recent', '<0x09>', '[MASK]', '▁Records', '<0x04>', '▁Potato', '<0x86>', '[MASK]', '<0x57>', '▁app', '<0x03>', '▁temporary', '<0x07>', '▁biopsy', '<0x02>', '<0x8F>', '<0x21>', '▁difficult', '▁explosion', '▁bactrim', '▁cemetery', '<0x0B>', 'any', '[MASK]', '▁until', '▁Cine', '▁keyboard', '<0x00>', '[MASK]', '▁furniture', '<0x09>', 'A', '<0x15>', '<0x25>', '▁USA', '<0x02>', '<0x31>', '<0x13>', '[MASK]', '▁breach', '<0x05>', '<0x01>', '▁June', '▁area', '[MASK]', '<0x43>', '▁sixth', '<0x73>', '[MASK]', '<0x02>', '<0x32>', '<0x34>', '▁before', '▁roughly', '[MASK]', '<0x01>', '▁businesses', '<0x04>', '▁June', '▁spinal', '<0x09>', '▁eczema', '<0x02>', '[MASK]', '▁goal', '<0x05>', '▁Verizon', '[MASK]', '<0x00>', '<0x57>', 'ü', '▁Programs', '<0xD5>', '[MASK]', '<0x02>', 'p', '<0x02>', '▁deeply', '<0x02>', '<0x04>', '[MASK]', '<0x02>', '[MASK]', '▁Because', '<0x06>', '▁himself', '<0x15>', '▁now', '▁existing', '▁automaker', '▁anti', '<0x07>', '▁exceeded', '[MASK]', 'wrenching', 'wrenching', '[MASK]', '▁credibility', '▁consent', '<0x06>', '▁High', '<0xD5>', '<0x01>', '▁there', '<0x05>', '▁Avengers', '▁Method', '[MASK]', '<0x57>', '▁easier', '<0x06>', '▁documentation', '▁marketing', '<0x03>', '▁daily', '<0x25>', '[MASK]', '▁topic', '▁urged', '[MASK]', '<0x01>', '▁temporary', 'ize', '<0x07>', '▁responds', '[MASK]', '<0x57>', '<0x4A>', '▁No', '<0x21>', '<0x46>', '▁contract', '<0x01>', '▁businesses', '▁area', '<0x07>', '▁To', '▁borrowing', '<0x02>', '▁gazing', '▁candidates', '▁tiny', '▁pageant', '<0x68>', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 886, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 4, 0, 0, 0, 4316, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 4743, 0, 0, 0, 0, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 6, 0, 0, 0, 10544, 0, 0, 0, 0, 0, 258, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 6046, 0, 0, 0, 0, 0, 903, 0, 0, 0, 0, 0, 0, 6300, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 39531, 0, 0, 0, 1418, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 490, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 763, 6, 128000, 6, 147, 37, 21, 41, 1031, 13, 128000, 6255, 8, 26923, 138, 128000, 91, 1410, 7, 4316, 11, 23102, 6, 147, 37, 1179, 9440, 100541, 13460, 15, 11771, 128000, 583, 33053, 6125, 4, 128000, 2075, 13, 558, 25, 41, 2222, 6, 53, 23, 128000, 7493, 9, 5, 1172, 537, 128000, 71, 6217, 119, 128000, 6, 54, 56, 416, 5288, 128000, 5, 1557, 8, 1172, 11097, 13, 28683, 6, 128000, 1238, 9, 13557, 128000, 4, 91, 18783, 11429, 217, 128000, 6, 1492, 6, 4264, 6, 8, 128000, 6, 128000, 1665, 10, 1385, 25, 394, 1759, 32196, 1688, 11, 12497, 128000, 50118, 50118, 128000, 10849, 4625, 10, 1418, 217, 5, 343, 9, 17720, 11567, 128000, 91, 1660, 10, 5265, 1305, 7, 1323, 41, 128000, 2270, 8322, 128000, 5, 4316, 5879, 11, 14873, 128000, 91, 78, 585, 37, 74, 1962, 5, 1557, 537, 11, 502, 14488, 6, 31993, 2961, 3262, 26682, 108, 2] masked_sample ids\n",
      "[1, 1725, 341, 7, 1482, 5, 1013, 22, 10653, 24427, 2193, 7936, 113, 10854, 2485, 202, 3311, 6, 53, 16, 1367, 4, 12897, 5634, 34, 117, 1400, 50, 1123, 1992, 6, 53, 473, 33, 65, 2352, 4, 12897, 5634, 16, 184, 7, 5, 3037, 6435, 22527, 5099, 7868, 19410, 1833, 1260, 8, 19037, 8185, 745, 36, 5488, 3960, 10, 650, 6084, 5560, 322, 1773, 13025, 6, 12897, 5634, 34, 57, 184, 7, 221, 858, 257, 12, 495, 2013, 6, 61, 817, 33535, 6315, 39404, 8, 5013, 13, 13945, 8, 7892, 5604, 8, 797, 4, 96, 7528, 6, 221, 858, 257, 12, 495, 2013, 56, 799, 1321, 4, 2477, 203, 9, 3037, 6435, 22527, 5099, 18, 25756, 16, 5627, 196, 8, 4371, 25, 233, 9, 226, 2160, 1536, 3343, 331, 5761, 50, 4367, 331, 2436, 24380, 440, 4, 23006, 4, 4367, 18, 194, 14275, 8, 177, 8952, 32, 2312, 6, 8, 650, 12, 8056, 24829, 154, 1414, 535, 11, 5, 25756, 452, 4, 12897, 5634, 34, 65, 794, 15466, 6, 11, 2] 1\n",
      "['[CLS]', '▁reasons', '▁-', '<0x03>', '▁California', '<0x01>', '▁inside', '<0x12>', '▁introduces', '▁Kits', '▁relevant', '▁Race', '<0x6D>', '▁imperative', '▁investigation', '<0xC6>', '▁Boston', '<0x02>', '<0x31>', '<0x0C>', '▁tried', '<0x00>', '▁proceeding', '▁walks', '<0x1E>', '<0x71>', '▁trip', '<0x2E>', '▁popular', '▁presented', '<0x02>', '<0x31>', 'e', '<0x1D>', '<0x3D>', '▁comfort', '<0x00>', '▁proceeding', '▁walks', '<0x0C>', '<0xB4>', '<0x03>', '<0x01>', '▁2003', '▁pollution', 'Test', '▁Fair', '▁racial', '▁Swimming', '▁passed', '▁West', '<0x04>', '▁Emmy', '▁basics', '▁non', '<0x20>', '▁salary', '▁involves', '<0x06>', '▁called', '▁steam', '▁emphasis', '▁up', 'H', '▁religions', '<0x02>', '▁proceeding', '▁walks', '<0x1E>', '<0x35>', '<0xB4>', '<0x03>', '<0xD9>', '▁needed', '<0xFD>', '<0x08>', '▁family', '▁Apple', '<0x02>', '<0x39>', '▁quite', '▁acreage', '▁moisture', '▁Lowes', '<0x04>', '▁overcome', '<0x09>', 'ct', '<0x04>', '▁Fortunately', '▁disorder', '<0x04>', '▁study', '<0x00>', '<0x5C>', '▁Excellent', '<0x02>', '<0xD9>', '▁needed', '<0xFD>', '<0x08>', '▁family', '▁Apple', '<0x34>', '▁learn', '▁link', '<0x00>', '▁drink', '<0xC7>', '<0x05>', '▁2003', '▁pollution', 'Test', '▁Fair', '<0x0E>', '▁lighthouse', '<0x0C>', '▁rail', '<0xC0>', '<0x04>', '▁tagged', '<0x15>', '<0xE5>', '<0x05>', '<0xDE>', '14', '▁places', '▁everyday', '▁been', '▁offense', '<0x2E>', '▁studying', '▁been', '▁Me', '▁naughty', '%', '<0x00>', '▁precursor', '<0x00>', '▁studying', '<0x0E>', '<0xBE>', '▁petrol', '<0x04>', '<0xAD>', '▁shifting', '<0x1C>', '▁applied', '<0x02>', '<0x04>', '▁called', '<0x08>', '▁protests', '▁Bran', '<0x96>', '▁Once', '▁online', '<0x07>', '<0x01>', '▁lighthouse', 'a', '<0x00>', '▁proceeding', '▁walks', '<0x1E>', '<0x3D>', '▁pay', '▁Factor', '<0x02>', '<0x07>', '[SEP]'] 2\n",
      "['[CLS]', '<0x72>', '▁brand', '<0x9C>', '<0x01>', '▁Public', '[MASK]', '▁Foundation', '<0x3E>', '<0x06>', 'ú', '[MASK]', '<0x01>', '[MASK]', 'fest', '▁concentration', '<0x7C>', '<0x19>', '▁role', '▁disease', '▁Friends', '[MASK]', '<0xDB>', '<0x01>', '▁limits', '▁hands', '<0x04>', '▁proud', '<0x14>', '[MASK]', '<0x4D>', '▁Dandelion', '▁concentration', '<0x7C>', '<0x19>', '▁Dental', '▁higher', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 31, 0, 1980, 0, 0, 0, 0, 0, 0, 0, 62, 0, 0, 0, 0, 0, 0, 0, 66, 0, 13235, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 118, 1224, 160, 5, 2384, 128000, 2468, 66, 10, 14165, 128000, 5, 128000, 13235, 5219, 128, 29, 985, 1682, 6387, 128000, 223, 5, 4000, 1312, 8, 2504, 24, 128000, 81, 74519, 5219, 128, 29, 8416, 1026, 479, 2] masked_sample ids\n",
      "[1, 38542, 2156, 37, 26, 479, 2] 1\n",
      "['[CLS]', 'lid', '▁90', '<0x21>', '<0x16>', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '▁90', '<0x21>', '<0x16>', '▁things', '[SEP]'] masked_sample\n",
      "[0, 38542, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 128000, 2156, 37, 26, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 128000, 2], 'labels': [0, 13237, 0]}, {'input_ids': [1, 627, 652, 128000, 10, 313, 1415, 159, 128000, 69, 2156, 8, 10, 251, 128000, 1382, 7, 1087, 1722, 31, 39, 128000, 479, 2], 'labels': [0, 0, 0, 9, 0, 0, 0, 0, 2115, 0, 0, 0, 0, 0, 36393, 0, 0, 0, 0, 0, 0, 5397, 0, 0]}, {'input_ids': [1, 118, 1224, 160, 5, 2384, 128000, 2468, 66, 10, 14165, 128000, 5, 128000, 13235, 5219, 128, 29, 985, 1682, 6387, 128000, 223, 5, 4000, 1312, 8, 2504, 24, 128000, 81, 74519, 5219, 128, 29, 8416, 1026, 479, 2], 'labels': [0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 31, 0, 1980, 0, 0, 0, 0, 0, 0, 0, 62, 0, 0, 0, 0, 0, 0, 0, 66, 0, 13235, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 2156, 37, 26, 479, 2], 'labels': [0, 38542, 0, 0, 0, 0, 0]}] 4\n",
      "['[CLS]', '▁Beans', '▁social', '▁Steps', '[MASK]', '<0xFE>', '▁hear', '▁revisions', '<0x04>', '▁Christmas', '[MASK]', '▁R', '▁marginalized', '▁defrauding', '▁simulations', '<0x01>', '▁Coalition', '▁rooms', '<0x04>', '▁1988', '▁people', '▁swap', 'ended', '▁90', '[MASK]', '<0x04>', '▁Cambridge', '▁ipad', '▁after', '[MASK]', '<0x03>', '<0x01>', '▁Griffin', '▁depend', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 1550, 0, 0, 0, 0, 0, 5, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23845, 0, 0, 0, 0, 10155, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 34451, 728, 17066, 128000, 258, 1275, 17029, 8, 1357, 128000, 909, 25606, 94086, 16492, 5, 11822, 2382, 8, 7015, 355, 9893, 17705, 2156, 128000, 8, 5853, 31287, 385, 128000, 7, 5, 13223, 5120, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 405, 5658, 28, 3859, 662, 128000, 2], 'labels': [0, 0, 0, 0, 0, 0, 479, 0]}, {'input_ids': [1, 118, 19975, 14, 127, 128000, 21, 6827, 7, 39, 128000, 479, 2], 'labels': [0, 0, 0, 0, 0, 809, 0, 0, 0, 0, 356, 0, 0]}, {'input_ids': [1, 133, 4743, 2456, 128000, 16493, 4031, 6, 11, 128000, 2456, 6, 188, 1625, 6, 21, 50842, 11, 28955, 4, 1437, 85, 128000, 3147, 15, 5, 496, 10315, 9, 15541, 28540, 11, 11735, 4, 50118, 128000, 243, 34, 128000, 57, 684, 25, 5, 4743, 2456, 2573, 128000, 8, 25, 5, 128000, 824, 4, 50118, 50118, 243, 128000, 5, 144, 5395, 745, 11, 4743, 2456, 6, 8, 21, 341, 128000, 10, 559, 7648, 9, 128000, 10979, 1767, 30, 188, 1625, 3383, 27058, 255, 7790, 4, 128000, 128000, 49379, 50118, 50118, 18285, 10315, 9, 15541, 128000, 11, 6623, 16557, 413, 6, 188, 1625, 128000, 30597, 254, 858, 9437, 11, 5, 315, 532, 50118, 36590, 1033, 8, 6609, 2121, 11, 28955, 50118, 1646, 3079, 22883, 11, 188, 1625, 2], 'labels': [0, 0, 0, 0, 11660, 0, 0, 0, 0, 4743, 0, 0, 0, 0, 0, 0, 1490, 0, 0, 0, 0, 0, 21, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 67, 0, 0, 0, 0, 0, 0, 0, 6919, 0, 0, 0, 2573, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 188, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50118, 50118, 0, 0, 0, 0, 0, 0, 0, 28540, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 315, 0, 0, 36590, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 34451, 728, 17066, 128000, 258, 1275, 17029, 8, 1357, 128000, 909, 25606, 94086, 16492, 5, 11822, 2382, 8, 7015, 355, 9893, 17705, 2156, 128000, 8, 5853, 31287, 385, 128000, 7, 5, 13223, 5120, 479, 2], 'labels': [0, 0, 0, 0, 1550, 0, 0, 0, 0, 0, 5, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23845, 0, 0, 0, 0, 10155, 0, 0, 0, 0, 0, 0]}] 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8877, 128, 417, 1323, 27665, 13, 3630, 479, 2] 1\n",
      "['[CLS]', '▁82', '<0x7C>', '▁him', '▁daily', '▁Freud', '<0x09>', '▁scheme', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁82', '<0x7C>', '▁him', '[MASK]', '▁Freud', '<0x09>', '[MASK]', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 1323, 0, 0, 3630, 0, 0] target_labels\n",
      "[1, 8877, 128, 417, 128000, 27665, 13, 128000, 479, 2] masked_sample ids\n",
      "[1, 1694, 120, 7, 766, 106, 479, 12801, 2] 1\n",
      "['[CLS]', '▁surface', '<0x74>', '<0x03>', '▁companies', '<0x66>', '▁things', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '▁surface', '[MASK]', '<0x03>', '▁companies', '<0x66>', '▁things', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 0, 120, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 1694, 128000, 7, 766, 106, 479, 12801, 2] masked_sample ids\n",
      "[1, 2527, 79, 128, 417, 1613, 71, 5, 1149, 2864, 511, 11728, 16285, 2156, 475, 4917, 4490, 30, 5, 6112, 9, 5, 28292, 1197, 227, 5, 17873, 479, 2] 1\n",
      "['[CLS]', '▁recommended', '<0x4B>', '<0x7C>', '▁him', '▁commercial', '<0x43>', '<0x01>', '▁N', '▁effectively', '▁team', '▁Parish', '▁Drivers', '▁90', '▁three', '▁ear', '▁Senior', '<0x1A>', '<0x01>', '▁Channel', '<0x05>', '<0x01>', '▁overlooks', '▁code', '<0xDF>', '<0x01>', '▁gram', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁recommended', '<0x4B>', '[MASK]', '▁him', '▁commercial', '<0x43>', '<0x01>', '▁N', '▁effectively', '▁team', '▁Parish', '▁Drivers', '▁90', '▁three', '▁ear', '▁Senior', '<0x1A>', '<0x01>', '▁Channel', '[MASK]', '<0x01>', '▁overlooks', '▁code', '<0xDF>', '<0x01>', '▁gram', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 128, 0, 0, 0, 0, 1149, 0, 0, 0, 0, 2156, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 2527, 79, 128000, 417, 1613, 71, 5, 1149, 2864, 511, 11728, 16285, 2156, 475, 4917, 4490, 30, 5, 6112, 128000, 5, 28292, 1197, 227, 5, 17873, 479, 2] masked_sample ids\n",
      "[1, 3297, 1612, 12, 13283, 3143, 311, 12487, 229, 1210, 15, 5, 11700, 13, 10, 36477, 181, 1657, 695, 147, 37, 1487, 39, 36477, 181, 1657, 2417, 4, 91, 78, 1382, 11, 5, 7953, 9176, 4365, 564, 212, 23741, 3672, 6, 8, 172, 1770, 5, 165, 13, 10, 36477, 181, 1657, 2168, 11, 4141, 1588, 260, 4, 50118, 50118, 9962, 1808, 173, 34, 57, 2343, 11, 23767, 11, 19773, 8, 2734, 924, 4, 50118, 50118, 49379, 50118, 50118, 47380, 5678, 50118, 50118, 45743, 18002, 163, 1657, 998, 50118, 50118, 10050, 2238, 2734, 10374, 50118, 38043, 82, 50118, 22004, 9, 3113, 1716, 36, 26111, 82, 43, 50118, 10050, 2238, 40620, 1952, 2] 1\n",
      "['[CLS]', '▁ancient', '▁hotel', '<0x08>', 'Some', '▁improvement', '▁one', '▁bothered', '<0xE1>', '▁average', '<0x0B>', '<0x01>', '▁Cotton', '<0x09>', '<0x06>', 'oop', '<0xB1>', '▁schools', '▁past', '<0x8F>', '<0x21>', '▁paid', '<0x23>', 'oop', '<0xB1>', '▁schools', '▁plastic', '<0x00>', '<0x57>', '<0x4A>', '▁benefits', '<0x07>', '<0x01>', '▁dairy', '▁pillow', '04', '▁start', '<0xD0>', '▁Respect', '▁flexible', '<0x02>', '<0x04>', '<0xA8>', '▁et', '<0x01>', '<0xA1>', '<0x09>', '<0x06>', 'oop', '<0xB1>', '▁schools', '▁dedicated', '<0x07>', '▁killing', '▁bar', '.', '<0x00>', 'wrenching', 'wrenching', '▁notably', '▁strategy', '<0xA9>', '<0x1E>', '<0x35>', '▁award', '<0x07>', '▁Bulgarian', '<0x07>', '▁jo', '<0x04>', '▁university', '▁heart', '<0x00>', 'wrenching', 'wrenching', 'ebel', 'wrenching', 'wrenching', '▁ported', '▁neutral', 'wrenching', 'wrenching', 'Dar', 'please', '<0x9F>', '▁schools', '▁couple', 'wrenching', 'wrenching', '▁correlation', '▁meant', '▁university', 'Be', 'wrenching', '▁BNP', '<0x4E>', 'wrenching', '▁helmets', '<0x05>', '▁lighting', '▁Court', '<0x20>', '▁Loading', '<0x4E>', '<0x27>', 'wrenching', '▁correlation', '▁meant', 'soluble', '▁server', '[SEP]'] 2\n",
      "['[CLS]', '▁set', '▁Hydrating', '<0xAF>', '<0x68>', '▁giveaway', 'berry', '▁berth', '<0x68>', '▁bags', '<0x68>', '[MASK]', '<0x01>', '<0xC4>', '[MASK]', '▁', '▁limit', '▁30', '<0x1A>', '[MASK]', '▁do', '<0x02>', '<0x01>', '▁larger', '▁Atlantic', '▁This', '[MASK]', '<0x51>', '<0x11>', '▁30', '<0x0B>', '▁special', '<0xC8>', '<0x02>', '[MASK]', '<0x91>', '▁fixing', '<0x04>', '[MASK]', '▁vocals', '<0x00>', '▁children', '<0x06>', '▁comfortable', '[MASK]', '<0x4C>', '<0x67>', '▁soft', '<0x02>', '<0x26>', '▁limit', '▁Great', '<0x03>', '▁account', '[MASK]', '▁International', '<0x05>', '[MASK]', '▁tally', '▁flower', '<0x02>', '<0x7D>', '▁mining', '▁partially', '<0x13>', '▁wanted', '[MASK]', '<0x0B>', '<0x01>', '[MASK]', '<0xF4>', '▁problems', '▁could', '[MASK]', 'to', '▁bar', '<0x08>', '▁hamstring', 'Mail', '[MASK]', '<0x00>', '<0x10>', '<0x7D>', '▁Industrial', '<0x96>', '▁white', '<0x12>', '▁eroded', '[MASK]', '<0x6D>', '<0x5B>', '[MASK]', '<0x13>', '▁wanted', '▁intelligence', '<0x0B>', '<0x01>', '▁entertaining', '▁Coral', '▁Understanding', '▁storage', '<0x00>', 'wrenching', 'wrenching', 'rounder', '▁Robinson', '▁fossils', '<0x6D>', '▁Holidays', '<0x0B>', '▁all', '[MASK]', '▁Museum', '▁ketchup', '<0x97>', '<0x1F>', '▁generated', 'wrenching', '<0x6D>', '▁Quincy', '▁Chroma', '<0x05>', '[MASK]', '<0x20>', '<0x81>', '22', '▁rejuvenation', '▁outsourced', '<0x08>', '[MASK]', '<0x1F>', '▁City', 'wrenching', '<0x6D>', '▁eroded', '<0xAF>', '<0x68>', '▁ketchup', '<0x97>', '<0x1F>', '▁Alex', 'wrenching', '<0x6D>', '▁suggestions', '▁Wind', '<0x68>', '▁my', '[MASK]', '▁ketchup', '<0xC8>', '<0x1F>', '▁typically', 'wrenching', '<0x6D>', 'rau', '[MASK]', '<0xC8>', '<0x1F>', '▁cultural', '[MASK]', '<0x6D>', '▁family', '<0xD7>', '<0xAF>', '<0x68>', '▁Z', 'an', '▁ketchup', '[MASK]', '<0x1F>', '▁hardware', '[MASK]', '<0x6D>', '▁store', '<0x22>', '▁all', '▁1995', '<0x06>', '[MASK]', '▁ketchup', '<0xC8>', '<0x1F>', '▁cultural', 'wrenching', '<0x6D>', '▁output', '[MASK]', '<0x02>', '%', 'etz', '<0x02>', '%', '[MASK]', '▁ketchup', '<0xC8>', '<0x1F>', '▁speech', 'wrenching', '<0x6D>', '▁specific', '▁thread', '▁Fridays', '▁ketchup', '[MASK]', '<0x1F>', '[MASK]', 'wrenching', '<0x6D>', '▁Wildcats', '▁Clan', '<0xA2>', '▁whom', '▁ketchup', '[MASK]', '<0x1F>', '▁viewing', 'wrenching', '<0x6D>', '▁vows', '▁spot', '▁ketchup', '<0xBF>', '<0x1F>', '▁bars', '[MASK]', '<0x6D>', '▁set', '▁NOW', '<0xAF>', '[MASK]', '▁giveaway', '<0x02>', 'berry', '▁berth', '<0x68>', '▁bags', '<0x68>', '[MASK]', '<0xC8>', '<0x1F>', '▁volume', 'wrenching', '<0x6D>', '▁temperate', '▁Knowing', '▁pictures', '▁ketchup', '<0x97>', '<0x1F>', '▁museum', 'wrenching', '<0x6D>', '▁family', '<0xC0>', '▁commissioner', '▁ketchup', '<0xC8>', '<0x1F>', '▁Use', 'wrenching', 'wrenching', '<0x64>', '▁daisy', 'wrenching', '<0x6D>', '▁Holidays', '[SEP]'] masked_sample\n",
      "[0, 0, 9259, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 8, 0, 0, 0, 0, 11619, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 8148, 0, 0, 0, 6107, 0, 0, 0, 0, 0, 2453, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 4611, 0, 0, 0, 0, 0, 0, 0, 0, 2940, 0, 0, 3107, 0, 0, 0, 73, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 0, 0, 0, 179, 0, 0, 21174, 0, 0, 0, 0, 0, 0, 0, 0, 1634, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 329, 0, 0, 0, 0, 0, 0, 0, 0, 1342, 0, 16945, 0, 0, 0, 0, 0, 0, 195, 0, 0, 0, 0, 35436, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 9671, 0, 0, 0, 0, 0, 0, 0, 34133, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 9908, 0, 0, 0, 0, 0, 0, 0, 41385, 0, 0, 0, 0, 0, 34643, 0, 204, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0, 3079, 0, 0, 0, 0, 0, 0, 0, 204, 0, 0, 0, 0, 0, 0, 0, 195, 0, 0, 50118, 0, 0, 0, 0, 108, 0, 0, 0, 0, 0, 0, 0, 34133, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 487, 95337, 179, 108, 10862, 14208, 24276, 108, 3713, 108, 128000, 5, 200, 128000, 507, 2642, 703, 30, 128000, 333, 6, 5, 1821, 5637, 329, 128000, 85, 21, 703, 15, 779, 204, 6, 128000, 149, 9880, 8, 128000, 10023, 4, 572, 10, 1800, 128000, 80, 107, 2052, 6, 42, 2642, 1447, 7, 914, 128000, 1282, 9, 128000, 20914, 4611, 6, 129, 3723, 7520, 23, 849, 128000, 15, 5, 128000, 248, 947, 387, 128000, 725, 1588, 12, 30158, 19657, 128000, 4, 20, 129, 5966, 154, 881, 22, 35436, 128000, 113, 95, 128000, 23, 849, 3414, 15, 5, 6003, 16469, 10413, 1634, 4, 50118, 50118, 39901, 8118, 27882, 113, 16549, 15, 305, 128000, 2990, 34133, 155, 35, 3714, 50118, 113, 29390, 56029, 9, 128000, 36, 133, 2944, 35110, 30831, 12, 128000, 35, 844, 50118, 113, 35436, 179, 108, 34133, 155, 35, 4283, 50118, 113, 4148, 8318, 108, 312, 128000, 34133, 204, 35, 2518, 50118, 113, 43361, 128000, 204, 35, 2546, 128000, 113, 495, 219, 179, 108, 2548, 1398, 34133, 128000, 35, 3305, 128000, 113, 1106, 38, 305, 4987, 10, 128000, 34133, 204, 35, 2546, 50118, 113, 3084, 128000, 6, 440, 22916, 6, 440, 128000, 34133, 204, 35, 2890, 50118, 113, 996, 3676, 26859, 34133, 128000, 35, 128000, 50118, 113, 24514, 22191, 166, 2462, 34133, 128000, 35, 4540, 50118, 113, 22456, 1832, 34133, 195, 35, 4124, 128000, 113, 487, 9259, 179, 128000, 10862, 6, 14208, 24276, 108, 3713, 108, 128000, 204, 35, 2481, 50118, 113, 33177, 11101, 1631, 34133, 155, 35, 4419, 50118, 113, 495, 196, 14086, 34133, 204, 35, 1922, 50118, 50118, 104, 45598, 50118, 113, 16549, 2] masked_sample ids\n",
      "[1, 16424, 5, 313, 479, 2] 1\n",
      "['[CLS]', '▁amend', '<0x01>', '▁he', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '<0x01>', '▁he', '▁things', '[SEP]'] masked_sample\n",
      "[0, 16424, 0, 0, 0, 0] target_labels\n",
      "[1, 128000, 5, 313, 479, 2] masked_sample ids\n",
      "[1, 49519, 579, 36000, 17487, 12801, 2] 1\n",
      "['[CLS]', '▁COD', '▁why', '▁Bologna', 'Mart', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '▁why', '▁Bologna', 'Mart', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 49519, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 128000, 579, 36000, 17487, 12801, 2] masked_sample ids\n",
      "[{'input_ids': [1, 8877, 11541, 639, 69, 8, 128000, 8, 14454, 69, 865, 1335, 128000, 2], 'labels': [0, 0, 0, 0, 0, 0, 5699, 0, 0, 0, 0, 0, 479, 0]}, {'input_ids': [1, 487, 95337, 179, 108, 10862, 14208, 24276, 108, 3713, 108, 128000, 5, 200, 128000, 507, 2642, 703, 30, 128000, 333, 6, 5, 1821, 5637, 329, 128000, 85, 21, 703, 15, 779, 204, 6, 128000, 149, 9880, 8, 128000, 10023, 4, 572, 10, 1800, 128000, 80, 107, 2052, 6, 42, 2642, 1447, 7, 914, 128000, 1282, 9, 128000, 20914, 4611, 6, 129, 3723, 7520, 23, 849, 128000, 15, 5, 128000, 248, 947, 387, 128000, 725, 1588, 12, 30158, 19657, 128000, 4, 20, 129, 5966, 154, 881, 22, 35436, 128000, 113, 95, 128000, 23, 849, 3414, 15, 5, 6003, 16469, 10413, 1634, 4, 50118, 50118, 39901, 8118, 27882, 113, 16549, 15, 305, 128000, 2990, 34133, 155, 35, 3714, 50118, 113, 29390, 56029, 9, 128000, 36, 133, 2944, 35110, 30831, 12, 128000, 35, 844, 50118, 113, 35436, 179, 108, 34133, 155, 35, 4283, 50118, 113, 4148, 8318, 108, 312, 128000, 34133, 204, 35, 2518, 50118, 113, 43361, 128000, 204, 35, 2546, 128000, 113, 495, 219, 179, 108, 2548, 1398, 34133, 128000, 35, 3305, 128000, 113, 1106, 38, 305, 4987, 10, 128000, 34133, 204, 35, 2546, 50118, 113, 3084, 128000, 6, 440, 22916, 6, 440, 128000, 34133, 204, 35, 2890, 50118, 113, 996, 3676, 26859, 34133, 128000, 35, 128000, 50118, 113, 24514, 22191, 166, 2462, 34133, 128000, 35, 4540, 50118, 113, 22456, 1832, 34133, 195, 35, 4124, 128000, 113, 487, 9259, 179, 128000, 10862, 6, 14208, 24276, 108, 3713, 108, 128000, 204, 35, 2481, 50118, 113, 33177, 11101, 1631, 34133, 155, 35, 4419, 50118, 113, 495, 196, 14086, 34133, 204, 35, 1922, 50118, 50118, 104, 45598, 50118, 113, 16549, 2], 'labels': [0, 0, 9259, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 8, 0, 0, 0, 0, 11619, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 8148, 0, 0, 0, 6107, 0, 0, 0, 0, 0, 2453, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 4611, 0, 0, 0, 0, 0, 0, 0, 0, 2940, 0, 0, 3107, 0, 0, 0, 73, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 0, 0, 0, 179, 0, 0, 21174, 0, 0, 0, 0, 0, 0, 0, 0, 1634, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 329, 0, 0, 0, 0, 0, 0, 0, 0, 1342, 0, 16945, 0, 0, 0, 0, 0, 0, 195, 0, 0, 0, 0, 35436, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 9671, 0, 0, 0, 0, 0, 0, 0, 34133, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 9908, 0, 0, 0, 0, 0, 0, 0, 41385, 0, 0, 0, 0, 0, 34643, 0, 204, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0, 3079, 0, 0, 0, 0, 0, 0, 0, 204, 0, 0, 0, 0, 0, 0, 0, 195, 0, 0, 50118, 0, 0, 0, 0, 108, 0, 0, 0, 0, 0, 0, 0, 34133, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 5, 313, 479, 2], 'labels': [0, 16424, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 579, 36000, 17487, 12801, 2], 'labels': [0, 49519, 0, 0, 0, 0, 0]}] 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5632, 5, 155, 4, 288, 30193, 14228, 1792, 12839, 468, 401, 6, 5, 83, 33287, 8408, 9235, 6, 9219, 3202, 8, 935, 15053, 4, 4701, 415, 10447, 931, 1249, 15, 719, 361, 6, 8148, 8, 21, 4209, 19, 5, 15465, 5997, 29913, 4, 50118, 50118, 49379, 50118, 50118, 47380, 5678, 50140, 9206, 11579, 387, 35, 15465, 4701, 415, 2154, 281, 11, 4133, 359, 1012, 924, 50118, 4701, 415, 10447, 9732, 12920, 7086, 36, 1990, 10206, 2383, 41295, 5376, 12, 2989, 4701, 415, 2154, 281, 43, 50118, 50118, 104, 15021, 10447, 50118, 31440, 12, 10799, 1734, 50118, 500, 4352, 12, 13630, 12, 19306, 1734, 50118, 30238, 12, 10799, 1677, 50118, 35985, 12, 13630, 12, 19306, 1734, 50118, 1646, 541, 29, 1677, 50118, 1646, 1749, 29, 1677, 50118, 43545, 29, 1677, 50118, 41355, 29, 1677, 2] 1\n",
      "['[CLS]', '▁slide', '<0x01>', '<0x97>', '<0x00>', '▁at', '▁Pear', '▁doubles', '▁People', '▁advertised', '▁look', '▁because', '<0x02>', '<0x01>', '<0x4F>', '▁mermaid', '▁69', '▁formerly', '<0x02>', '▁dump', '▁expectations', '<0x04>', 'on', '▁distraction', '<0x00>', '▁List', 've', '▁overly', '▁behind', '▁leading', '<0x0B>', '▁control', '▁how', '<0x02>', 'person', '<0x04>', '<0x11>', '▁Bush', '<0x0F>', '<0x01>', '▁Rand', '▁suicide', '▁guaranteeing', '<0x00>', 'wrenching', 'wrenching', 'ebel', 'wrenching', 'wrenching', '▁ported', '▁neutral', '▁dietitian', '▁Privacy', '▁preferably', '▁could', '<0x1F>', '▁Rand', '▁List', 've', '▁previously', '▁are', '<0x07>', '▁indicate', '▁its', '▁anyone', '▁heart', 'wrenching', '▁List', 've', '▁overly', 'range', '▁coral', '▁nationwide', '<0x20>', '▁balance', '▁caution', '▁fee', '799', '▁succeed', '<0x08>', '▁license', '▁List', 've', '▁previously', '▁are', '<0x27>', 'wrenching', 'wrenching', '<0x64>', 'language', '▁overly', 'wrenching', '▁Invoice', '<0x08>', '▁WHAT', '▁See', 'wrenching', '▁including', '▁admit', '<0x08>', '▁bowls', '<0x08>', '▁emerges', '▁See', 'wrenching', 'evo', '<0x08>', '▁WHAT', '▁cash', 'wrenching', '▁Goff', '<0x08>', '▁bowls', '<0x08>', '▁emerges', '▁See', 'wrenching', '▁join', '▁again', '<0x19>', '▁cash', 'wrenching', '▁join', '▁James', '<0x19>', '▁cash', 'wrenching', '▁FPGA', '<0x19>', '▁cash', 'wrenching', '▁crepe', '<0x19>', '▁cash', '[SEP]'] 2\n",
      "['[CLS]', '▁reasons', '▁-', '<0x03>', '▁California', '<0x01>', '[MASK]', '<0x12>', '[MASK]', '▁Kits', '▁relevant', '▁Race', '<0x6D>', '▁imperative', '[MASK]', '<0xC6>', '▁Boston', '<0x02>', '<0x31>', '<0x0C>', '▁tried', '<0x00>', '▁proceeding', '[MASK]', '<0x1E>', '<0x71>', '▁trip', '<0x2E>', '▁popular', '▁presented', '[MASK]', '[MASK]', 'e', '<0x1D>', '<0x3D>', '▁comfort', '<0x00>', '▁proceeding', '▁walks', '<0x0C>', '<0xB4>', '<0x03>', '[MASK]', '▁2003', '▁pollution', 'Test', '[MASK]', '▁racial', '▁Swimming', '▁passed', '[MASK]', '<0x04>', '▁Emmy', '▁basics', '▁non', '<0x20>', '▁salary', '[MASK]', '<0x06>', '▁called', '▁steam', '[MASK]', '▁up', 'H', '▁religions', '<0x02>', '▁proceeding', '▁walks', '[MASK]', '<0x35>', '<0xB4>', '<0x03>', '<0xD9>', '▁needed', '<0xFD>', '<0x08>', '▁family', '▁Apple', '[MASK]', '<0x39>', '▁quite', '▁acreage', '▁moisture', '▁Lowes', '<0x04>', '▁overcome', '<0x09>', '[MASK]', '<0x04>', '▁Fortunately', '▁disorder', '<0x04>', '▁study', '[MASK]', '<0x5C>', '▁Excellent', '<0x02>', '[MASK]', '▁needed', '<0xFD>', '<0x08>', '▁family', '▁Apple', '<0x34>', '▁learn', '▁link', '<0x00>', '[MASK]', '<0xC7>', '<0x05>', '▁2003', '▁pollution', 'Test', '[MASK]', '<0x0E>', '[MASK]', '<0x0C>', '▁rail', '<0xC0>', '<0x04>', '▁tagged', '[MASK]', '<0xE5>', '<0x05>', '<0xDE>', '14', '▁places', '▁everyday', '▁been', '▁offense', '<0x2E>', '▁studying', '▁been', '▁Me', '[MASK]', '%', '<0x00>', '▁precursor', '<0x00>', '▁studying', '<0x0E>', '<0xBE>', '▁Flowing', '<0x04>', '<0xAD>', '[MASK]', '<0x1C>', '▁applied', '<0x02>', '<0x04>', '▁called', '<0x08>', '▁protests', '▁Bran', '<0x96>', '▁Once', '[MASK]', '<0x07>', '<0x01>', '▁lighthouse', 'a', '<0x00>', '▁proceeding', '▁walks', '<0x1E>', '<0x3D>', '▁pay', '▁Factor', '<0x02>', '<0x07>', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 0, 1013, 0, 10653, 0, 0, 0, 0, 0, 2485, 0, 0, 0, 0, 0, 0, 0, 0, 5634, 0, 0, 0, 0, 0, 0, 6, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5099, 0, 0, 0, 1260, 0, 0, 0, 0, 0, 0, 3960, 0, 0, 0, 5560, 0, 0, 0, 0, 0, 0, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 817, 0, 0, 0, 0, 0, 0, 13945, 0, 0, 0, 0, 0, 4, 0, 0, 0, 221, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2477, 0, 0, 0, 0, 0, 5099, 0, 25756, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 0, 331, 0, 0, 0, 0, 0, 24380, 0, 0, 0, 0, 0, 0, 0, 14275, 0, 0, 8952, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 535, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 1725, 341, 7, 1482, 5, 128000, 22, 128000, 24427, 2193, 7936, 113, 10854, 128000, 202, 3311, 6, 53, 16, 1367, 4, 12897, 128000, 34, 117, 1400, 50, 1123, 1992, 128000, 128000, 473, 33, 65, 2352, 4, 12897, 5634, 16, 184, 7, 128000, 3037, 6435, 22527, 128000, 7868, 19410, 1833, 128000, 8, 19037, 8185, 745, 36, 5488, 128000, 10, 650, 6084, 128000, 322, 1773, 13025, 6, 12897, 5634, 128000, 57, 184, 7, 221, 858, 257, 12, 495, 2013, 128000, 61, 817, 33535, 6315, 39404, 8, 5013, 13, 128000, 8, 7892, 5604, 8, 797, 128000, 96, 7528, 6, 128000, 858, 257, 12, 495, 2013, 56, 799, 1321, 4, 128000, 203, 9, 3037, 6435, 22527, 128000, 18, 128000, 16, 5627, 196, 8, 4371, 128000, 233, 9, 226, 2160, 1536, 3343, 331, 5761, 50, 4367, 331, 2436, 128000, 440, 4, 23006, 4, 4367, 18, 194, 102956, 8, 177, 128000, 32, 2312, 6, 8, 650, 12, 8056, 24829, 154, 1414, 128000, 11, 5, 25756, 452, 4, 12897, 5634, 34, 65, 794, 15466, 6, 11, 2] masked_sample ids\n",
      "[1, 8877, 21222, 162, 11, 101, 79, 341, 7, 77, 939, 21, 10, 410, 1816, 8, 27046, 127, 28702, 479, 2] 1\n",
      "['[CLS]', '▁82', '▁Qui', '<0x9E>', '<0x07>', '<0x61>', '<0x4B>', '▁-', '<0x03>', '<0x49>', '▁forward', '<0x11>', '<0x06>', '▁best', '▁daughter', '<0x04>', '▁Berger', '<0x7B>', 'CW', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁ancient', '▁hotel', '<0x08>', '[MASK]', '▁improvement', '▁one', '▁bothered', '<0xE1>', '▁average', '[MASK]', '<0x01>', '▁Cotton', '<0x09>', '<0x06>', 'oop', '<0xB1>', '▁schools', 'ccio', '<0x8F>', '<0x21>', '▁paid', '<0x23>', '[MASK]', '<0xB1>', '▁schools', '▁plastic', '<0x00>', '<0x57>', '<0x4A>', '▁benefits', '[MASK]', '<0x01>', '▁dairy', '▁pillow', '04', '▁start', '<0xD0>', '▁Respect', '[MASK]', '<0x02>', '<0x04>', '<0xA8>', '▁et', '[MASK]', '<0xA1>', '<0x09>', '<0x06>', 'oop', '<0xB1>', '[MASK]', '▁dedicated', '<0x07>', '▁killing', '▁bar', '.', '[MASK]', 'wrenching', 'wrenching', '▁notably', '▁strategy', '<0xA9>', '<0x1E>', '<0x35>', '▁award', '[MASK]', '▁Bulgarian', '<0x07>', '[MASK]', '<0x04>', '▁university', '▁heart', '<0x00>', '[MASK]', 'wrenching', 'ebel', 'wrenching', 'wrenching', '▁ported', '▁neutral', 'wrenching', '[MASK]', 'Dar', 'please', '<0x9F>', '▁schools', '▁couple', 'wrenching', '[MASK]', '▁correlation', '▁meant', '▁university', 'Be', 'wrenching', '▁BNP', '[MASK]', 'wrenching', '▁helmets', '<0x05>', '▁lighting', '▁Court', '[MASK]', '▁Loading', '<0x4E>', '<0x27>', 'wrenching', '▁correlation', '▁meant', 'soluble', '▁server', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 13283, 0, 0, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 695, 0, 0, 0, 0, 36477, 0, 0, 0, 0, 91, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 3672, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1657, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 19773, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 82, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 3297, 1612, 12, 128000, 3143, 311, 12487, 229, 1210, 128000, 5, 11700, 13, 10, 36477, 181, 1657, 71751, 147, 37, 1487, 39, 128000, 181, 1657, 2417, 4, 91, 78, 1382, 128000, 5, 7953, 9176, 4365, 564, 212, 23741, 128000, 6, 8, 172, 1770, 128000, 165, 13, 10, 36477, 181, 128000, 2168, 11, 4141, 1588, 260, 128000, 50118, 50118, 9962, 1808, 173, 34, 57, 2343, 128000, 23767, 11, 128000, 8, 2734, 924, 4, 128000, 50118, 49379, 50118, 50118, 47380, 5678, 50118, 128000, 45743, 18002, 163, 1657, 998, 50118, 128000, 10050, 2238, 2734, 10374, 50118, 38043, 128000, 50118, 22004, 9, 3113, 1716, 128000, 26111, 82, 43, 50118, 10050, 2238, 40620, 1952, 2] masked_sample ids\n",
      "[{'input_ids': [1, 8877, 128, 417, 128000, 27665, 13, 128000, 479, 2], 'labels': [0, 0, 0, 0, 1323, 0, 0, 3630, 0, 0]}, {'input_ids': [1, 1694, 128000, 7, 766, 106, 479, 12801, 2], 'labels': [0, 0, 120, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 2527, 79, 128000, 417, 1613, 71, 5, 1149, 2864, 511, 11728, 16285, 2156, 475, 4917, 4490, 30, 5, 6112, 128000, 5, 28292, 1197, 227, 5, 17873, 479, 2], 'labels': [0, 0, 0, 128, 0, 0, 0, 0, 1149, 0, 0, 0, 0, 2156, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 3297, 1612, 12, 128000, 3143, 311, 12487, 229, 1210, 128000, 5, 11700, 13, 10, 36477, 181, 1657, 71751, 147, 37, 1487, 39, 128000, 181, 1657, 2417, 4, 91, 78, 1382, 128000, 5, 7953, 9176, 4365, 564, 212, 23741, 128000, 6, 8, 172, 1770, 128000, 165, 13, 10, 36477, 181, 128000, 2168, 11, 4141, 1588, 260, 128000, 50118, 50118, 9962, 1808, 173, 34, 57, 2343, 128000, 23767, 11, 128000, 8, 2734, 924, 4, 128000, 50118, 49379, 50118, 50118, 47380, 5678, 50118, 128000, 45743, 18002, 163, 1657, 998, 50118, 128000, 10050, 2238, 2734, 10374, 50118, 38043, 128000, 50118, 22004, 9, 3113, 1716, 128000, 26111, 82, 43, 50118, 10050, 2238, 40620, 1952, 2], 'labels': [0, 0, 0, 0, 13283, 0, 0, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 695, 0, 0, 0, 0, 36477, 0, 0, 0, 0, 91, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 3672, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1657, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 19773, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 82, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0]}] 4\n",
      "['[CLS]', '▁82', '▁Qui', '<0x9E>', '<0x07>', '[MASK]', '<0x4B>', '▁-', '[MASK]', '<0x49>', '▁forward', '<0x11>', '<0x06>', '▁best', '▁daughter', '<0x04>', '▁Berger', '<0x7B>', 'non', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 101, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28702, 0, 0] target_labels\n",
      "[1, 8877, 21222, 162, 11, 128000, 79, 341, 128000, 77, 939, 21, 10, 410, 1816, 8, 27046, 127, 7731, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 4297, 117, 128000, 3422, 479, 2], 'labels': [0, 0, 0, 55, 0, 0, 0]}, {'input_ids': [1, 763, 6, 128000, 6, 147, 37, 21, 41, 1031, 13, 128000, 6255, 8, 26923, 138, 128000, 91, 1410, 7, 4316, 11, 23102, 6, 147, 37, 1179, 9440, 100541, 13460, 15, 11771, 128000, 583, 33053, 6125, 4, 128000, 2075, 13, 558, 25, 41, 2222, 6, 53, 23, 128000, 7493, 9, 5, 1172, 537, 128000, 71, 6217, 119, 128000, 6, 54, 56, 416, 5288, 128000, 5, 1557, 8, 1172, 11097, 13, 28683, 6, 128000, 1238, 9, 13557, 128000, 4, 91, 18783, 11429, 217, 128000, 6, 1492, 6, 4264, 6, 8, 128000, 6, 128000, 1665, 10, 1385, 25, 394, 1759, 32196, 1688, 11, 12497, 128000, 50118, 50118, 128000, 10849, 4625, 10, 1418, 217, 5, 343, 9, 17720, 11567, 128000, 91, 1660, 10, 5265, 1305, 7, 1323, 41, 128000, 2270, 8322, 128000, 5, 4316, 5879, 11, 14873, 128000, 91, 78, 585, 37, 74, 1962, 5, 1557, 537, 11, 502, 14488, 6, 31993, 2961, 3262, 26682, 108, 2], 'labels': [0, 0, 0, 886, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 4, 0, 0, 0, 4316, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 4743, 0, 0, 0, 0, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 6, 0, 0, 0, 10544, 0, 0, 0, 0, 0, 258, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 6046, 0, 0, 0, 0, 0, 903, 0, 0, 0, 0, 0, 0, 6300, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 39531, 0, 0, 0, 1418, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 490, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 1725, 341, 7, 1482, 5, 128000, 22, 128000, 24427, 2193, 7936, 113, 10854, 128000, 202, 3311, 6, 53, 16, 1367, 4, 12897, 128000, 34, 117, 1400, 50, 1123, 1992, 128000, 128000, 473, 33, 65, 2352, 4, 12897, 5634, 16, 184, 7, 128000, 3037, 6435, 22527, 128000, 7868, 19410, 1833, 128000, 8, 19037, 8185, 745, 36, 5488, 128000, 10, 650, 6084, 128000, 322, 1773, 13025, 6, 12897, 5634, 128000, 57, 184, 7, 221, 858, 257, 12, 495, 2013, 128000, 61, 817, 33535, 6315, 39404, 8, 5013, 13, 128000, 8, 7892, 5604, 8, 797, 128000, 96, 7528, 6, 128000, 858, 257, 12, 495, 2013, 56, 799, 1321, 4, 128000, 203, 9, 3037, 6435, 22527, 128000, 18, 128000, 16, 5627, 196, 8, 4371, 128000, 233, 9, 226, 2160, 1536, 3343, 331, 5761, 50, 4367, 331, 2436, 128000, 440, 4, 23006, 4, 4367, 18, 194, 102956, 8, 177, 128000, 32, 2312, 6, 8, 650, 12, 8056, 24829, 154, 1414, 128000, 11, 5, 25756, 452, 4, 12897, 5634, 34, 65, 794, 15466, 6, 11, 2], 'labels': [0, 0, 0, 0, 0, 0, 1013, 0, 10653, 0, 0, 0, 0, 0, 2485, 0, 0, 0, 0, 0, 0, 0, 0, 5634, 0, 0, 0, 0, 0, 0, 6, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5099, 0, 0, 0, 1260, 0, 0, 0, 0, 0, 0, 3960, 0, 0, 0, 5560, 0, 0, 0, 0, 0, 0, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 817, 0, 0, 0, 0, 0, 0, 13945, 0, 0, 0, 0, 0, 4, 0, 0, 0, 221, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2477, 0, 0, 0, 0, 0, 5099, 0, 25756, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 0, 331, 0, 0, 0, 0, 0, 24380, 0, 0, 0, 0, 0, 0, 0, 14275, 0, 0, 8952, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 535, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 8877, 21222, 162, 11, 128000, 79, 341, 128000, 77, 939, 21, 10, 410, 1816, 8, 27046, 127, 7731, 479, 2], 'labels': [0, 0, 0, 0, 0, 101, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28702, 0, 0]}] 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 500, 260, 1073, 8849, 38, 16, 10, 435, 709, 1803, 14, 4620, 41, 6833, 2757, 11, 9462, 1073, 8849, 28764, 9, 7157, 493, 1418, 11, 5, 1362, 194, 9, 580, 7104, 4, 50118, 50118, 20981, 10486, 50118, 725, 873, 1452, 7748, 1437, 16, 2034, 23, 479, 50118, 50118, 500, 260, 1073, 8849, 38, 7522, 11700, 16, 43490, 30, 15803, 8467, 3644, 7522, 11700, 11, 5, 1926, 6, 9462, 1073, 8849, 3082, 7522, 11700, 11, 5, 3017, 6, 20009, 417, 11695, 7522, 11700, 11, 5, 2077, 8, 8550, 1588, 710, 7522, 11700, 8, 4317, 12969, 298, 7522, 11700, 11, 41598, 4147, 352, 1418, 420, 5, 41598, 4147, 352, 1995, 11, 5, 3072, 4, 50118, 50118, 487, 20329, 1418, 16, 2260, 70, 13996, 2617, 35512, 6480, 7, 5, 3017, 9, 41598, 4147, 352, 1995, 6, 8094, 684, 25, 5371, 1073, 853, 20206, 4, 20, 70, 13996, 2617, 35512, 32, 847, 420, 30, 215, 43506, 5119, 25, 12656, 1097, 118, 6, 732, 8629, 118, 8, 28194, 1908, 3648, 4, 590, 209, 12323, 562, 11052, 5357, 62, 6, 12530, 32, 10, 16331, 1905, 4, 50118, 50118, 500, 260, 1073, 8849, 38, 7522, 11700, 34, 41, 443, 9, 17445, 4, 4540, 50141, 7203, 176, 4, 85, 34, 112, 5730, 611, 857, 415, 579, 2] 1\n",
      "['[CLS]', '▁including', '.', '▁six', '▁hint', '<0x22>', '<0x0C>', '<0x06>', '1', '▁season', 'nd', '<0x0A>', '▁struggling', '<0x25>', 'page', '▁telling', '<0x07>', 'ons', '▁six', '▁hint', '▁Undergraduate', '<0x05>', '▁assists', '▁better', '▁High', '<0x07>', '<0x01>', '▁track', '<0xBE>', '<0x05>', '▁money', '▁conditioning', '<0x00>', 'wrenching', 'wrenching', '▁Identification', '▁sexually', 'wrenching', 'to', '▁probably', '▁blood', '▁Grade', '▁wish', '<0x0C>', '▁tips', '<0x13>', '▁things', 'wrenching', 'wrenching', '▁including', '.', '▁six', '▁hint', '<0x22>', '▁audit', '▁Cotton', '<0x0C>', '▁Reproductive', '<0x1A>', '▁computational', '▁Floor', '▁Jim', '▁audit', '▁Cotton', '<0x07>', '<0x01>', '▁warm', '<0x02>', 'ons', '▁six', '▁hint', '▁messages', '▁audit', '▁Cotton', '<0x07>', '<0x01>', '▁procedure', '<0x02>', '▁augmented', '▁him', 'three', '▁audit', '▁Cotton', '<0x07>', '<0x01>', '▁Over', '<0x04>', '▁pole', '▁bar', '▁price', '▁audit', '▁Cotton', '<0x04>', '▁hanging', '▁penny', '▁not', '▁audit', '▁Cotton', '<0x07>', '▁Phen', 'ma', '▁into', '▁High', '▁But', '<0x01>', '▁Phen', 'ma', '▁into', '▁Art', '<0x07>', '<0x01>', '▁successfully', '<0x00>', 'wrenching', 'wrenching', '▁set', '▁athletics', '▁High', '<0x0C>', '▁species', '<0x42>', '▁Louise', '▁push', '▁py', '▁arrange', '<0x03>', '<0x01>', '▁procedure', '<0x05>', '▁Phen', 'ma', '▁into', '▁Art', '<0x02>', '▁ridiculous', '▁run', '<0x15>', '▁instruction', '▁six', '▁child', '▁crave', '<0x00>', '<0x10>', '<0x42>', '▁Louise', '▁push', '▁py', '<0x1C>', '▁various', '▁But', '<0x1A>', '<0xD3>', '▁Medication', '▁roots', '<0x15>', '▁CRM', '▁House', '<0x72>', '<0x02>', '▁told', '▁Template', '<0x72>', '<0x04>', '▁favoured', '▁cards', '▁reputation', '<0x00>', '▁didn', '<0xCD>', '▁elastic', '▁looking', 'See', '▁waves', '<0x3A>', '<0x02>', '▁hay', '<0x1C>', '<0x06>', '▁oversee', '▁item', '<0x00>', 'wrenching', 'wrenching', '▁including', '.', '▁six', '▁hint', '<0x22>', '▁audit', '▁Cotton', '<0x1E>', '<0x25>', '▁There', '<0x05>', '▁mist', '<0x00>', '▁viewing', '▁thefts', '▁consensus', '<0xAC>', '<0x00>', '<0x51>', '<0x1E>', '<0x6C>', 'tech', '▁often', '▁human', 've', '▁why', '[SEP]'] 2\n",
      "['[CLS]', '▁slide', '<0x01>', '[MASK]', '<0x00>', '▁at', '▁Pear', '▁doubles', '▁People', '[MASK]', '▁look', '▁because', '<0x02>', '<0x01>', '<0x4F>', '▁mermaid', '▁69', '▁formerly', '[MASK]', '▁dump', '▁expectations', '[MASK]', 'on', '▁distraction', '<0x00>', '▁List', 've', '▁overly', '▁behind', '[MASK]', '<0x0B>', '▁control', '▁how', '<0x02>', 'person', '<0x04>', '[MASK]', '▁Bush', '<0x0F>', '<0x01>', '[MASK]', '▁suicide', '▁guaranteeing', '<0x00>', 'wrenching', 'wrenching', 'ebel', 'wrenching', 'wrenching', '▁ported', '▁neutral', '▁dietitian', '[MASK]', '▁preferably', '▁could', '<0x1F>', '▁Rand', '▁List', '[MASK]', '▁previously', '▁are', '<0x07>', '▁indicate', '▁its', '[MASK]', '▁heart', 'wrenching', '▁List', 've', '[MASK]', 'range', '▁coral', '▁nationwide', '<0x20>', '▁balance', '▁caution', '▁fee', '799', '▁succeed', '[MASK]', '▁license', '▁List', 've', '▁previously', '▁are', '<0x27>', 'wrenching', 'wrenching', '[MASK]', 'language', '▁overly', 'wrenching', '[MASK]', '<0x08>', '▁WHAT', '▁See', 'wrenching', '▁including', '▁admit', '<0x08>', '▁bowls', '<0x08>', '[MASK]', '▁See', 'wrenching', '[MASK]', '<0x08>', '▁WHAT', '▁cash', 'wrenching', '▁Goff', '<0x08>', '▁bowls', '<0x08>', '▁emerges', '[MASK]', 'wrenching', '▁join', '▁again', '<0x19>', '▁cash', 'wrenching', '▁join', '▁James', '<0x19>', '▁cash', 'wrenching', '▁FPGA', '<0x19>', '▁cash', 'wrenching', '▁crepe', '<0x19>', '▁cash', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 155, 0, 0, 0, 0, 0, 12839, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 1249, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 15465, 0, 0, 0, 0, 0, 49379, 0, 0, 0, 0, 0, 9206, 0, 0, 0, 0, 0, 415, 0, 0, 0, 0, 0, 1012, 0, 0, 0, 0, 10447, 0, 0, 0, 0, 0, 10206, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 104, 0, 0, 0, 31440, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19306, 0, 0, 30238, 0, 0, 0, 0, 0, 0, 13630, 0, 0, 1734, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 5632, 5, 128000, 4, 288, 30193, 14228, 1792, 128000, 468, 401, 6, 5, 83, 33287, 8408, 9235, 128000, 9219, 3202, 128000, 935, 15053, 4, 4701, 415, 10447, 931, 128000, 15, 719, 361, 6, 8148, 8, 128000, 4209, 19, 5, 128000, 5997, 29913, 4, 50118, 50118, 49379, 50118, 50118, 47380, 5678, 50140, 128000, 11579, 387, 35, 15465, 4701, 128000, 2154, 281, 11, 4133, 359, 128000, 924, 50118, 4701, 415, 128000, 9732, 12920, 7086, 36, 1990, 10206, 2383, 41295, 5376, 128000, 2989, 4701, 415, 2154, 281, 43, 50118, 50118, 128000, 15021, 10447, 50118, 128000, 12, 10799, 1734, 50118, 500, 4352, 12, 13630, 12, 128000, 1734, 50118, 128000, 12, 10799, 1677, 50118, 35985, 12, 13630, 12, 19306, 128000, 50118, 1646, 541, 29, 1677, 50118, 1646, 1749, 29, 1677, 50118, 43545, 29, 1677, 50118, 41355, 29, 1677, 2] masked_sample ids\n",
      "[1, 179, 8, 66, 2156, 11, 8, 66, 2156, 454, 129, 5, 14291, 12213, 127, 10317, 1299, 588, 5988, 479, 2] 1\n",
      "['[CLS]', '<0xAF>', '<0x04>', '<0x3E>', '▁90', '<0x07>', '<0x04>', '<0x3E>', '▁90', '▁same', '<0x7D>', '<0x01>', '▁triumph', '▁enhancement', '<0x7B>', 'ren', '▁wrong', '▁local', '▁concluded', '▁things', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 1/25701300 [00:03<22070:21:27,  0.32it/s, v_num=43, loss_gen=136.0, loss_disc=0.899][1, 49519, 37, 128, 890, 1166, 24, 2156, 13071, 102, 479, 2] 1\n",
      "['[CLS]', '▁COD', '<0x21>', '<0x7C>', '▁pretty', '▁easily', '<0x14>', '▁90', '▁Hood', '<0x62>', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '<0xAF>', '<0x04>', '[MASK]', '▁90', '<0x07>', '<0x04>', 'march', '▁90', '▁same', '<0x7D>', '<0x01>', '▁triumph', '▁enhancement', '[MASK]', 'ren', '▁wrong', '▁local', '▁concluded', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 66, 0, 0, 0, 66, 0, 0, 0, 0, 0, 0, 127, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 179, 8, 128000, 2156, 11, 8, 54275, 2156, 454, 129, 5, 14291, 12213, 128000, 10317, 1299, 588, 5988, 479, 2] masked_sample ids\n",
      "[1, 242, 104, 2923, 40, 28, 6400, 30, 47421, 150, 23, 6553, 8307, 366, 35, 20, 5366, 1543, 29378, 29918, 16, 145, 2226, 30, 2627, 6, 9096, 3497, 6, 12587, 4, 20, 8873, 9399, 281, 29378, 29918, 16, 145, 2226, 30, 272, 1075, 27404, 8, 5323, 846, 18, 21624, 2757, 4, 1437, 50118, 50118, 40066, 19, 27994, 4048, 211, 11328, 913, 30702, 6, 47421, 189, 67, 2324, 10, 2898, 913, 368, 14, 74, 28, 10, 24633, 9, 5, 7090, 36241, 12, 261, 17550, 24625, 36, 3632, 100, 238, 15, 792, 5, 6280, 873, 13253, 176, 26236, 7728, 671, 2511, 4, 6109, 18, 211, 11328, 40, 836, 552, 10, 231, 791, 29378, 29918, 373, 42560, 100, 2562, 13345, 61, 16, 145, 2226, 30, 5, 3108, 5374, 3131, 36, 2336, 100, 43, 7, 2274, 5, 29277, 102, 2968, 9271, 4, 50118, 50118, 725, 3843, 50118, 50118, 725, 3843, 16, 5, 796, 7681, 9, 5, 34479, 2383, 34665, 83, 28887, 2511, 4, 20, 47421, 15138, 6, 2033, 15, 1132, 759, 954, 6, 40, 1056, 15, 762, 19851, 7, 28754, 913, 8, 26236, 3816, 20576, 3092, 215, 25, 5, 4271, 2] 1\n",
      "['[CLS]', '<0xEE>', '<0x64>', '▁surprise', '<0x24>', '<0x18>', '▁Commercial', '<0x1A>', '▁Dubbed', '<0x92>', '<0x13>', 'sen', '▁Olympics', '▁,', '<0x1F>', '<0x10>', '▁»', '▁Group', '▁vie', '▁Garner', '<0x0C>', '<0x8D>', 'ie', '<0x1A>', '▁installed', '<0x02>', '▁Pool', 'There', '<0x02>', '▁tangible', '<0x00>', '<0x10>', '▁bucket', '▁pale', '▁are', '▁vie', '▁Garner', '<0x0C>', '<0x8D>', 'ie', '<0x1A>', '▁that', '▁throughout', '▁brittle', '<0x04>', '▁exit', '▁US', '<0x0E>', '▁plagued', '▁telling', '<0x00>', '▁wish', 'wrenching', 'wrenching', '▁Interests', '<0x0F>', '▁teak', '▁rice', '<0xCF>', '▁merit', '▁clear', '▁toiletries', '<0x02>', '▁Dubbed', '<0xB9>', '<0x3F>', '▁German', '<0x06>', '▁crime', '▁clear', 're', '<0x0A>', '<0x46>', '<0x18>', '<0x06>', 'god', '<0x05>', '<0x01>', '▁lighter', '▁rigidity', '<0x08>', ',', '▁Patterson', '▁pronounce', '<0x20>', '▁savings', '<0x60>', '<0xEA>', '<0x0B>', '▁building', '<0x01>', '51', '▁probably', '▁Instant', '<0xAC>', '▁exhilarating', '▁companion', '▁government', '▁serving', '<0x00>', '▁patch', '<0x0E>', '<0xCF>', '▁merit', '<0x24>', '▁visit', '▁put', '<0x06>', '<0xE3>', '▁mind', '▁vie', '▁Garner', '▁she', '▁cipher', '<0x60>', '▁Valley', '▁READ', '<0x39>', '<0x0C>', '<0x8D>', 'ie', '<0x1A>', '<0x01>', '▁river', '▁hip', '▁Market', '<0x20>', '▁unless', '<0x60>', '<0x27>', '<0x03>', '▁teacher', '<0x01>', '▁Bail', '<0x62>', '▁delicious', 'ara', '<0x00>', 'wrenching', 'wrenching', 'to', '▁posting', 'wrenching', 'wrenching', 'to', '▁posting', '<0x0C>', '<0x01>', '▁understand', '▁corners', '<0x05>', '<0x01>', '▁Anywhere', '▁fee', '▁airfield', '<0x4F>', '▁Barbados', '▁serving', '<0x00>', '<0x10>', '▁Dubbed', 'wo', '<0x02>', '▁ice', '<0x0B>', '▁policy', '▁low', '▁outside', '<0x02>', '<0x24>', '▁individual', '<0x0B>', '▁11', '▁prisons', '<0x03>', '▁Zak', '▁clear', '<0x04>', '▁exhilarating', '▁valid', '▁Ve', '▁reasonable', '<0xD3>', '<0x15>', '<0x01>', '▁ceremony', '[SEP]'] 2\n",
      "['[CLS]', '▁COD', '▁tragedies', '<0x7C>', '▁pretty', '▁easily', '<0x14>', '▁90', '▁Hood', '[MASK]', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 37, 0, 0, 0, 0, 0, 0, 102, 0, 0] target_labels\n",
      "[1, 49519, 31894, 128, 890, 1166, 24, 2156, 13071, 128000, 479, 2] masked_sample ids\n",
      "[1, 1843, 9927, 17200, 39, 18940, 2156, 2851, 25170, 1925, 8794, 69, 6085, 479, 2] 1\n",
      "['[CLS]', '▁prevent', '▁je', '▁vain', '<0x23>', '▁slightest', '▁90', '▁closer', 'letter', '▁waiting', '▁Pictures', '<0x41>', '▁neighbors', '▁things', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 2/25701300 [00:03<11821:22:30,  0.60it/s, v_num=43, loss_gen=218.0, loss_disc=0.432][1, 463, 6146, 209, 80, 7601, 6, 5, 34120, 3930, 9, 21065, 18402, 8, 5, 7343, 18933, 225, 3930, 4, 50118, 50118, 43854, 301, 50118, 50118, 2515, 2997, 7848, 226, 11736, 2865, 11, 27723, 131, 51, 18264, 11, 13466, 4, 96, 10206, 6, 79, 1145, 4508, 4616, 6, 41, 8083, 54, 1373, 69, 773, 11, 419, 930, 4, 252, 2997, 11, 9095, 8, 2442, 2997, 13, 5, 1079, 9, 69, 301, 4, 50118, 50118, 2515, 962, 11, 8607, 6, 886, 6, 15, 759, 365, 6, 3503, 6, 31, 23665, 8, 29367, 2088, 1144, 2988, 23, 5, 1046, 9, 8101, 4, 50118, 50118, 19224, 67, 50118, 41600, 9, 390, 11, 2866, 50118, 50118, 49379, 50118, 50118, 47380, 5678, 50118, 1437, 50118, 50118, 4310, 39998, 10974, 50118, 17297, 1580, 1138, 50118, 44038, 1821, 16132, 50118, 34696, 470, 4211, 50118, 34696, 390, 4211, 50118, 4310, 390, 36829, 50118, 19814, 39998, 10974, 50118, 1646, 2036, 26906, 50118, 32701, 3257, 50118, 19814, 11022, 994, 50118, 36118, 1891, 589, 16132, 50118, 29972, 9, 4222, 2383, 448, 2] 1\n",
      "['[CLS]', '▁As', '▁carries', '<0xCD>', '<0x4C>', '▁pharmacy', '<0x02>', '<0x01>', '▁Macmillan', '▁roles', '<0x05>', '▁Cube', '▁Squad', '<0x04>', '<0x01>', '▁analyst', '▁slap', '<0xDD>', '▁roles', '<0x00>', 'wrenching', 'wrenching', '▁Pembroke', '▁we', 'wrenching', 'wrenching', '▁Music', '▁upper', '▁Lawrence', '<0xDE>', '▁placeholder', '▁Michigan', '<0x07>', '▁abandoning', '<0x7F>', '<0x2F>', '▁Grass', '<0x07>', '▁slate', '<0x00>', '<0x5C>', '▁caution', '<0x02>', '<0x4B>', '▁instead', '▁que', '▁branch', '<0x02>', '<0x25>', '▁affair', '<0x32>', '▁Department', '<0x41>', '▁five', '<0x07>', '▁$', '▁turn', '<0x00>', '<0xF8>', '▁upper', '<0x07>', '▁fortune', '<0x04>', '▁radio', '▁upper', '<0x09>', '<0x01>', '▁win', '<0x05>', '<0x41>', '▁we', '<0x00>', 'wrenching', 'wrenching', '▁Music', '00', '<0x07>', '▁necessity', '<0x02>', '▁required', '<0x02>', '<0x0B>', '▁low', '▁make', '<0x02>', '▁inches', '<0x02>', '<0x1B>', '5°', '<0x04>', 'fields', '▁gain', '▁related', '▁Bar', '<0x13>', '<0x01>', '▁takes', '<0x05>', '▁Crystal', '<0x00>', 'wrenching', 'wrenching', '▁toured', '<0x3F>', 'wrenching', '▁anniversaries', '<0x05>', '▁through', '<0x07>', '▁enable', 'wrenching', 'wrenching', 'ebel', 'wrenching', 'wrenching', '▁ported', '▁neutral', 'wrenching', '▁wish', 'wrenching', 'wrenching', '▁maintaining', '▁Bump', '▁overlooking', 'wrenching', '▁visuals', 'of', '▁cause', 'wrenching', '▁looping', '▁larger', '▁NS', 'wrenching', 'kos', '▁place', '▁Him', 'wrenching', 'kos', '▁through', '▁Him', 'wrenching', '▁maintaining', '▁through', 'mba', 'wrenching', '▁wedge', '▁Bump', '▁overlooking', 'wrenching', '▁join', '▁Green', '▁Massive', 'wrenching', '▁Singing', 'ville', 'wrenching', '▁wedge', '▁realizing', '▁created', 'wrenching', 'adas', '▁cells', '▁On', '▁NS', 'wrenching', '▁survives', '<0x05>', '▁Oct', '▁fee', '▁each', '[SEP]'] 2\n",
      "['[CLS]', '▁prevent', '▁je', '▁Bonuses', '<0x23>', '▁slightest', '▁90', '▁closer', 'letter', '▁waiting', '▁Pictures', '<0x41>', '▁neighbors', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 17200, 0, 0, 0, 0, 0, 0, 0, 0, 6085, 0, 0] target_labels\n",
      "[1, 1843, 9927, 53656, 39, 18940, 2156, 2851, 25170, 1925, 8794, 69, 6085, 479, 2] masked_sample ids\n",
      "[1, 49519, 939, 40, 393, 2980, 47, 456, 479, 12801, 2] 1\n",
      "['[CLS]', '▁COD', '▁forward', '<0x24>', '▁then', '▁Very', '<0x2B>', '▁5', '▁things', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '▁COD', '[MASK]', '<0x24>', '▁then', '▁Very', '<0x2B>', '[MASK]', '▁things', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 0, 939, 0, 0, 0, 0, 456, 0, 0, 0] target_labels\n",
      "[1, 49519, 128000, 40, 393, 2980, 47, 128000, 479, 12801, 2] masked_sample ids\n",
      "[1, 627, 326, 1180, 2379, 65, 479, 2] 1\n",
      "['[CLS]', '▁God', '▁time', '▁word', '▁suggest', '<0x3D>', '▁things', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 3/25701300 [00:03<8374:46:50,  0.85it/s, v_num=43, loss_gen=218.0, loss_disc=0.432] ['[CLS]', '▁God', '▁time', '▁word', '▁suggest', '<0x3D>', '▁things', '[SEP]'] masked_sample\n",
      "[0, 627, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 627, 326, 1180, 2379, 65, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 49519, 31894, 128, 890, 1166, 24, 2156, 13071, 128000, 479, 2], 'labels': [0, 0, 37, 0, 0, 0, 0, 0, 0, 102, 0, 0]}, {'input_ids': [1, 1843, 9927, 53656, 39, 18940, 2156, 2851, 25170, 1925, 8794, 69, 6085, 479, 2], 'labels': [0, 0, 0, 17200, 0, 0, 0, 0, 0, 0, 0, 0, 6085, 0, 0]}, {'input_ids': [1, 49519, 128000, 40, 393, 2980, 47, 128000, 479, 12801, 2], 'labels': [0, 0, 939, 0, 0, 0, 0, 456, 0, 0, 0]}, {'input_ids': [1, 627, 326, 1180, 2379, 65, 479, 2], 'labels': [0, 627, 0, 0, 0, 0, 0, 0]}] 4\n",
      "Epoch 0:   0%|          | 3/25701300 [00:03<8476:39:24,  0.84it/s, v_num=43, loss_gen=152.0, loss_disc=0.314]['[CLS]', '▁including', '.', '▁six', '[MASK]', '<0x22>', '<0x0C>', '<0x06>', '1', '▁season', 'nd', '<0x0A>', '▁struggling', '<0x25>', 'page', '▁telling', '▁CENTRE', 'ons', '▁six', '▁hint', '▁Undergraduate', '<0x05>', '▁assists', '▁glutathione', '▁High', 'istry', '<0x01>', '▁track', '<0xBE>', '<0x05>', '▁money', '▁conditioning', '<0x00>', 'wrenching', 'wrenching', '[MASK]', '▁sexually', 'wrenching', 'to', '▁probably', '▁blood', '▁Grade', '[MASK]', '<0x0C>', '▁tips', '<0x13>', '[MASK]', 'wrenching', 'wrenching', '▁including', '[MASK]', '▁six', '▁hint', '<0x22>', '▁audit', '▁Cotton', '<0x0C>', '[MASK]', '<0x1A>', '▁computational', '▁Floor', '▁Jim', '▁audit', '▁Cotton', '<0x07>', '<0x01>', '[MASK]', '<0x02>', 'ons', '▁six', '▁hint', '[MASK]', '▁audit', '[MASK]', '<0x07>', '<0x01>', '▁procedure', '<0x02>', '▁augmented', '[MASK]', 'three', '▁audit', '▁Cotton', '<0x07>', '<0x01>', '▁Over', '<0x04>', '[MASK]', '▁bar', '▁price', '▁audit', '[MASK]', '<0x04>', '▁hanging', '▁penny', '▁not', '▁audit', '▁Cotton', '<0x07>', '▁Phen', '[MASK]', '▁into', '▁High', '▁But', '<0x01>', '▁Phen', 'ma', '▁into', '[MASK]', '<0x07>', '<0x01>', '▁successfully', '[MASK]', 'wrenching', 'wrenching', '▁set', '▁athletics', '[MASK]', '<0x0C>', '▁species', '<0x42>', '▁Louise', '[MASK]', '▁py', '▁arrange', '<0x03>', '<0x01>', '▁procedure', '<0x05>', '▁Phen', 'ma', '▁into', '[MASK]', '<0x02>', '▁ridiculous', '▁run', '<0x15>', '▁instruction', '[MASK]', '[MASK]', '▁crave', '<0x00>', '<0x10>', '<0x42>', '▁Louise', '[MASK]', '▁py', '<0x1C>', '▁various', '▁But', '<0x1A>', '<0xD3>', '▁Medication', '▁roots', '[MASK]', '▁CRM', '▁House', '[MASK]', '<0x02>', '▁told', '▁Template', '<0x72>', '<0x04>', '[MASK]', '▁cards', '▁reputation', '<0x00>', '▁didn', '<0xCD>', '▁elastic', '▁looking', 'See', '▁waves', '<0x3A>', '[MASK]', '▁hay', '<0x1C>', '<0x06>', '▁oversee', '▁item', '[MASK]', 'wrenching', 'wrenching', '▁including', '.', '[MASK]', '▁hint', '<0x22>', '▁audit', '▁Cotton', '[MASK]', '<0x25>', '▁There', '<0x05>', '▁mist', '<0x00>', '▁viewing', '▁thefts', '▁consensus', '<0xAC>', '<0x00>', '<0x51>', '<0x1E>', '<0x6C>', 'tech', '▁often', '▁human', 've', '▁why', '[SEP]'] masked_sample\n",
      " [0, 0, 0, 0, 8849, 0, 0, 0, 0, 0, 1803, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 493, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20981, 0, 0, 0, 0, 0, 0, 1437, 0, 0, 0, 479, 0, 0, 0, 260, 0, 0, 0, 0, 0, 0, 43490, 0, 0, 0, 0, 0, 0, 0, 0, 1926, 0, 0, 0, 0, 3082, 0, 11700, 0, 0, 0, 0, 0, 417, 0, 0, 0, 0, 0, 0, 0, 8550, 0, 0, 0, 11700, 0, 0, 0, 0, 0, 0, 0, 0, 4147, 0, 0, 0, 0, 0, 0, 0, 1995, 0, 0, 0, 4, 0, 0, 0, 0, 1418, 0, 0, 0, 0, 2617, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1995, 0, 0, 0, 0, 0, 1073, 853, 0, 0, 0, 0, 0, 2617, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 0, 118, 0, 0, 0, 0, 0, 28194, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 1073, 0, 0, 0, 0, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]target_labels\n",
      "[1, 500, 260, 1073, 128000, 38, 16, 10, 435, 709, 1803, 14, 4620, 41, 6833, 2757, 87151, 9462, 1073, 8849, 28764, 9, 7157, 55576, 1418, 92300, 5, 1362, 194, 9, 580, 7104, 4, 50118, 50118, 128000, 10486, 50118, 725, 873, 1452, 7748, 128000, 16, 2034, 23, 128000, 50118, 50118, 500, 128000, 1073, 8849, 38, 7522, 11700, 16, 128000, 30, 15803, 8467, 3644, 7522, 11700, 11, 5, 128000, 6, 9462, 1073, 8849, 128000, 7522, 128000, 11, 5, 3017, 6, 20009, 128000, 11695, 7522, 11700, 11, 5, 2077, 8, 128000, 1588, 710, 7522, 128000, 8, 4317, 12969, 298, 7522, 11700, 11, 41598, 128000, 352, 1418, 420, 5, 41598, 4147, 352, 128000, 11, 5, 3072, 128000, 50118, 50118, 487, 20329, 128000, 16, 2260, 70, 13996, 128000, 35512, 6480, 7, 5, 3017, 9, 41598, 4147, 352, 128000, 6, 8094, 684, 25, 5371, 128000, 128000, 20206, 4, 20, 70, 13996, 128000, 35512, 32, 847, 420, 30, 215, 43506, 5119, 128000, 12656, 1097, 128000, 6, 732, 8629, 118, 8, 128000, 1908, 3648, 4, 590, 209, 12323, 562, 11052, 5357, 62, 128000, 12530, 32, 10, 16331, 1905, 128000, 50118, 50118, 500, 260, 128000, 8849, 38, 7522, 11700, 128000, 41, 443, 9, 17445, 4, 4540, 50141, 7203, 176, 4, 85, 34, 112, 5730, 611, 857, 415, 579, 2] masked_sample ids\n",
      "[1, 627, 169, 37, 1415, 23, 20435, 2426, 2156, 101, 79, 21, 5, 129, 65, 11, 5, 929, 2156, 2468, 69, 235, 11, 479, 2] 1\n",
      "['[CLS]', '▁God', '<0xA5>', '<0x21>', '▁tools', '<0x13>', '▁Sophia', '▁exciting', '▁90', '<0x61>', '<0x4B>', '<0x11>', '<0x01>', '<0x7D>', '<0x3D>', '<0x07>', '<0x01>', '▁enjoy', '▁90', '▁Foundation', '<0x41>', '<0xE7>', '<0x07>', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁God', '<0xA5>', '<0x21>', '▁tools', '<0x13>', '▁Sophia', '▁exciting', '[MASK]', '<0x61>', '<0x4B>', '<0x11>', '<0x01>', '<0x7D>', '<0x3D>', '[MASK]', '<0x01>', '▁enjoy', '▁90', '▁Foundation', '<0x41>', '<0xE7>', '<0x07>', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 627, 0, 0, 0, 0, 0, 0, 2156, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 627, 169, 37, 1415, 23, 20435, 2426, 128000, 101, 79, 21, 5, 129, 65, 128000, 5, 929, 2156, 2468, 69, 235, 11, 128000, 2] masked_sample ids\n",
      "[1, 134, 644, 3010, 4, 50118, 50118, 36391, 16849, 9, 272, 2562, 574, 1437, 50118, 133, 8047, 9, 5, 138, 32, 7, 35, 50140, 36836, 3906, 8, 668, 17329, 2104, 8, 518, 23, 5, 9651, 4, 50118, 36836, 1078, 8, 573, 13, 3054, 6, 3670, 6, 9145, 11, 10753, 19, 275, 758, 3464, 4, 50118, 25138, 13014, 1414, 9, 2244, 14, 694, 323, 518, 23, 5, 3062, 7, 6292, 1374, 5838, 4, 50118, 19127, 12427, 877, 3054, 6, 4408, 6, 9145, 8, 7107, 7467, 4, 50118, 15347, 6, 3616, 8, 3014, 9651, 8, 43120, 1069, 3275, 11, 5498, 4, 50118, 50118, 33347, 29, 1437, 50118, 133, 272, 2562, 574, 11236, 5, 19566, 155, 23, 5, 229, 2889, 11, 494, 336, 8, 21, 2121, 11, 502, 199, 8, 21, 1357, 7, 5, 285, 71, 155, 377, 4, 1437, 50118, 50118, 243, 21, 1695, 59, 382, 1629, 10056, 4416, 21, 1240, 15, 5, 745, 9, 5, 19566, 155, 8, 97, 1377, 23, 229, 2889, 4, 20, 1663, 9, 10, 1437, 2] 1\n",
      "['[CLS]', '<0x82>', '—', '▁arms', '<0x00>', 'wrenching', 'wrenching', '▁auditions', '▁cafes', '<0x05>', '▁that', '▁Valley', '▁7', '▁wish', 'wrenching', '<0x81>', '▁arriving', '<0x05>', '<0x01>', '<0x86>', '<0x1C>', '<0x03>', '<0x1F>', '▁dietitian', '▁landfills', '▁Again', '<0x04>', '▁least', '▁DH', '▁copy', '<0x04>', '▁never', '<0x13>', '<0x01>', '▁turkey', '<0x00>', 'wrenching', '▁landfills', '▁review', '<0x04>', '▁My', '<0x09>', '▁throw', '<0x02>', '▁expenses', '<0x02>', '▁microwave', '<0x07>', '▁Idaho', '<0x0F>', '▁with', '▁everything', '▁iron', '<0x00>', 'wrenching', '▁1865', '▁recurring', '▁Once', '<0x05>', '▁techniques', '<0x0A>', '▁women', '▁.', '▁never', '<0x13>', '<0x01>', '▁topics', '<0x03>', '▁FL', '▁December', '▁chips', '<0x00>', 'wrenching', '▁Lessons', '▁dumped', '▁:', '▁throw', '<0x02>', '▁Singapore', '<0x02>', '▁microwave', '<0x04>', '▁Used', 'ney', '<0x00>', 'wrenching', '▁Known', '<0x02>', '▁noise', '<0x04>', '▁Having', '▁turkey', '<0x04>', '▁Excess', '▁receive', '▁tomorrow', '<0x07>', '▁Mass', '<0x00>', 'wrenching', 'wrenching', '▁pigeon', '<0x19>', '▁wish', 'wrenching', '<0x81>', '▁that', '▁Valley', '▁7', '▁logging', '<0x01>', '▁nicer', '<0x97>', '<0x13>', '<0x01>', '<0xE1>', '▁cloud', '<0x07>', '▁under', '▁A', '<0x04>', '<0x11>', '▁listed', '<0x07>', '▁To', '<0xC3>', '<0x04>', '<0x11>', '▁Christmas', '<0x03>', '<0x01>', ')', '<0x43>', '<0x97>', '▁–', '<0x00>', '▁wish', 'wrenching', 'wrenching', '<0xEF>', '<0x11>', '▁firm', '<0x37>', \"▁'\", '▁overall', '▁administrators', '▁graphics', '<0x11>', '▁town', '<0x0B>', '<0x01>', '▁non', '<0x05>', '<0x01>', '▁nicer', '<0x97>', '<0x04>', '<0x5D>', '▁resources', '<0x13>', '<0xE1>', '▁cloud', '<0x00>', '<0x10>', '▁According', '<0x05>', '<0x06>', '▁wish', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 4/25701300 [00:04<7794:51:46,  0.92it/s, v_num=43, loss_gen=127.0, loss_disc=0.293]['[CLS]', '<0xEE>', '<0x64>', '▁surprise', '<0x24>', '<0x18>', '[MASK]', '<0x1A>', '▁Dubbed', '<0x92>', '<0x13>', '▁Scattering', '▁Olympics', '▁,', '[MASK]', '<0x10>', '▁»', '▁Group', '▁vie', '[MASK]', '<0x0C>', '<0x8D>', 'ie', '<0x1A>', '▁installed', '<0x02>', '▁Pool', 'There', '<0x02>', '[MASK]', '<0x00>', '<0x10>', '▁bucket', '▁pale', '▁are', '[MASK]', '▁Garner', '[MASK]', '<0x8D>', 'ie', '<0x1A>', '▁that', '▁throughout', '▁brittle', '<0x04>', '[MASK]', '▁US', '<0x0E>', '▁plagued', '▁telling', '<0x00>', '▁401', 'wrenching', 'wrenching', '▁Interests', '<0x0F>', '▁teak', '[MASK]', '<0xCF>', '▁merit', '▁clear', '[MASK]', '<0x02>', '▁Dubbed', '<0xB9>', '<0x3F>', '▁German', '<0x06>', '▁crime', '▁clear', 're', '<0x0A>', '<0x46>', '<0x18>', '<0x06>', 'god', '<0x05>', '<0x01>', '[MASK]', '▁rigidity', '<0x08>', ',', '▁Patterson', '[MASK]', '<0x20>', '▁savings', '<0x60>', '<0xEA>', '<0x0B>', '▁building', '[MASK]', '51', '▁probably', '[MASK]', '<0xAC>', '▁exhilarating', '▁companion', '▁government', '▁serving', '<0x00>', '▁patch', '<0x0E>', '[MASK]', '▁merit', '<0x24>', '▁visit', '▁put', '[MASK]', '<0xE3>', '▁mind', '▁vie', '▁Garner', '[MASK]', '▁cipher', '<0x60>', '▁Valley', '[MASK]', '<0x39>', '<0x0C>', '<0x8D>', 'ie', '<0x1A>', '<0x01>', '▁river', '[MASK]', '▁Market', '<0x20>', '▁unless', '<0x60>', '<0x27>', '<0x03>', '[MASK]', '<0x01>', '[MASK]', '<0x62>', '▁delicious', 'ara', '<0x00>', 'wrenching', 'wrenching', 'to', '▁posting', 'wrenching', 'wrenching', 'to', '▁posting', '[MASK]', '<0x01>', '▁understand', '▁corners', '<0x05>', '<0x01>', '▁Anywhere', '▁fee', '▁airfield', '<0x4F>', '[MASK]', '▁serving', '<0x00>', '<0x10>', '▁Dubbed', 'wo', '<0x02>', '▁ice', '<0x0B>', '▁policy', '▁low', '▁outside', '<0x02>', '<0x24>', '▁individual', '<0x0B>', '▁11', '▁prisons', '<0x03>', '▁Zak', '▁clear', '<0x04>', '▁exhilarating', '▁valid', '▁Ve', '▁reasonable', '<0xD3>', '<0x15>', '<0x01>', '▁ceremony', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 0, 6400, 0, 0, 0, 0, 6553, 0, 0, 35, 0, 0, 0, 0, 29918, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12587, 0, 0, 0, 0, 0, 29378, 0, 16, 0, 0, 0, 0, 0, 0, 0, 5323, 0, 0, 0, 0, 0, 1437, 0, 0, 0, 0, 0, 4048, 0, 0, 0, 30702, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 74, 0, 0, 0, 0, 0, 7090, 0, 0, 0, 0, 24625, 0, 0, 0, 0, 0, 0, 5, 0, 0, 13253, 0, 0, 0, 0, 0, 0, 0, 0, 211, 0, 0, 0, 0, 10, 0, 0, 0, 0, 373, 0, 0, 0, 13345, 0, 0, 0, 0, 0, 0, 0, 5374, 0, 0, 0, 0, 0, 0, 2274, 0, 29277, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 725, 0, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28887, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 954, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 242, 104, 2923, 40, 28, 128000, 30, 47421, 150, 23, 109123, 8307, 366, 128000, 20, 5366, 1543, 29378, 128000, 16, 145, 2226, 30, 2627, 6, 9096, 3497, 6, 128000, 4, 20, 8873, 9399, 281, 128000, 29918, 128000, 145, 2226, 30, 272, 1075, 27404, 8, 128000, 846, 18, 21624, 2757, 4, 14804, 50118, 50118, 40066, 19, 27994, 128000, 211, 11328, 913, 128000, 6, 47421, 189, 67, 2324, 10, 2898, 913, 368, 14, 74, 28, 10, 24633, 9, 5, 128000, 36241, 12, 261, 17550, 128000, 36, 3632, 100, 238, 15, 792, 128000, 6280, 873, 128000, 176, 26236, 7728, 671, 2511, 4, 6109, 18, 128000, 11328, 40, 836, 552, 128000, 231, 791, 29378, 29918, 128000, 42560, 100, 2562, 128000, 61, 16, 145, 2226, 30, 5, 3108, 128000, 3131, 36, 2336, 100, 43, 7, 128000, 5, 128000, 102, 2968, 9271, 4, 50118, 50118, 725, 3843, 50118, 50118, 725, 3843, 128000, 5, 796, 7681, 9, 5, 34479, 2383, 34665, 83, 128000, 2511, 4, 20, 47421, 15138, 6, 2033, 15, 1132, 759, 954, 6, 40, 1056, 15, 762, 19851, 7, 28754, 913, 8, 26236, 3816, 20576, 3092, 215, 25, 5, 4271, 2] masked_sample ids\n",
      "[1, 8877, 8266, 5, 1925, 38221, 159, 69, 3124, 2156, 8, 5, 45219, 6721, 11, 69, 471, 14, 2551, 7, 120, 3007, 19, 358, 1149, 479, 2] 1\n",
      "['[CLS]', '▁82', '▁trademark', '<0x01>', '▁waiting', 'gift', '<0x9B>', '<0x41>', '▁abuse', '▁90', '<0x04>', '<0x01>', 'ibel', '▁Hamilton', '<0x07>', '<0x41>', '▁So', '<0x0A>', '▁worry', '<0x03>', '<0x74>', '▁stick', '<0x0F>', 'm', '▁N', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁As', '[MASK]', '<0xCD>', '<0x4C>', '▁pharmacy', '<0x02>', '<0x01>', '▁Macmillan', '[MASK]', '<0x05>', '▁Cube', '▁Squad', '[MASK]', '<0x01>', '▁analyst', '▁slap', '<0xDD>', '▁roles', '<0x00>', 'wrenching', 'wrenching', '[MASK]', '▁we', 'wrenching', 'wrenching', '▁Music', '[MASK]', '▁Lawrence', '<0xDE>', '▁placeholder', '▁Michigan', '<0x07>', '[MASK]', '<0x7F>', '<0x2F>', '▁Grass', '<0x07>', '▁slate', '<0x00>', '[MASK]', '▁caution', '<0x02>', '<0x4B>', '▁instead', '▁que', '▁branch', '<0x02>', '[MASK]', '▁affair', '<0x32>', '[MASK]', '<0x41>', '▁five', '<0x07>', '▁$', '▁turn', '[MASK]', '<0xF8>', '▁upper', '<0x07>', '▁fortune', '[MASK]', '▁radio', '▁upper', '<0x09>', '<0x01>', '▁win', '<0x05>', '<0x41>', '▁we', '[MASK]', 'wrenching', 'wrenching', '▁Music', '00', '[MASK]', '▁necessity', '<0x02>', '▁required', '<0x02>', '<0x0B>', '▁low', '▁make', 'rapid', '[MASK]', '<0x02>', '<0x1B>', '5°', '<0x04>', 'fields', '▁gain', '▁related', '▁Bar', '<0x13>', '<0x01>', '▁takes', '<0x05>', '▁Crystal', '<0x00>', '[MASK]', 'wrenching', '▁toured', '[MASK]', 'wrenching', '▁anniversaries', '<0x05>', '▁through', '<0x07>', '▁enable', 'wrenching', 'wrenching', 'ebel', '▁Barney', 'wrenching', '▁ported', '▁neutral', 'wrenching', '[MASK]', 'wrenching', 'wrenching', '▁maintaining', '▁Bump', '▁overlooking', 'wrenching', '▁visuals', '[MASK]', '▁cause', 'wrenching', '[MASK]', '▁larger', '▁NS', 'wrenching', 'kos', '▁place', '▁Him', 'wrenching', 'kos', '▁through', '▁Him', 'wrenching', '▁maintaining', '▁through', '[MASK]', 'wrenching', '[MASK]', '▁Bump', '▁overlooking', 'wrenching', '▁join', '▁Green', '▁Massive', 'wrenching', '[MASK]', 'ville', 'wrenching', '▁wedge', '▁realizing', '▁created', 'wrenching', 'adas', '▁cells', '▁On', '▁NS', 'wrenching', '▁survives', '<0x05>', '▁Oct', '▁fee', '▁each', '[SEP]'] masked_sample\n",
      "[0, 0, 6146, 0, 0, 0, 0, 0, 0, 3930, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 43854, 0, 0, 0, 0, 2997, 0, 0, 0, 0, 0, 27723, 0, 0, 0, 0, 0, 0, 96, 0, 0, 0, 0, 0, 0, 0, 41, 0, 0, 1373, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 6, 3503, 0, 0, 0, 0, 0, 0, 0, 2988, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 67, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 1437, 0, 0, 0, 0, 0, 0, 0, 1580, 0, 0, 44038, 0, 0, 0, 0, 0, 0, 0, 0, 390, 0, 0, 0, 0, 36829, 0, 19814, 0, 0, 0, 0, 0, 0, 0, 32701, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 463, 128000, 209, 80, 7601, 6, 5, 34120, 128000, 9, 21065, 18402, 128000, 5, 7343, 18933, 225, 3930, 4, 50118, 50118, 128000, 301, 50118, 50118, 2515, 128000, 7848, 226, 11736, 2865, 11, 128000, 131, 51, 18264, 11, 13466, 4, 128000, 10206, 6, 79, 1145, 4508, 4616, 6, 128000, 8083, 54, 128000, 69, 773, 11, 419, 930, 128000, 252, 2997, 11, 9095, 128000, 2442, 2997, 13, 5, 1079, 9, 69, 301, 128000, 50118, 50118, 2515, 962, 128000, 8607, 6, 886, 6, 15, 759, 365, 68116, 128000, 6, 31, 23665, 8, 29367, 2088, 1144, 2988, 23, 5, 1046, 9, 8101, 4, 128000, 50118, 19224, 128000, 50118, 41600, 9, 390, 11, 2866, 50118, 50118, 49379, 27604, 50118, 47380, 5678, 50118, 128000, 50118, 50118, 4310, 39998, 10974, 50118, 17297, 128000, 1138, 50118, 128000, 1821, 16132, 50118, 34696, 470, 4211, 50118, 34696, 390, 4211, 50118, 4310, 390, 128000, 50118, 128000, 39998, 10974, 50118, 1646, 2036, 26906, 50118, 128000, 3257, 50118, 19814, 11022, 994, 50118, 36118, 1891, 589, 16132, 50118, 29972, 9, 4222, 2383, 448, 2] masked_sample ids\n",
      "[1, 42710, 254, 8, 444, 55, 9669, 479, 2] 1\n",
      "['[CLS]', '▁до', '<0xFA>', '<0x04>', '▁down', '<0x33>', '▁Brandon', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '<0xFA>', '<0x04>', '▁down', '<0x33>', '▁Brandon', '▁things', '[SEP]'] masked_sample\n",
      "[0, 42710, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 128000, 254, 8, 444, 55, 9669, 479, 2] masked_sample ids\n",
      "[1, 8877, 531, 33, 11118, 24, 31, 39, 543, 1305, 2156, 13, 9069, 128, 29, 12253, 479, 2] 1\n",
      "['[CLS]', '▁82', '▁provide', '<0x1D>', '▁overlooked', '<0x14>', '<0x1B>', '<0x23>', '▁U', '▁marketing', '▁90', '<0x09>', '▁Upper', '<0x7C>', '<0x19>', '▁towers', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁82', '▁trademark', '<0x01>', '▁waiting', '[MASK]', '<0x9B>', '<0x41>', '▁abuse', '▁90', '<0x04>', '<0x01>', '[MASK]', '▁Hamilton', '<0x07>', '[MASK]', '▁So', '<0x0A>', '▁worry', '<0x03>', '<0x74>', '▁stick', '<0x0F>', '[MASK]', '▁N', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 38221, 0, 0, 0, 0, 0, 0, 45219, 0, 0, 69, 0, 0, 0, 0, 0, 0, 0, 358, 0, 0, 0] target_labels\n",
      "[1, 8877, 8266, 5, 1925, 128000, 159, 69, 3124, 2156, 8, 5, 128000, 6721, 11, 128000, 471, 14, 2551, 7, 120, 3007, 19, 128000, 1149, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 5632, 5, 128000, 4, 288, 30193, 14228, 1792, 128000, 468, 401, 6, 5, 83, 33287, 8408, 9235, 128000, 9219, 3202, 128000, 935, 15053, 4, 4701, 415, 10447, 931, 128000, 15, 719, 361, 6, 8148, 8, 128000, 4209, 19, 5, 128000, 5997, 29913, 4, 50118, 50118, 49379, 50118, 50118, 47380, 5678, 50140, 128000, 11579, 387, 35, 15465, 4701, 128000, 2154, 281, 11, 4133, 359, 128000, 924, 50118, 4701, 415, 128000, 9732, 12920, 7086, 36, 1990, 10206, 2383, 41295, 5376, 128000, 2989, 4701, 415, 2154, 281, 43, 50118, 50118, 128000, 15021, 10447, 50118, 128000, 12, 10799, 1734, 50118, 500, 4352, 12, 13630, 12, 128000, 1734, 50118, 128000, 12, 10799, 1677, 50118, 35985, 12, 13630, 12, 19306, 128000, 50118, 1646, 541, 29, 1677, 50118, 1646, 1749, 29, 1677, 50118, 43545, 29, 1677, 50118, 41355, 29, 1677, 2], 'labels': [0, 0, 0, 155, 0, 0, 0, 0, 0, 12839, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 1249, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 15465, 0, 0, 0, 0, 0, 49379, 0, 0, 0, 0, 0, 9206, 0, 0, 0, 0, 0, 415, 0, 0, 0, 0, 0, 1012, 0, 0, 0, 0, 10447, 0, 0, 0, 0, 0, 10206, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 104, 0, 0, 0, 31440, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19306, 0, 0, 30238, 0, 0, 0, 0, 0, 0, 13630, 0, 0, 1734, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 179, 8, 128000, 2156, 11, 8, 54275, 2156, 454, 129, 5, 14291, 12213, 128000, 10317, 1299, 588, 5988, 479, 2], 'labels': [0, 0, 0, 66, 0, 0, 0, 66, 0, 0, 0, 0, 0, 0, 127, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 242, 104, 2923, 40, 28, 128000, 30, 47421, 150, 23, 109123, 8307, 366, 128000, 20, 5366, 1543, 29378, 128000, 16, 145, 2226, 30, 2627, 6, 9096, 3497, 6, 128000, 4, 20, 8873, 9399, 281, 128000, 29918, 128000, 145, 2226, 30, 272, 1075, 27404, 8, 128000, 846, 18, 21624, 2757, 4, 14804, 50118, 50118, 40066, 19, 27994, 128000, 211, 11328, 913, 128000, 6, 47421, 189, 67, 2324, 10, 2898, 913, 368, 14, 74, 28, 10, 24633, 9, 5, 128000, 36241, 12, 261, 17550, 128000, 36, 3632, 100, 238, 15, 792, 128000, 6280, 873, 128000, 176, 26236, 7728, 671, 2511, 4, 6109, 18, 128000, 11328, 40, 836, 552, 128000, 231, 791, 29378, 29918, 128000, 42560, 100, 2562, 128000, 61, 16, 145, 2226, 30, 5, 3108, 128000, 3131, 36, 2336, 100, 43, 7, 128000, 5, 128000, 102, 2968, 9271, 4, 50118, 50118, 725, 3843, 50118, 50118, 725, 3843, 128000, 5, 796, 7681, 9, 5, 34479, 2383, 34665, 83, 128000, 2511, 4, 20, 47421, 15138, 6, 2033, 15, 1132, 759, 954, 6, 40, 1056, 15, 762, 19851, 7, 28754, 913, 8, 26236, 3816, 20576, 3092, 215, 25, 5, 4271, 2], 'labels': [0, 0, 0, 0, 0, 0, 6400, 0, 0, 0, 0, 6553, 0, 0, 35, 0, 0, 0, 0, 29918, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12587, 0, 0, 0, 0, 0, 29378, 0, 16, 0, 0, 0, 0, 0, 0, 0, 5323, 0, 0, 0, 0, 0, 1437, 0, 0, 0, 0, 0, 4048, 0, 0, 0, 30702, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 74, 0, 0, 0, 0, 0, 7090, 0, 0, 0, 0, 24625, 0, 0, 0, 0, 0, 0, 5, 0, 0, 13253, 0, 0, 0, 0, 0, 0, 0, 0, 211, 0, 0, 0, 0, 10, 0, 0, 0, 0, 373, 0, 0, 0, 13345, 0, 0, 0, 0, 0, 0, 0, 5374, 0, 0, 0, 0, 0, 0, 2274, 0, 29277, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 725, 0, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28887, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 954, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 8877, 8266, 5, 1925, 128000, 159, 69, 3124, 2156, 8, 5, 128000, 6721, 11, 128000, 471, 14, 2551, 7, 120, 3007, 19, 128000, 1149, 479, 2], 'labels': [0, 0, 0, 0, 0, 38221, 0, 0, 0, 0, 0, 0, 45219, 0, 0, 69, 0, 0, 0, 0, 0, 0, 0, 358, 0, 0, 0]}] 4\n",
      "[1, 12724, 2721, 2933, 2473, 14, 58, 3820, 19, 1109, 8, 2933, 2156, 373, 7, 69, 479, 2] 1\n",
      "['[CLS]', '▁tribes', '▁Team', '▁mouth', '▁menu', '<0x0A>', '<0x36>', '▁^', '<0x0F>', '▁late', '<0x04>', '▁mouth', '▁90', '▁she', '<0x03>', '<0x41>', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁82', '▁provide', '<0x1D>', '▁overlooked', '<0x14>', '<0x1B>', '<0x23>', '▁U', '▁marketing', '▁90', '[MASK]', '▁Upper', '<0x7C>', '[MASK]', '▁towers', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 13, 0, 0, 29, 0, 0, 0] target_labels\n",
      "[1, 8877, 531, 33, 11118, 24, 31, 39, 543, 1305, 2156, 128000, 9069, 128, 128000, 12253, 479, 2] masked_sample ids\n",
      "[1, 118, 115, 213, 19, 47, 479, 12801, 2] 1\n",
      "['[CLS]', '<0x72>', '<0x6F>', '<0xD1>', '<0x0F>', '<0x2B>', '▁things', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '<0x72>', '<0x6F>', '<0xD1>', 'abella', '<0x2B>', '▁things', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 19, 0, 0, 0, 0] target_labels\n",
      "[1, 118, 115, 213, 57790, 47, 479, 12801, 2] masked_sample ids\n",
      "[{'input_ids': [1, 463, 128000, 209, 80, 7601, 6, 5, 34120, 128000, 9, 21065, 18402, 128000, 5, 7343, 18933, 225, 3930, 4, 50118, 50118, 128000, 301, 50118, 50118, 2515, 128000, 7848, 226, 11736, 2865, 11, 128000, 131, 51, 18264, 11, 13466, 4, 128000, 10206, 6, 79, 1145, 4508, 4616, 6, 128000, 8083, 54, 128000, 69, 773, 11, 419, 930, 128000, 252, 2997, 11, 9095, 128000, 2442, 2997, 13, 5, 1079, 9, 69, 301, 128000, 50118, 50118, 2515, 962, 128000, 8607, 6, 886, 6, 15, 759, 365, 68116, 128000, 6, 31, 23665, 8, 29367, 2088, 1144, 2988, 23, 5, 1046, 9, 8101, 4, 128000, 50118, 19224, 128000, 50118, 41600, 9, 390, 11, 2866, 50118, 50118, 49379, 27604, 50118, 47380, 5678, 50118, 128000, 50118, 50118, 4310, 39998, 10974, 50118, 17297, 128000, 1138, 50118, 128000, 1821, 16132, 50118, 34696, 470, 4211, 50118, 34696, 390, 4211, 50118, 4310, 390, 128000, 50118, 128000, 39998, 10974, 50118, 1646, 2036, 26906, 50118, 128000, 3257, 50118, 19814, 11022, 994, 50118, 36118, 1891, 589, 16132, 50118, 29972, 9, 4222, 2383, 448, 2], 'labels': [0, 0, 6146, 0, 0, 0, 0, 0, 0, 3930, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 43854, 0, 0, 0, 0, 2997, 0, 0, 0, 0, 0, 27723, 0, 0, 0, 0, 0, 0, 96, 0, 0, 0, 0, 0, 0, 0, 41, 0, 0, 1373, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 6, 3503, 0, 0, 0, 0, 0, 0, 0, 2988, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 67, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 1437, 0, 0, 0, 0, 0, 0, 0, 1580, 0, 0, 44038, 0, 0, 0, 0, 0, 0, 0, 0, 390, 0, 0, 0, 0, 36829, 0, 19814, 0, 0, 0, 0, 0, 0, 0, 32701, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 254, 8, 444, 55, 9669, 479, 2], 'labels': [0, 42710, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 8877, 531, 33, 11118, 24, 31, 39, 543, 1305, 2156, 128000, 9069, 128, 128000, 12253, 479, 2], 'labels': [0, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 13, 0, 0, 29, 0, 0, 0]}, {'input_ids': [1, 118, 115, 213, 57790, 47, 479, 12801, 2], 'labels': [0, 0, 0, 0, 19, 0, 0, 0, 0]}] 4\n",
      "['[CLS]', '▁tribes', '▁Team', '▁mouth', '[MASK]', '<0x0A>', '<0x36>', '▁^', '[MASK]', '▁late', '<0x04>', '▁mouth', '▁90', '▁she', '<0x03>', '<0x41>', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 2473, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0, 69, 0, 0] target_labels\n",
      "[1, 12724, 2721, 2933, 128000, 14, 58, 3820, 128000, 1109, 8, 2933, 2156, 373, 7, 69, 479, 2] masked_sample ids\n",
      "[1, 22466, 367, 728, 2156, 5, 11641, 19057, 10, 8401, 2838, 50, 34415, 2601, 479, 2] 1\n",
      "['[CLS]', '▁axe', '▁You', '▁social', '▁90', '<0x01>', '▁advertisements', '▁saint', '<0x06>', '▁Military', '▁chair', '<0x2E>', '▁Athena', '▁vs', '▁things', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 5/25701300 [00:04<7067:15:14,  1.01it/s, v_num=43, loss_gen=127.0, loss_disc=0.293]['[CLS]', '▁axe', '[MASK]', '▁social', '▁90', '<0x01>', '▁advertisements', '[MASK]', '<0x06>', '▁Military', '▁chair', '<0x2E>', '▁Athena', '▁vs', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 367, 0, 0, 0, 0, 19057, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 22466, 128000, 728, 2156, 5, 11641, 128000, 10, 8401, 2838, 50, 34415, 2601, 479, 2] masked_sample ids\n",
      "[1, 25252, 89, 37, 20290, 16190, 10, 4683, 147, 37, 74, 6105, 614, 454, 2936, 132, 438, 2035, 11, 290, 722, 479, 2] 1\n",
      "['[CLS]', '▁Eleven', '<0x55>', '<0x21>', 'AGE', '▁resign', '<0x06>', '▁formula', '<0x8F>', '<0x21>', '<0x46>', '▁Jean', '▁large', '▁same', '▁relatively', '<0x80>', '▁while', '▁organizations', '<0x07>', '▁your', '▁won', '▁things', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 5/25701300 [00:05<7143:25:35,  1.00it/s, v_num=43, loss_gen=126.0, loss_disc=0.383][1, 49519, 46736, 17487, 12801, 2] 1\n",
      "['[CLS]', '▁COD', 'CMA', 'Mart', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '▁COD', 'CMA', 'Mart', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 12801, 0] target_labels\n",
      "[1, 49519, 46736, 17487, 128000, 2] masked_sample ids\n",
      "[1, 6968, 115, 465, 2512, 2037, 62, 11, 39, 997, 479, 12801, 2] 1\n",
      "['[CLS]', '▁organize', '<0x6F>', '▁part', '▁raise', '▁Africa', '<0x3A>', '<0x07>', '<0x23>', '▁running', '▁things', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '▁Eleven', '<0x55>', '<0x21>', '▁wretch', '▁resign', '<0x06>', '[MASK]', '<0x8F>', '<0x21>', '<0x46>', '▁Jean', '▁large', '▁same', '▁relatively', '<0x80>', '▁while', '▁organizations', '<0x07>', '▁your', '▁won', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 20290, 0, 0, 4683, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0] target_labels\n",
      "[1, 25252, 89, 37, 103608, 16190, 10, 128000, 147, 37, 74, 6105, 614, 454, 2936, 132, 438, 2035, 11, 290, 722, 479, 2] masked_sample ids\n",
      "[1, 33309, 18226, 1242, 763, 36, 6, 25606, 4839, 16, 5, 1154, 8037, 11, 33545, 6, 2034, 11, 18226, 1242, 763, 12, 448, 1097, 11104, 6131, 8, 15, 5, 2946, 18, 3285, 1353, 31585, 4, 3139, 23678, 16, 14092, 9, 16762, 34769, 17529, 8, 35899, 5065, 7501, 30, 911, 9, 19790, 22178, 4, 85, 4620, 5, 1312, 9, 5, 2946, 18, 144, 505, 7666, 12, 11600, 976, 4, 85, 16, 10, 4066, 14294, 13, 7892, 6, 217, 103, 3159, 8, 14739, 4707, 6, 25, 157, 25, 41, 505, 5651, 1255, 4, 1777, 18226, 1242, 763, 8, 63, 3817, 29084, 1719, 2156, 8, 680, 10, 1186, 9, 29073, 6, 217, 490, 514, 6, 769, 196, 5134, 29, 6, 35899, 5065, 6, 8, 7666, 21775, 918, 4, 20, 8037, 1495, 4865, 479, 1777, 18226, 1242, 763, 21, 2998, 10, 7727, 1245, 9, 758, 3585, 223, 5, 758, 5474, 271, 9127, 15, 902, 132, 6, 4999, 4, 50118, 50118, 133, 251, 13597, 19976, 1115, 493, 36, 41635, 4306, 5638, 354, 12303, 611, 853, 43, 1437, 2] 1\n",
      "['[CLS]', '▁predatory', 'shan', '▁goes', '▁current', '<0x20>', '<0x02>', '▁marginalized', '▁resulted', '<0x0C>', '<0x01>', '▁17', '▁Dublin', '<0x07>', '▁Greensboro', '<0x02>', '▁tips', '<0x07>', 'shan', '▁goes', '▁current', '<0x08>', '▁each', '▁House', '▁reputable', '▁relaxed', '<0x04>', '<0x0B>', '<0x01>', '▁resolution', '<0x0E>', '▁Wall', '▁ground', 'Hold', '<0x00>', '▁losing', '▁Kensington', '<0x0C>', '▁Shares', '<0x05>', '▁LC', '▁habitual', 'NS', '<0x04>', '▁sauté', '▁Things', '▁delicate', '<0x1A>', '▁points', '<0x05>', '▁manifestation', '▁420', '<0x00>', '<0x51>', '▁struggling', '<0x01>', '▁hands', '<0x05>', '<0x01>', '▁resolution', '<0x0E>', '<0x8C>', '▁found', '▁gel', '<0x08>', '▁128', '▁events', '<0x00>', '<0x51>', '<0x0C>', '<0x06>', '▁guitar', '▁noodles', '<0x09>', '▁Fortunately', '<0x02>', '<0xD5>', '<0x63>', '▁institutions', '<0x04>', '▁polling', '▁Trade', '<0x02>', '<0x15>', '<0x99>', '<0x15>', '<0x25>', '▁found', '▁photographer', '▁gave', '<0x00>', '▁dark', 'shan', '▁goes', '▁current', '<0x04>', '<0x3B>', '▁pace', '▁Stripe', '▁challenge', '▁90', '<0x04>', '▁include', '<0x06>', '+', '<0x05>', '▁souvenirs', '<0x02>', '<0xD5>', '▁does', '▁data', '<0x02>', '▁industry', '<0xC0>', '▁burn', '<0x19>', '<0x02>', '▁sauté', '▁Things', '<0x02>', '<0x04>', '▁gel', '▁detectives', '▁John', '<0x00>', '<0x10>', '▁Dublin', '▁wait', '▁DVD', '▁things', '▁dark', 'shan', '▁goes', '▁current', '<0x11>', '▁studio', '<0x06>', '▁destinations', '▁hair', '<0x05>', '▁everything', '▁argument', '<0xDB>', '<0x01>', '▁everything', '▁Given', '-', '▁fatigue', '<0x0B>', '▁National', '<0x80>', '<0x02>', 'art', '<0x00>', 'wrenching', 'wrenching', '<0x81>', '<0xF7>', '▁MAC', '{', '▁image', '▁better', '<0x20>', '▁misused', '▁stretch', '▁aggressive', '▁than', 'After', '▁often', '▁child', '<0x27>', '▁wish', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 6/25701300 [00:05<6157:42:48,  1.16it/s, v_num=43, loss_gen=126.0, loss_disc=0.383]['[CLS]', '▁organize', '[MASK]', '▁part', '▁raise', '▁Africa', '<0x3A>', '<0x07>', '[MASK]', '▁running', '▁things', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 0, 115, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0] target_labels\n",
      "[1, 6968, 128000, 465, 2512, 2037, 62, 11, 128000, 997, 479, 12801, 2] masked_sample ids\n",
      "[1, 462, 1906, 27328, 1415, 66, 11, 5, 22097, 479, 2] 1\n",
      "Epoch 0:   0%|          | 6/25701300 [00:05<6204:33:35,  1.15it/s, v_num=43, loss_gen=113.0, loss_disc=0.200]'[SEP]'] 2\n",
      "[1, 6968, 6056, 295, 75, 489, 12200, 479, 12801, 2] 1\n",
      "['[CLS]', '▁organize', '▁Win', '▁can', '<0x47>', '▁always', 'road', '▁things', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '▁eight', '▁subtitles', '▁tools', '<0x3E>', '<0x07>', '<0x01>', '[MASK]', '▁things', '[SEP]'] masked_sample\n",
      "['[CLS]', '▁organize', '▁Win', '▁can', '[MASK]', '▁always', 'road', '▁things', '[MASK]', '[SEP]'][0, 462, 0, 0, 0, 0, 0, 0, 22097, 0, 0]  masked_sampletarget_labels\n",
      "\n",
      "[0, 0, 0, 0, 75, 0, 0, 0, 12801, 0][1, 128000, 1906, 27328, 1415, 66, 11, 5, 128000, 479, 2]  target_labelsmasked_sample ids\n",
      "\n",
      "[1, 6968, 6056, 295, 128000, 489, 12200, 479, 128000, 2][1, 4297, 939, 21, 45, 1268, 780, 7, 127, 748, 18611, 479, 2]  masked_sample ids1\n",
      "\n",
      "[1, 506, 24029, 4024, 162, 5373, 479, 12801, 2]['[CLS]', '▁army', '▁forward', '<0x11>', '<0x29>', '▁consider', '▁United', '<0x03>', '<0x7B>', '▁below', 'ison', '▁things', '[SEP]']  12\n",
      "\n",
      "['[CLS]', '▁service', '▁Bearing', '▁Nov', '<0x9E>', '▁investigate', '▁things', '▁amendments', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 7/25701300 [00:05<5487:25:11,  1.30it/s, v_num=43, loss_gen=113.0, loss_disc=0.200]['[CLS]', '▁service', '▁Bearing', '▁Nov', '▁quantifying', '▁investigate', '▁things', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 162, 0, 0, 0, 0] target_labels\n",
      "[1, 506, 24029, 4024, 65363, 5373, 479, 12801, 2] masked_sample ids\n",
      "[1, 8877, 1224, 7, 192, 14, 6128, 420, 5, 20707, 5, 253, 3994, 4490, 58, 878, 1706, 5, 1855, 16836, 8, 33189, 88, 24, 479, 2] 1\n",
      "['[CLS]', '▁82', '▁brand', '<0x03>', '<0xBC>', '<0x0A>', '▁arranged', '▁But', '<0x01>', 'hai', '<0x01>', '<0xF9>', '▁recognition', '▁Senior', '<0x36>', '▁likely', '▁condition', '<0x01>', '▁characters', '▁traced', '<0x04>', '▁для', '<0x54>', '<0x14>', '▁things', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 7/25701300 [00:05<5535:48:42,  1.29it/s, v_num=43, loss_gen=128.0, loss_disc=0.211]['[CLS]', '▁army', '[MASK]', '<0x11>', '<0x29>', '▁consider', '▁United', '<0x03>', '<0x7B>', '[MASK]', 'ison', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 939, 0, 0, 0, 0, 0, 0, 748, 0, 0, 0] target_labels\n",
      "[1, 4297, 128000, 21, 45, 1268, 780, 7, 127, 128000, 18611, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 49519, 46736, 17487, 128000, 2], 'labels': [0, 0, 0, 0, 12801, 0]}, {'input_ids': [1, 6968, 128000, 465, 2512, 2037, 62, 11, 128000, 997, 479, 12801, 2], 'labels': [0, 0, 115, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 1906, 27328, 1415, 66, 11, 5, 128000, 479, 2], 'labels': [0, 462, 0, 0, 0, 0, 0, 0, 22097, 0, 0]}, {'input_ids': [1, 4297, 128000, 21, 45, 1268, 780, 7, 127, 128000, 18611, 479, 2], 'labels': [0, 0, 939, 0, 0, 0, 0, 0, 0, 748, 0, 0, 0]}] 4\n",
      "['[CLS]', '<0x82>', '—', '▁arms', '<0x00>', 'wrenching', 'wrenching', '▁auditions', 'vator', '<0x05>', '▁that', '▁Valley', '▁7', '▁wish', '[MASK]', '<0x81>', '▁arriving', '<0x05>', '<0x01>', '<0x86>', '<0x1C>', '<0x03>', '<0x1F>', '[MASK]', '▁landfills', '▁Again', '<0x04>', '▁least', '▁DH', '▁copy', '[MASK]', '▁never', '<0x13>', '[MASK]', '▁turkey', '<0x00>', 'wrenching', '▁landfills', '▁review', '<0x04>', '[MASK]', '<0x09>', '▁throw', '<0x02>', '▁expenses', '[MASK]', '▁microwave', '<0x07>', '▁Idaho', '<0x0F>', '▁with', '▁Duolingo', '▁iron', '<0x00>', 'wrenching', '▁1865', '▁recurring', '▁Once', '<0x05>', '[MASK]', '<0x0A>', '▁women', '▁.', '[MASK]', '<0x13>', '<0x01>', '▁topics', '<0x03>', '▁FL', '[MASK]', '▁chips', '<0x00>', 'wrenching', '▁Lessons', '▁dumped', '▁:', '▁throw', '<0x02>', '[MASK]', '<0x02>', '▁microwave', '[MASK]', '▁Used', 'ney', '<0x00>', '[MASK]', '▁Known', '<0x02>', '▁noise', '<0x04>', '▁Having', '▁turkey', '<0x04>', '▁Excess', '▁receive', '▁tomorrow', '[MASK]', '▁Mass', '<0x00>', 'wrenching', 'wrenching', '▁pigeon', '[MASK]', '▁wish', '[MASK]', '<0x81>', '▁that', '▁Valley', '▁7', '▁logging', '[MASK]', '▁nicer', '<0x97>', '<0x13>', '<0x01>', '<0xE1>', '▁cloud', '<0x07>', '▁under', '▁A', '<0x04>', '<0x11>', '▁listed', '<0x07>', '[MASK]', '<0xC3>', '<0x04>', '<0x11>', '▁Christmas', '<0x03>', '<0x01>', ')', '<0x43>', '<0x97>', '[MASK]', '<0x00>', '▁wish', 'wrenching', 'wrenching', '[MASK]', '<0x11>', '▁firm', '<0x37>', \"▁'\", '▁overall', '[MASK]', '▁graphics', '<0x11>', '▁town', '<0x0B>', '<0x01>', '▁non', '<0x05>', '<0x01>', '▁nicer', '<0x97>', '<0x04>', '<0x5D>', '▁resources', '<0x13>', '<0xE1>', '▁cloud', '<0x00>', '<0x10>', '▁According', '<0x05>', '<0x06>', '▁wish', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 50118, 0, 0, 16849, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 50140, 0, 0, 0, 0, 0, 0, 8, 0, 0, 5, 0, 0, 0, 0, 0, 0, 573, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 758, 0, 0, 0, 0, 0, 0, 0, 2244, 0, 0, 0, 518, 0, 0, 0, 0, 0, 1374, 0, 0, 0, 0, 0, 0, 0, 0, 4408, 0, 0, 8, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 29, 0, 50118, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 502, 0, 0, 0, 0, 0, 0, 0, 71, 0, 377, 0, 0, 0, 0, 243, 0, 0, 0, 0, 0, 10056, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 134, 644, 3010, 4, 50118, 50118, 36391, 73939, 9, 272, 2562, 574, 1437, 128000, 133, 8047, 9, 5, 138, 32, 7, 35, 128000, 36836, 3906, 8, 668, 17329, 2104, 128000, 518, 23, 128000, 9651, 4, 50118, 36836, 1078, 8, 128000, 13, 3054, 6, 3670, 128000, 9145, 11, 10753, 19, 275, 106131, 3464, 4, 50118, 25138, 13014, 1414, 9, 128000, 14, 694, 323, 128000, 23, 5, 3062, 7, 6292, 128000, 5838, 4, 50118, 19127, 12427, 877, 3054, 6, 128000, 6, 9145, 128000, 7107, 7467, 4, 128000, 15347, 6, 3616, 8, 3014, 9651, 8, 43120, 1069, 3275, 128000, 5498, 4, 50118, 50118, 33347, 128000, 1437, 128000, 133, 272, 2562, 574, 11236, 128000, 19566, 155, 23, 5, 229, 2889, 11, 494, 336, 8, 21, 2121, 11, 128000, 199, 8, 21, 1357, 7, 5, 285, 71, 155, 128000, 4, 1437, 50118, 50118, 128000, 21, 1695, 59, 382, 1629, 128000, 4416, 21, 1240, 15, 5, 745, 9, 5, 19566, 155, 8, 97, 1377, 23, 229, 2889, 4, 20, 1663, 9, 10, 1437, 2] masked_sample ids\n",
      "[1, 49519, 11380, 479, 2] 1\n",
      "['[CLS]', '▁COD', '▁learnt', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁COD', '[MASK]', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 11380, 0, 0] target_labels\n",
      "[1, 49519, 128000, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 500, 260, 1073, 128000, 38, 16, 10, 435, 709, 1803, 14, 4620, 41, 6833, 2757, 87151, 9462, 1073, 8849, 28764, 9, 7157, 55576, 1418, 92300, 5, 1362, 194, 9, 580, 7104, 4, 50118, 50118, 128000, 10486, 50118, 725, 873, 1452, 7748, 128000, 16, 2034, 23, 128000, 50118, 50118, 500, 128000, 1073, 8849, 38, 7522, 11700, 16, 128000, 30, 15803, 8467, 3644, 7522, 11700, 11, 5, 128000, 6, 9462, 1073, 8849, 128000, 7522, 128000, 11, 5, 3017, 6, 20009, 128000, 11695, 7522, 11700, 11, 5, 2077, 8, 128000, 1588, 710, 7522, 128000, 8, 4317, 12969, 298, 7522, 11700, 11, 41598, 128000, 352, 1418, 420, 5, 41598, 4147, 352, 128000, 11, 5, 3072, 128000, 50118, 50118, 487, 20329, 128000, 16, 2260, 70, 13996, 128000, 35512, 6480, 7, 5, 3017, 9, 41598, 4147, 352, 128000, 6, 8094, 684, 25, 5371, 128000, 128000, 20206, 4, 20, 70, 13996, 128000, 35512, 32, 847, 420, 30, 215, 43506, 5119, 128000, 12656, 1097, 128000, 6, 732, 8629, 118, 8, 128000, 1908, 3648, 4, 590, 209, 12323, 562, 11052, 5357, 62, 128000, 12530, 32, 10, 16331, 1905, 128000, 50118, 50118, 500, 260, 128000, 8849, 38, 7522, 11700, 128000, 41, 443, 9, 17445, 4, 4540, 50141, 7203, 176, 4, 85, 34, 112, 5730, 611, 857, 415, 579, 2], 'labels': [0, 0, 0, 0, 8849, 0, 0, 0, 0, 0, 1803, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 493, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20981, 0, 0, 0, 0, 0, 0, 1437, 0, 0, 0, 479, 0, 0, 0, 260, 0, 0, 0, 0, 0, 0, 43490, 0, 0, 0, 0, 0, 0, 0, 0, 1926, 0, 0, 0, 0, 3082, 0, 11700, 0, 0, 0, 0, 0, 417, 0, 0, 0, 0, 0, 0, 0, 8550, 0, 0, 0, 11700, 0, 0, 0, 0, 0, 0, 0, 0, 4147, 0, 0, 0, 0, 0, 0, 0, 1995, 0, 0, 0, 4, 0, 0, 0, 0, 1418, 0, 0, 0, 0, 2617, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1995, 0, 0, 0, 0, 0, 1073, 853, 0, 0, 0, 0, 0, 2617, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 0, 118, 0, 0, 0, 0, 0, 28194, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 1073, 0, 0, 0, 0, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 627, 169, 37, 1415, 23, 20435, 2426, 128000, 101, 79, 21, 5, 129, 65, 128000, 5, 929, 2156, 2468, 69, 235, 11, 128000, 2], 'labels': [0, 627, 0, 0, 0, 0, 0, 0, 2156, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 479, 0]}, {'input_ids': [1, 134, 644, 3010, 4, 50118, 50118, 36391, 73939, 9, 272, 2562, 574, 1437, 128000, 133, 8047, 9, 5, 138, 32, 7, 35, 128000, 36836, 3906, 8, 668, 17329, 2104, 128000, 518, 23, 128000, 9651, 4, 50118, 36836, 1078, 8, 128000, 13, 3054, 6, 3670, 128000, 9145, 11, 10753, 19, 275, 106131, 3464, 4, 50118, 25138, 13014, 1414, 9, 128000, 14, 694, 323, 128000, 23, 5, 3062, 7, 6292, 128000, 5838, 4, 50118, 19127, 12427, 877, 3054, 6, 128000, 6, 9145, 128000, 7107, 7467, 4, 128000, 15347, 6, 3616, 8, 3014, 9651, 8, 43120, 1069, 3275, 128000, 5498, 4, 50118, 50118, 33347, 128000, 1437, 128000, 133, 272, 2562, 574, 11236, 128000, 19566, 155, 23, 5, 229, 2889, 11, 494, 336, 8, 21, 2121, 11, 128000, 199, 8, 21, 1357, 7, 5, 285, 71, 155, 128000, 4, 1437, 50118, 50118, 128000, 21, 1695, 59, 382, 1629, 128000, 4416, 21, 1240, 15, 5, 745, 9, 5, 19566, 155, 8, 97, 1377, 23, 229, 2889, 4, 20, 1663, 9, 10, 1437, 2], 'labels': [0, 0, 0, 0, 0, 50118, 0, 0, 16849, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 50140, 0, 0, 0, 0, 0, 0, 8, 0, 0, 5, 0, 0, 0, 0, 0, 0, 573, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 758, 0, 0, 0, 0, 0, 0, 0, 2244, 0, 0, 0, 518, 0, 0, 0, 0, 0, 1374, 0, 0, 0, 0, 0, 0, 0, 0, 4408, 0, 0, 8, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 29, 0, 50118, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 502, 0, 0, 0, 0, 0, 0, 0, 71, 0, 377, 0, 0, 0, 0, 243, 0, 0, 0, 0, 0, 10056, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 49519, 128000, 479, 2], 'labels': [0, 0, 11380, 0, 0]}] 4\n",
      "[1, 700, 7700, 5, 4049, 7, 39, 14638, 8, 19811, 39, 5397, 124, 2156, 37907, 66, 5, 4076, 11, 65, 251, 821, 31777, 479, 2] 1\n",
      "['[CLS]', '▁went', '▁albums', '<0x01>', '▁Section', '<0x03>', '<0x23>', '▁paints', '<0x04>', '▁parole', '<0x23>', '▁MA', '<0x78>', '▁90', 'hereinafter', '<0x3E>', '<0x01>', 'um', '<0x07>', '<0x3D>', '<0xF7>', '▁living', 'finished', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁82', '▁brand', '<0x03>', '<0xBC>', '[MASK]', '▁arranged', '▁But', '[MASK]', 'hai', '<0x01>', '<0xF9>', '▁recognition', '▁Senior', '<0x36>', '[MASK]', '▁condition', '<0x01>', '▁characters', '▁traced', '<0x04>', '▁для', '<0x54>', '<0x14>', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 14, 0, 0, 5, 0, 0, 0, 0, 0, 0, 878, 0, 0, 0, 0, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 8877, 1224, 7, 192, 128000, 6128, 420, 128000, 20707, 5, 253, 3994, 4490, 58, 128000, 1706, 5, 1855, 16836, 8, 33189, 88, 24, 128000, 2] masked_sample ids\n",
      "[1, 35047, 415, 28, 7560, 15, 39, 28702, 479, 2] 1\n",
      "['[CLS]', 'ulin', 've', '<0x18>', '▁98', '<0x0B>', '<0x23>', 'CW', '▁things', '[SEP]'] 2\n",
      "['[CLS]', 'ulin', 've', '[MASK]', '▁98', '<0x0B>', '<0x23>', 'CW', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 28, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 35047, 415, 128000, 7560, 15, 39, 28702, 128000, 2] masked_sample ids\n",
      "[{'input_ids': [1, 6968, 6056, 295, 128000, 489, 12200, 479, 128000, 2], 'labels': [0, 0, 0, 0, 75, 0, 0, 0, 12801, 0]}, {'input_ids': [1, 506, 24029, 4024, 65363, 5373, 479, 12801, 2], 'labels': [0, 0, 0, 0, 162, 0, 0, 0, 0]}, {'input_ids': [1, 8877, 1224, 7, 192, 128000, 6128, 420, 128000, 20707, 5, 253, 3994, 4490, 58, 128000, 1706, 5, 1855, 16836, 8, 33189, 88, 24, 128000, 2], 'labels': [0, 0, 0, 0, 0, 14, 0, 0, 5, 0, 0, 0, 0, 0, 0, 878, 0, 0, 0, 0, 0, 0, 0, 0, 479, 0]}, {'input_ids': [1, 35047, 415, 128000, 7560, 15, 39, 28702, 128000, 2], 'labels': [0, 0, 0, 28, 0, 0, 0, 0, 479, 0]}] 4\n",
      "Epoch 0:   0%|          | 8/25701300 [00:05<5183:50:37,  1.38it/s, v_num=43, loss_gen=128.0, loss_disc=0.211]['[CLS]', '▁went', '[MASK]', '<0x01>', '▁Section', '<0x03>', '<0x23>', '[MASK]', '<0x04>', '▁parole', '<0x23>', '▁MA', '<0x78>', '▁90', '[MASK]', '<0x3E>', '<0x01>', 'um', '<0x07>', '<0x3D>', '[MASK]', '▁living', 'finished', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 7700, 0, 0, 0, 0, 14638, 0, 0, 0, 0, 0, 0, 37907, 0, 0, 0, 0, 0, 251, 0, 0, 0, 0] target_labels\n",
      "[1, 700, 128000, 5, 4049, 7, 39, 128000, 8, 19811, 39, 5397, 124, 2156, 128000, 66, 5, 4076, 11, 65, 128000, 821, 31777, 479, 2] masked_sample ids\n",
      "[1, 49519, 117, 2156, 12801, 79, 2641, 2156, 2157, 5, 6941, 386, 7, 283, 479, 2] 1\n",
      "['[CLS]', '▁COD', '<0x71>', '▁90', '▁amendments', '<0x4B>', '▁factor', '▁90', '▁River', '<0x01>', '▁mice', '▁many', '<0x03>', '▁as', '▁things', '[SEP]'] 2\n",
      "Epoch 0:   0%|          | 8/25701300 [00:05<5235:55:04,  1.36it/s, v_num=43, loss_gen=113.0, loss_disc=0.242]['[CLS]', '▁renamed', '<0x71>', '▁90', '▁amendments', '<0x4B>', '▁factor', '[MASK]', '▁River', '<0x01>', '▁mice', '▁many', '<0x03>', '▁as', '▁things', '[SEP]'] masked_sample\n",
      "[0, 49519, 0, 0, 0, 0, 0, 2156, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 15193, 117, 2156, 12801, 79, 2641, 128000, 2157, 5, 6941, 386, 7, 283, 479, 2] masked_sample ids\n",
      "[1, 417, 1243, 1239, 28328, 31, 127, 1420, 2156, 8, 16490, 114, 939, 109, 295, 75, 619, 101, 41, 13473, 4095, 479, 2] 1\n",
      "['[CLS]', '▁him', '▁shall', '▁impact', '▁Directorate', '<0x1B>', '<0x7B>', '▁Monday', '▁90', '<0x04>', '▁whichever', '<0x6E>', '▁forward', '<0x69>', '▁can', '<0x47>', '▁done', '<0x61>', '<0x25>', '▁rainy', '▁tournament', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '▁shall', '▁impact', '▁Directorate', '<0x1B>', '<0x7B>', '▁Monday', '▁90', '<0x04>', '[MASK]', '<0x6E>', '▁forward', '<0x69>', '▁can', '<0x47>', '▁done', '[MASK]', '<0x25>', '▁rainy', '▁tournament', '▁things', '[SEP]'] masked_sample\n",
      "[0, 417, 0, 0, 0, 0, 0, 0, 0, 0, 16490, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 128000, 1243, 1239, 28328, 31, 127, 1420, 2156, 8, 128000, 114, 939, 109, 295, 75, 619, 128000, 41, 13473, 4095, 479, 2] masked_sample ids\n",
      "[1, 49519, 8401, 4917, 102, 47, 236, 162, 7, 224, 17487, 12801, 2] 1\n",
      "['[CLS]', '▁COD', '▁Military', '▁ear', '<0x62>', '<0x2B>', '<0xE8>', '<0x9E>', '<0x03>', '<0xDC>', 'Mart', '▁amendments', '[SEP]'] 2\n",
      "['[CLS]', '▁COD', '▁Military', '▁ear', '<0x62>', '<0x2B>', '<0xE8>', '<0x9E>', '[MASK]', '<0xDC>', 'Mart', '▁amendments', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 4917, 0, 0, 0, 0, 7, 0, 0, 0, 0] target_labels\n",
      "[1, 49519, 8401, 4917, 102, 47, 236, 162, 128000, 224, 17487, 12801, 2] masked_sample ids\n",
      "[{'input_ids': [1, 700, 128000, 5, 4049, 7, 39, 128000, 8, 19811, 39, 5397, 124, 2156, 128000, 66, 5, 4076, 11, 65, 128000, 821, 31777, 479, 2], 'labels': [0, 0, 7700, 0, 0, 0, 0, 14638, 0, 0, 0, 0, 0, 0, 37907, 0, 0, 0, 0, 0, 251, 0, 0, 0, 0]}, {'input_ids': [1, 15193, 117, 2156, 12801, 79, 2641, 128000, 2157, 5, 6941, 386, 7, 283, 479, 2], 'labels': [0, 49519, 0, 0, 0, 0, 0, 2156, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 1243, 1239, 28328, 31, 127, 1420, 2156, 8, 128000, 114, 939, 109, 295, 75, 619, 128000, 41, 13473, 4095, 479, 2], 'labels': [0, 417, 0, 0, 0, 0, 0, 0, 0, 0, 16490, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0]}, {'input_ids': [1, 49519, 8401, 4917, 102, 47, 236, 162, 128000, 224, 17487, 12801, 2], 'labels': [0, 0, 0, 4917, 0, 0, 0, 0, 7, 0, 0, 0, 0]}] 4\n",
      "[1, 17830, 20479, 2156, 52, 5764, 156, 84, 169, 1706, 5, 3543, 9, 5, 3267, 25606, 939, 10346, 69, 25, 79, 4425, 124, 479, 2] 1\n",
      "['[CLS]', '▁hefty', '▁Surf', '▁90', '<0x30>', '▁Indiana', '<0x98>', '<0x50>', '<0xA5>', '▁condition', '<0x01>', '▁millions', '<0x05>', '<0x01>', '▁hurt', '▁marginalized', '▁forward', '▁ladder', '<0x41>', '<0x15>', '<0x4B>', '08', '<0x78>', '▁things', '[SEP]'] 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁hefty', '▁Surf', '▁90', '[MASK]', '▁Indiana', '<0x98>', '<0x50>', '[MASK]', '▁condition', '<0x01>', '▁millions', '<0x05>', '<0x01>', '▁hurt', '[MASK]', '▁forward', '▁ladder', '<0x41>', '<0x15>', '<0x4B>', '08', '<0x78>', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 52, 0, 0, 0, 169, 0, 0, 0, 0, 0, 0, 25606, 0, 0, 0, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 17830, 20479, 2156, 128000, 5764, 156, 84, 128000, 1706, 5, 3543, 9, 5, 3267, 128000, 939, 10346, 69, 25, 79, 4425, 124, 479, 2] masked_sample ids\n",
      "[1, 1594, 45, 13, 5, 8513, 32248, 9, 5, 8661, 2156, 1236, 11290, 9927, 11, 39, 5856, 2396, 123, 28105, 1210, 927, 2156, 5, 913, 9, 5, 1136, 429, 33, 6536, 123, 66, 2569, 479, 2] 1\n",
      "['[CLS]', '▁changed', '<0x29>', '<0x09>', '<0x01>', '▁Cruz', '▁weathered', '<0x05>', '<0x01>', '▁Jake', '▁90', '▁credit', '▁Plaza', '▁je', '<0x07>', '<0x23>', '▁adequate', '▁frame', '<0x77>', '▁edging', '▁average', '▁By', '▁90', '<0x01>', '▁clear', '<0x05>', '<0x01>', '▁items', '▁&', '<0x1D>', '▁poll', '<0x77>', '<0x3E>', '▁<', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁predatory', 'shan', '😌', '▁current', '<0x20>', '<0x02>', '▁marginalized', '▁resulted', '<0x0C>', '▁tied', '▁17', '▁Dublin', '<0x07>', '▁Greensboro', '<0x02>', '▁tips', '[MASK]', 'shan', '▁goes', '▁current', '[MASK]', '▁each', '▁House', '▁reputable', '▁relaxed', '[MASK]', '<0x0B>', '<0x01>', '▁resolution', '<0x0E>', '▁Wall', '▁ground', 'Hold', '<0x00>', '▁losing', 'иц', '[MASK]', '▁Shares', '<0x05>', '▁LC', '▁habitual', 'NS', '<0x04>', '▁sauté', '▁Things', '▁delicate', '<0x1A>', '[MASK]', '<0x05>', '▁manifestation', '▁420', '[MASK]', '<0x51>', '▁struggling', '<0x01>', '▁hands', '<0x05>', '<0x01>', '▁resolution', '▁Muertos', '<0x8C>', '▁found', '[MASK]', '<0x08>', '▁128', '▁events', '<0x00>', '<0x51>', '<0x0C>', '<0x06>', '▁guitar', '▁noodles', '<0x09>', '▁Fortunately', '[MASK]', '<0xD5>', '<0x63>', '▁institutions', '<0x04>', '[MASK]', '▁Trade', '<0x02>', '<0x15>', '<0x99>', '<0x15>', '<0x25>', '▁found', '[MASK]', '▁gave', '<0x00>', '▁dark', 'shan', '▁goes', '[MASK]', '<0x04>', '<0x3B>', '▁pace', '▁Stripe', '▁challenge', '▁90', '[MASK]', '▁include', '<0x06>', '+', '<0x05>', '▁souvenirs', '[MASK]', '<0xD5>', '[MASK]', '▁data', '<0x02>', '▁industry', '<0xC0>', '▁burn', '<0x19>', '[MASK]', '▁sauté', '▁Things', '<0x02>', '<0x04>', '▁gel', '▁detectives', '▁John', '[MASK]', '<0x10>', '▁Dublin', '▁wait', '▁DVD', '▁things', '▁dark', 'shan', '[MASK]', '▁current', '<0x11>', '▁studio', '<0x06>', '▁destinations', '[MASK]', '<0x05>', '▁everything', '[MASK]', '<0xDB>', '<0x01>', '▁everything', '▁Given', '-', '▁fatigue', '<0x0B>', '[MASK]', '<0x80>', '<0x02>', 'art', '<0x00>', 'wrenching', '[MASK]', '<0x81>', '<0xF7>', '▁MAC', '{', '▁image', '▁better', '<0x20>', '▁misused', '▁stretch', '▁aggressive', '▁than', 'After', '▁often', '▁child', '<0x27>', '▁wish', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 1242, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 12, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23678, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 911, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 18, 0, 0, 7666, 0, 0, 0, 0, 0, 0, 0, 4066, 0, 0, 0, 6, 0, 0, 0, 0, 14739, 0, 0, 0, 0, 0, 0, 0, 5651, 0, 0, 0, 0, 0, 763, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 6, 0, 490, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1242, 0, 0, 0, 0, 0, 1245, 0, 0, 3585, 0, 0, 0, 0, 0, 0, 0, 902, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 33309, 18226, 126735, 763, 36, 6, 25606, 4839, 16, 4946, 1154, 8037, 11, 33545, 6, 2034, 128000, 18226, 1242, 763, 128000, 448, 1097, 11104, 6131, 128000, 15, 5, 2946, 18, 3285, 1353, 31585, 4, 3139, 102858, 128000, 14092, 9, 16762, 34769, 17529, 8, 35899, 5065, 7501, 30, 128000, 9, 19790, 22178, 128000, 85, 4620, 5, 1312, 9, 5, 2946, 95217, 144, 505, 128000, 12, 11600, 976, 4, 85, 16, 10, 4066, 14294, 13, 7892, 128000, 217, 103, 3159, 8, 128000, 4707, 6, 25, 157, 25, 41, 505, 128000, 1255, 4, 1777, 18226, 1242, 128000, 8, 63, 3817, 29084, 1719, 2156, 128000, 680, 10, 1186, 9, 29073, 128000, 217, 128000, 514, 6, 769, 196, 5134, 29, 128000, 35899, 5065, 6, 8, 7666, 21775, 918, 128000, 20, 8037, 1495, 4865, 479, 1777, 18226, 128000, 763, 21, 2998, 10, 7727, 128000, 9, 758, 128000, 223, 5, 758, 5474, 271, 9127, 15, 128000, 132, 6, 4999, 4, 50118, 128000, 133, 251, 13597, 19976, 1115, 493, 36, 41635, 4306, 5638, 354, 12303, 611, 853, 43, 1437, 2] masked_sample ids\n",
      "[{'input_ids': [1, 12724, 2721, 2933, 128000, 14, 58, 3820, 128000, 1109, 8, 2933, 2156, 373, 7, 69, 479, 2], 'labels': [0, 0, 0, 0, 2473, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0, 69, 0, 0]}, {'input_ids': [1, 22466, 128000, 728, 2156, 5, 11641, 128000, 10, 8401, 2838, 50, 34415, 2601, 479, 2], 'labels': [0, 0, 367, 0, 0, 0, 0, 19057, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 25252, 89, 37, 103608, 16190, 10, 128000, 147, 37, 74, 6105, 614, 454, 2936, 132, 438, 2035, 11, 290, 722, 479, 2], 'labels': [0, 0, 0, 0, 20290, 0, 0, 4683, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0]}, {'input_ids': [1, 33309, 18226, 126735, 763, 36, 6, 25606, 4839, 16, 4946, 1154, 8037, 11, 33545, 6, 2034, 128000, 18226, 1242, 763, 128000, 448, 1097, 11104, 6131, 128000, 15, 5, 2946, 18, 3285, 1353, 31585, 4, 3139, 102858, 128000, 14092, 9, 16762, 34769, 17529, 8, 35899, 5065, 7501, 30, 128000, 9, 19790, 22178, 128000, 85, 4620, 5, 1312, 9, 5, 2946, 95217, 144, 505, 128000, 12, 11600, 976, 4, 85, 16, 10, 4066, 14294, 13, 7892, 128000, 217, 103, 3159, 8, 128000, 4707, 6, 25, 157, 25, 41, 505, 128000, 1255, 4, 1777, 18226, 1242, 128000, 8, 63, 3817, 29084, 1719, 2156, 128000, 680, 10, 1186, 9, 29073, 128000, 217, 128000, 514, 6, 769, 196, 5134, 29, 128000, 35899, 5065, 6, 8, 7666, 21775, 918, 128000, 20, 8037, 1495, 4865, 479, 1777, 18226, 128000, 763, 21, 2998, 10, 7727, 128000, 9, 758, 128000, 223, 5, 758, 5474, 271, 9127, 15, 128000, 132, 6, 4999, 4, 50118, 128000, 133, 251, 13597, 19976, 1115, 493, 36, 41635, 4306, 5638, 354, 12303, 611, 853, 43, 1437, 2], 'labels': [0, 0, 0, 1242, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 12, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23678, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 911, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 18, 0, 0, 7666, 0, 0, 0, 0, 0, 0, 0, 4066, 0, 0, 0, 6, 0, 0, 0, 0, 14739, 0, 0, 0, 0, 0, 0, 0, 5651, 0, 0, 0, 0, 0, 763, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 6, 0, 490, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1242, 0, 0, 0, 0, 0, 1245, 0, 0, 3585, 0, 0, 0, 0, 0, 0, 0, 902, 0, 0, 0, 0, 0, 50118, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}] 4\n",
      "[1, 9178, 251, 56, 37, 57, 11, 5, 23678, 137, 17487, 2] 1\n",
      "['[CLS]', '▁urgent', '<0xF7>', '<0x34>', '<0x21>', '<0x35>', '<0x07>', '<0x01>', '▁Kensington', '<0x85>', 'Mart', '[SEP]'] 2\n",
      "['[CLS]', '[MASK]', '<0x29>', '<0x09>', '<0x01>', '▁Cruz', '▁weathered', '<0x05>', '<0x01>', '▁Jake', '▁90', '▁credit', '[MASK]', '▁je', '<0x07>', '<0x23>', '▁adequate', '▁frame', '<0x77>', '▁edging', '▁average', '▁By', '▁90', '[MASK]', '▁clear', '<0x05>', '<0x01>', '▁items', '▁strapping', '<0x1D>', '▁poll', '<0x77>', '<0x3E>', '▁<', '▁things', '[SEP]'] masked_sample\n",
      "[0, 1594, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11290, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 429, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 128000, 45, 13, 5, 8513, 32248, 9, 5, 8661, 2156, 1236, 128000, 9927, 11, 39, 5856, 2396, 123, 28105, 1210, 927, 2156, 128000, 913, 9, 5, 1136, 55996, 33, 6536, 123, 66, 2569, 479, 2] masked_sample ids\n",
      "[1, 32630, 61, 7, 3190, 312, 4203, 28585, 19277, 4807, 6, 15, 195, 902, 28234, 6, 19, 11588, 118, 4654, 102, 230, 18068, 11456, 118, 4807, 4, 2804, 1206, 56, 30, 419, 28234, 283, 7, 192, 5, 8263, 312, 4203, 28585, 19277, 4807, 19, 39, 7416, 9, 145, 10, 33747, 884, 6, 25, 10, 1856, 7, 39, 308, 476, 4, 50118, 50118, 20839, 39, 5010, 6, 5, 2804, 6304, 1342, 439, 617, 30, 6769, 8173, 312, 4203, 28585, 19277, 4807, 396, 4692, 1303, 454, 37, 56, 2312, 6, 19, 5, 244, 9, 39, 670, 1081, 3405, 7, 1745, 1655, 11663, 9, 5, 987, 36, 8155, 56, 57, 5, 2804, 6304, 1342, 18, 275, 313, 11, 37613, 43, 7, 27120, 5, 323, 9, 5, 315, 5752, 7, 33, 312, 4203, 28585, 19277, 4807, 1051, 88, 21323, 7, 5, 1089, 5748, 21878, 9, 26214, 6125, 6, 147, 37, 21, 1682, 148, 623, 1771, 3082, 4, 374, 601, 494, 27939, 6, 312, 4203, 28585, 19277, 4807, 21, 4507, 81, 7, 10, 1089, 2938, 1370, 11, 4644, 6, 31, 147, 37, 21, 1051, 15, 7, 26214, 6125, 4, 870, 42, 4202, 179, 2] 1\n",
      "['[CLS]', '▁Hiro', '<0x39>', '<0x03>', '▁transport', '▁my', '▁Democrats', '▁Hun', 'imi', '▁grass', '<0x02>', '<0x0B>', '<0xBF>', '▁National', '▁homestead', '<0x02>', '<0x0F>', '▁Chile', '<0x72>', '▁chairs', '<0x62>', '<0xE2>', '▁Santiago', '▁pilots', '<0x72>', '▁grass', '<0x00>', '▁wearing', '▁career', '<0x34>', '<0x1A>', '▁$', '▁homestead', '▁as', '<0x03>', '<0xBC>', '<0x01>', '▁drum', '▁my', '▁Democrats', '▁Hun', 'imi', '▁grass', '<0x0F>', '<0x23>', '▁algorithm', '<0x05>', '<0x8D>', '<0x06>', 'comp', '▁size', '<0x02>', '<0x15>', '<0x06>', '▁protection', '<0x03>', '<0x23>', '▁their', 'I', '<0x00>', 'wrenching', 'wrenching', '▁Payments', '<0x23>', '▁developer', '<0x02>', '<0x01>', '▁wearing', '▁terminal', '▁English', '▁information', '▁power', '<0x1A>', '58', '▁shore', '▁my', '▁Democrats', '▁Hun', 'imi', '▁grass', '▁back', '▁Prince', '▁groups', '▁same', '<0x21>', '<0x34>', '▁applied', '<0x02>', '<0x0F>', '<0x01>', '<0xF0>', '<0x05>', '<0x23>', '▁came', '▁card', '▁Un', '<0x03>', '▁husband', '▁un', '▁Representative', '<0x05>', '<0x01>', '▁St', '<0x20>', '▁Yellow', '<0x34>', '<0x35>', '<0x01>', '▁wearing', '▁terminal', '▁English', '<0x0E>', '▁with', '▁he', '<0x07>', '▁ingestion', '<0x27>', '<0x03>', '▁mellow', '<0x01>', '▁.', '<0x05>', '<0x01>', '▁his', '▁swing', '<0x03>', '<0x1D>', '▁my', '▁Democrats', '▁Hun', 'imi', '▁grass', '▁risk', '<0x54>', '▁surfaced', '<0x03>', '<0x01>', '▁paper', '▁delete', '▁Airbnb', '<0x05>', '▁Schultz', '▁keyboard', '<0x02>', '<0x8F>', '<0x21>', '<0x11>', '▁disease', '<0x90>', '▁read', '▁cancer', '▁messages', '<0x00>', '▁work', '▁name', '▁under', 'Made', '<0x02>', '▁my', '▁Democrats', '▁Hun', 'imi', '▁grass', '<0x11>', '▁packages', '<0x4D>', '<0x03>', '<0x06>', '▁paper', '▁fields', '▁October', '<0x07>', '▁statistics', '<0x02>', '<0x1B>', '<0x8F>', '<0x21>', '<0x11>', '▁risk', '<0x0B>', '<0x03>', '▁Schultz', '▁keyboard', '<0x00>', '▁property', '<0x26>', '▁Training', '<0xAF>', '[SEP]'] 2\n",
      "['[CLS]', '▁urgent', '<0xF7>', '<0x34>', '<0x21>', '[MASK]', '<0x07>', '[MASK]', '▁Kensington', '<0x85>', 'Mart', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 57, 0, 5, 0, 0, 0, 0] target_labels\n",
      "[1, 9178, 251, 56, 37, 128000, 11, 128000, 23678, 137, 17487, 2] masked_sample ids\n",
      "[1, 102, 579, 1452, 37682, 2369, 376, 2156, 156, 9, 793, 12396, 14291, 154, 223, 2917, 2156, 9219, 219, 475, 16598, 3786, 14357, 8633, 7520, 2156, 8, 33960, 9247, 37539, 479, 2] 1\n",
      "['[CLS]', '<0x62>', '▁why', '▁blood', 'wedding', '▁visitors', '▁1', '▁90', '<0x98>', '<0x05>', '▁results', '의', '▁triumph', '<0x96>', '<0xDB>', '21', '▁90', '▁dump', '<0xD7>', '▁three', '▁quarry', '▁routine', '▁recruited', '▁brave', '▁partially', '▁90', '<0x04>', '▁Commitment', '▁Opera', 'message', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '<0x62>', '▁why', '▁blood', 'wedding', '▁visitors', '[MASK]', '▁90', '[MASK]', '<0x05>', '▁results', '의', '▁triumph', '<0x96>', '[MASK]', '21', '▁90', '▁dump', '<0xD7>', '[MASK]', '▁quarry', '▁routine', '▁recruited', '▁brave', '▁partially', '▁90', '<0x04>', '▁Commitment', '▁Opera', 'message', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 0, 0, 0, 376, 0, 156, 0, 0, 0, 0, 0, 223, 0, 0, 0, 0, 475, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 479, 0] target_labels\n",
      "[1, 102, 579, 1452, 37682, 2369, 128000, 2156, 128000, 9, 793, 12396, 14291, 154, 128000, 2917, 2156, 9219, 219, 128000, 16598, 3786, 14357, 8633, 7520, 2156, 8, 33960, 9247, 37539, 128000, 2] masked_sample ids\n",
      "[1, 108, 102, 14648, 128, 29, 10, 14648, 2156, 128, 26, 821, 4755, 479, 2] 1\n",
      "['[CLS]', '<0x68>', '<0x62>', 'av', '<0x7C>', '<0x19>', '<0x06>', 'av', '▁90', '<0x7C>', '<0x16>', '▁living', 'more', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '<0x68>', '[MASK]', 'av', '<0x7C>', '<0x19>', '<0x06>', 'av', '▁90', '<0x7C>', '<0x16>', '[MASK]', 'more', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 102, 0, 0, 0, 0, 0, 0, 0, 0, 821, 0, 0, 0] target_labels\n",
      "[1, 108, 128000, 14648, 128, 29, 10, 14648, 2156, 128, 26, 128000, 4755, 479, 2] masked_sample ids\n",
      "[1, 29, 3569, 8973, 1134, 50118, 21461, 268, 108, 659, 2665, 2] 1\n",
      "['[CLS]', '<0x19>', '▁crucial', '▁conviction', '▁cover', 'wrenching', '▁Walnut', 's', '<0x68>', '▁far', '▁birth', '[SEP]'] 2\n",
      "['[CLS]', '<0x19>', '▁crucial', '[MASK]', '▁cover', 'wrenching', '▁Walnut', 's', '<0x68>', '▁far', '[MASK]', '[SEP]'] masked_sample\n",
      "[0, 0, 0, 8973, 0, 0, 0, 0, 0, 0, 2665, 0] target_labels\n",
      "[1, 29, 3569, 128000, 1134, 50118, 21461, 268, 108, 659, 128000, 2] masked_sample ids\n",
      "[{'input_ids': [1, 9178, 251, 56, 37, 128000, 11, 128000, 23678, 137, 17487, 2], 'labels': [0, 0, 0, 0, 0, 57, 0, 5, 0, 0, 0, 0]}, {'input_ids': [1, 102, 579, 1452, 37682, 2369, 128000, 2156, 128000, 9, 793, 12396, 14291, 154, 128000, 2917, 2156, 9219, 219, 128000, 16598, 3786, 14357, 8633, 7520, 2156, 8, 33960, 9247, 37539, 128000, 2], 'labels': [0, 0, 0, 0, 0, 0, 376, 0, 156, 0, 0, 0, 0, 0, 223, 0, 0, 0, 0, 475, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 479, 0]}, {'input_ids': [1, 108, 128000, 14648, 128, 29, 10, 14648, 2156, 128, 26, 128000, 4755, 479, 2], 'labels': [0, 0, 102, 0, 0, 0, 0, 0, 0, 0, 0, 821, 0, 0, 0]}, {'input_ids': [1, 29, 3569, 128000, 1134, 50118, 21461, 268, 108, 659, 128000, 2], 'labels': [0, 0, 0, 8973, 0, 0, 0, 0, 0, 0, 2665, 0]}] 4\n",
      "['[CLS]', '[MASK]', '<0x39>', '<0x03>', '▁transport', '▁my', '▁Democrats', '[MASK]', 'imi', '▁grass', '<0x02>', '<0x0B>', '<0xBF>', '▁National', '▁homestead', '<0x02>', '<0x0F>', '[MASK]', '<0x72>', '▁chairs', '<0x62>', '<0xE2>', '▁Santiago', '▁pilots', '[MASK]', '▁grass', '<0x00>', '▁wearing', '▁career', '<0x34>', '<0x1A>', '▁$', '▁homestead', '▁as', '<0x03>', '[MASK]', '<0x01>', '▁drum', '▁my', '▁Democrats', '▁Hun', 'imi', '[MASK]', '<0x0F>', '<0x23>', '▁algorithm', '[MASK]', '<0x8D>', '<0x06>', 'comp', '[MASK]', '<0x02>', '<0x15>', '<0x06>', '▁protection', '<0x03>', '<0x23>', '▁their', '[MASK]', '<0x00>', 'wrenching', 'wrenching', '▁Payments', '▁ASSIGNORS', '▁developer', '<0x02>', '<0x01>', '▁wearing', '▁terminal', '[MASK]', '▁information', '▁power', '<0x1A>', '58', '[MASK]', '▁my', '▁Democrats', '▁Hun', 'imi', '▁grass', '▁back', '▁Prince', '▁groups', '▁breakthroughs', '<0x21>', '<0x34>', '▁applied', '[MASK]', '<0x0F>', '<0x01>', '<0xF0>', '<0x05>', '<0x23>', '▁came', '▁card', '▁Un', '[MASK]', '▁husband', '▁un', '▁Representative', '<0x05>', '[MASK]', '▁St', '<0x20>', '▁Yellow', '[MASK]', '<0x35>', '<0x01>', '▁wearing', '▁terminal', '[MASK]', '<0x0E>', '▁with', '▁he', '<0x07>', '▁ingestion', '[MASK]', '<0x03>', '▁mellow', '<0x01>', '▁.', '<0x05>', '<0x01>', '▁his', '▁swing', '[MASK]', '<0x1D>', '▁my', '▁Democrats', '▁Hun', 'imi', '▁grass', '▁risk', '<0x54>', '▁surfaced', '<0x03>', '[MASK]', '▁paper', '▁delete', '▁Airbnb', '<0x05>', '[MASK]', '▁keyboard', '<0x02>', '<0x8F>', '<0x21>', '<0x11>', '▁disease', '<0x90>', '[MASK]', '▁cancer', '▁messages', '<0x00>', '▁work', '▁name', '[MASK]', 'Made', '<0x02>', '[MASK]', '▁Democrats', '▁Hun', 'imi', '▁grass', '<0x11>', '[MASK]', '<0x4D>', '<0x03>', '<0x06>', '▁paper', '▁fields', '▁October', '<0x07>', '▁statistics', '<0x02>', '<0x1B>', '<0x8F>', '<0x21>', '<0x11>', '▁risk', '<0x0B>', '<0x03>', '▁Schultz', '▁keyboard', '<0x00>', '▁property', '<0x26>', '▁Training', '<0xAF>', '[SEP]'] masked_sample\n",
      "[0, 32630, 0, 0, 0, 0, 0, 28585, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11588, 0, 0, 0, 0, 0, 0, 118, 0, 0, 0, 1206, 0, 0, 0, 0, 0, 0, 192, 0, 0, 0, 0, 0, 0, 4807, 0, 0, 0, 9, 0, 0, 0, 884, 0, 0, 0, 0, 0, 0, 0, 476, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 1342, 0, 0, 0, 0, 8173, 0, 0, 0, 0, 0, 0, 0, 0, 454, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 5, 0, 0, 0, 56, 0, 0, 0, 0, 1342, 0, 0, 0, 0, 0, 43, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 28585, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 26214, 0, 0, 0, 0, 0, 0, 0, 623, 0, 0, 0, 0, 0, 494, 0, 0, 312, 0, 0, 0, 0, 0, 4507, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] target_labels\n",
      "[1, 128000, 61, 7, 3190, 312, 4203, 128000, 19277, 4807, 6, 15, 195, 902, 28234, 6, 19, 128000, 118, 4654, 102, 230, 18068, 11456, 128000, 4807, 4, 2804, 1206, 56, 30, 419, 28234, 283, 7, 128000, 5, 8263, 312, 4203, 28585, 19277, 128000, 19, 39, 7416, 128000, 145, 10, 33747, 128000, 6, 25, 10, 1856, 7, 39, 308, 128000, 4, 50118, 50118, 20839, 117850, 5010, 6, 5, 2804, 6304, 128000, 439, 617, 30, 6769, 128000, 312, 4203, 28585, 19277, 4807, 396, 4692, 1303, 33683, 37, 56, 2312, 128000, 19, 5, 244, 9, 39, 670, 1081, 3405, 128000, 1745, 1655, 11663, 9, 128000, 987, 36, 8155, 128000, 57, 5, 2804, 6304, 128000, 18, 275, 313, 11, 37613, 128000, 7, 27120, 5, 323, 9, 5, 315, 5752, 128000, 33, 312, 4203, 28585, 19277, 4807, 1051, 88, 21323, 7, 128000, 1089, 5748, 21878, 9, 128000, 6125, 6, 147, 37, 21, 1682, 148, 128000, 1771, 3082, 4, 374, 601, 128000, 27939, 6, 128000, 4203, 28585, 19277, 4807, 21, 128000, 81, 7, 10, 1089, 2938, 1370, 11, 4644, 6, 31, 147, 37, 21, 1051, 15, 7, 26214, 6125, 4, 870, 42, 4202, 179, 2] masked_sample ids\n",
      "[1, 12963, 114, 37, 21, 295, 75, 184, 2156, 5350, 90, 128, 29, 1041, 74, 36811, 905, 69, 11, 683, 1576, 9, 3605, 479, 2] 1\n",
      "['[CLS]', '▁projection', '<0x6E>', '<0x21>', '<0x11>', '▁can', '<0x47>', '<0xB4>', '▁90', '▁vulnerable', '<0x56>', '<0x7C>', '<0x19>', '▁ready', '<0x46>', '▁pseudonym', '▁age', '<0x41>', '<0x07>', '▁line', '▁fresh', '<0x05>', '▁hidden', '▁things', '[SEP]'] 2\n",
      "['[CLS]', '▁projection', '[MASK]', '<0x21>', '<0x11>', '▁can', '<0x47>', '<0xB4>', '▁90', '▁vulnerable', '<0x56>', '<0x7C>', '<0x19>', '▁Entry', '<0x46>', '▁pseudonym', '▁age', '<0x41>', '<0x07>', '▁line', '▁fresh', '[MASK]', '▁hidden', '▁things', '[SEP]'] masked_sample\n",
      "[0, 0, 114, 0, 0, 0, 0, 184, 0, 0, 0, 0, 0, 1041, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0] target_labels\n",
      "[1, 12963, 128000, 37, 21, 295, 75, 184, 2156, 5350, 90, 128, 29, 12382, 74, 36811, 905, 69, 11, 683, 1576, 128000, 3605, 479, 2] masked_sample ids\n",
      "[{'input_ids': [1, 17830, 20479, 2156, 128000, 5764, 156, 84, 128000, 1706, 5, 3543, 9, 5, 3267, 128000, 939, 10346, 69, 25, 79, 4425, 124, 479, 2], 'labels': [0, 0, 0, 0, 52, 0, 0, 0, 169, 0, 0, 0, 0, 0, 0, 25606, 0, 0, 0, 0, 0, 0, 0, 479, 0]}, {'input_ids': [1, 128000, 45, 13, 5, 8513, 32248, 9, 5, 8661, 2156, 1236, 128000, 9927, 11, 39, 5856, 2396, 123, 28105, 1210, 927, 2156, 128000, 913, 9, 5, 1136, 55996, 33, 6536, 123, 66, 2569, 479, 2], 'labels': [0, 1594, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11290, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 429, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 128000, 61, 7, 3190, 312, 4203, 128000, 19277, 4807, 6, 15, 195, 902, 28234, 6, 19, 128000, 118, 4654, 102, 230, 18068, 11456, 128000, 4807, 4, 2804, 1206, 56, 30, 419, 28234, 283, 7, 128000, 5, 8263, 312, 4203, 28585, 19277, 128000, 19, 39, 7416, 128000, 145, 10, 33747, 128000, 6, 25, 10, 1856, 7, 39, 308, 128000, 4, 50118, 50118, 20839, 117850, 5010, 6, 5, 2804, 6304, 128000, 439, 617, 30, 6769, 128000, 312, 4203, 28585, 19277, 4807, 396, 4692, 1303, 33683, 37, 56, 2312, 128000, 19, 5, 244, 9, 39, 670, 1081, 3405, 128000, 1745, 1655, 11663, 9, 128000, 987, 36, 8155, 128000, 57, 5, 2804, 6304, 128000, 18, 275, 313, 11, 37613, 128000, 7, 27120, 5, 323, 9, 5, 315, 5752, 128000, 33, 312, 4203, 28585, 19277, 4807, 1051, 88, 21323, 7, 128000, 1089, 5748, 21878, 9, 128000, 6125, 6, 147, 37, 21, 1682, 148, 128000, 1771, 3082, 4, 374, 601, 128000, 27939, 6, 128000, 4203, 28585, 19277, 4807, 21, 128000, 81, 7, 10, 1089, 2938, 1370, 11, 4644, 6, 31, 147, 37, 21, 1051, 15, 7, 26214, 6125, 4, 870, 42, 4202, 179, 2], 'labels': [0, 32630, 0, 0, 0, 0, 0, 28585, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11588, 0, 0, 0, 0, 0, 0, 118, 0, 0, 0, 1206, 0, 0, 0, 0, 0, 0, 192, 0, 0, 0, 0, 0, 0, 4807, 0, 0, 0, 9, 0, 0, 0, 884, 0, 0, 0, 0, 0, 0, 0, 476, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 1342, 0, 0, 0, 0, 8173, 0, 0, 0, 0, 0, 0, 0, 0, 454, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 5, 0, 0, 0, 56, 0, 0, 0, 0, 1342, 0, 0, 0, 0, 0, 43, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 28585, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 26214, 0, 0, 0, 0, 0, 0, 0, 623, 0, 0, 0, 0, 0, 494, 0, 0, 312, 0, 0, 0, 0, 0, 4507, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [1, 12963, 128000, 37, 21, 295, 75, 184, 2156, 5350, 90, 128, 29, 12382, 74, 36811, 905, 69, 11, 683, 1576, 128000, 3605, 479, 2], 'labels': [0, 0, 114, 0, 0, 0, 0, 184, 0, 0, 0, 0, 0, 1041, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0]}] 4\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "trainer = L.Trainer(max_epochs=3, accelerator='gpu', devices=1)\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/maengmaengeeee/anaconda3/envs/edison/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deberta.utils import NGramMaskGenerator\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens = tokenizer.tokenize(text, add_special_tokens=True)\n",
    "mask_gen = NGramMaskGenerator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/maengmaengeeee/project/edison/deberta/utils.py\u001b[0m(94)\u001b[0;36mmask_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     92 \u001b[0;31m        \u001b[0mtarget_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     93 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 94 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     95 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     96 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_choice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "[[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
      "[0, 0, 0, 0, 0, 14929, 0, 262, 0, 0, 0, 0]\n",
      "array([False, False, False, False,  True, False,  True, False, False,\n",
      "       False])\n",
      "['[CLS]', '▁The', '▁quick', '▁brown', '▁fox', '[MASK]', '▁over', '[MASK]', '▁lazy', '▁dog', '.', '[SEP]']\n",
      "['[CLS]', '▁The', '▁quick', '▁brown', '▁fox', '[MASK]', '▁over', '[MASK]', '▁lazy', '▁dog', '.', '[SEP]']\n",
      "[0, 0, 0, 0, 0, 14929, 0, 262, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "mask_gen.mask_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([217, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "arr = torch.randn(32, 217, 128001)\n",
    "arr = torch.nn.functional.softmax(arr, dim=-1)\n",
    "torch.multinomial(arr[0], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = torch.randn(32, 217, 128001)\n",
    "# arr.min(), arr.max()\n",
    "arr = torch.nn.functional.softmax(arr, dim=-1)\n",
    "# arr.min(), arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 217, 128001]), torch.Size([217, 128001]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape, arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([217, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0].multinomial(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial = torch.distributions.multinomial.Multinomial(1, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = multinomial.sample().topk(1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 217, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
