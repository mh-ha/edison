hidden_dim: 768
embedding_dim: 768
padding_idx: 0
vocab_size: 128001
absolute_position_biased_input: True
num_heads: 12
num_head_dim: 64
layernorm_eps: 1.e-9
hidden_dropout_prob: 0.1
num_hidden_layers: 12
device: 'cuda'
max_seq_len: 512
mask_lm_prob: 0.15
max_preds_per_seq: null
learning_rate: 5.e-4
batch_size: 4
gradient_clip_val: 1.0
gradient_clip_algorithm: 'norm'
tokenizer_name: 'microsoft/deberta-v3-base'
