wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.11.9
    cli_version: 0.16.4
    framework: huggingface
    huggingface_version: 4.38.2
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1722079122.0
    t:
      1:
      - 1
      - 5
      - 11
      - 33
      - 49
      - 51
      - 53
      - 55
      - 71
      - 100
      2:
      - 1
      - 5
      - 11
      - 33
      - 49
      - 51
      - 53
      - 55
      - 71
      - 100
      3:
      - 7
      - 23
      4: 3.11.9
      5: 0.16.4
      6: 4.38.2
      8:
      - 4
      - 5
      13: darwin-arm64
    m:
    - 1: trainer/global_step
      6:
      - 3
    - 1: loss
      5: 1
      6:
      - 1
    - 1: epoch
      5: 1
      6:
      - 1
config:
  desc: null
  value:
    project_name: experiment_edison
    model_name: Edison
    train_for: AE
    dataset_name: roc
    dataloader_name: get_dataloader
    gradient_clip_val: 1.0
    gradient_clip_algorithm: norm
    gradient_accumulation_steps: 1
    max_steps_ae: 50000
    max_steps_diffusion: 250000
    train_batch_size: 4
    max_seq_len: 64
    learning_rate: 0.0001
    min_buffer_size: 5
    buffer_sampling_ratio: 0.5
    ae_module_name: edison_ae
    dim_lm: 768
    dim_ae: 64
    num_layers: 3
    num_encoder_latents: 32
    num_decoder_latents: 32
    transformer_decoder: true
    l2_normalize_latents: true
    diffusion_module_name: baseline_diffusion
    pretrained_ae_path: null
    sampling_timesteps: 250
    loss_type: l2
    objective: pred_v
    scale: 1.0
    train_prob_self_cond: 0.5
    tx_dim: 768
    tx_depth: 12
    num_attn_heads: 12
    ff_mult: 4
    attn_head_dim: 64
    latent_dim: 64
    lm_dim: 768
    dropout: 0.1
    class_conditional: false
    num_classes: 0
    class_unconditional_prob: 0.1
    num_samples: 1000
    self_condition: true
    scale_shift: true
    num_dense_connections: 3
    feedforward_mult: 4
    time_difference_embedding_over_context: 2
    use_latents_c0: false
