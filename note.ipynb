{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maeng.k/anaconda3/envs/edison/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from edison.modules.lightning_data_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 93161 examples [00:00, 1461714.63 examples/s]\n",
      "Generating valid split: 5000 examples [00:00, 1200774.12 examples/s]\n",
      "Map: 100%|██████████| 93161/93161 [00:00<00:00, 128771.81 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 131367.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset('roc', data_path='edison/datasets/ROCstory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Juan really wanted to see the new blockbuster at the movie theater. He arrived early but the line was already long. He waited three hours. When it was finally his turn, he was told the movie was full. All he could watch was a kid's movie he ended up liking quite a lot.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maeng.k/anaconda3/envs/edison/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Map: 100%|██████████| 93161/93161 [00:10<00:00, 8895.67 examples/s]\n",
      "\n",
      "  | Name | Type                         | Params\n",
      "------------------------------------------------------\n",
      "0 | lm   | BartForConditionalGeneration | 139 M \n",
      "1 | ae   | PerceiverAutoEncoder         | 25.6 M\n",
      "------------------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "139 M     Non-trainable params\n",
      "165 M     Total params\n",
      "660.155   Total estimated model params size (MB)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|█         | 1290/11646 [01:36<12:53, 13.40it/s, v_num=119, loss=3.540]"
     ]
    }
   ],
   "source": [
    "from edison.train import TrainFunction\n",
    "from edison.config.config import Config\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = Config()\n",
    "train_fn = TrainFunction(config)\n",
    "train_fn.train_LD4LG_AE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maeng.k/anaconda3/envs/edison/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | autoencoder     | LD4LGAE           | 165 M \n",
      "1 | diffusion_model | GaussianDiffusion | 187 M \n",
      "------------------------------------------------------\n",
      "187 M     Trainable params\n",
      "165 M     Non-trainable params\n",
      "352 M     Total params\n",
      "1,411.773 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  34%|███▍      | 3972/11646 [07:45<15:00,  8.53it/s, v_num=124, loss=0.346]"
     ]
    }
   ],
   "source": [
    "from edison.train import TrainFunction\n",
    "from edison.config.config import Config\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = Config()\n",
    "train_fn = TrainFunction(config)\n",
    "train_fn.train_LD4LG_Diffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
